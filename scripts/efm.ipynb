{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def sinkhorn(A, n_iter=4):\n",
    "    \"\"\"\n",
    "    Sinkhorn iterations.\n",
    "    \"\"\"\n",
    "    for i in range(n_iter):\n",
    "        A /= A.sum(dim=1, keepdim=True)\n",
    "        A /= A.sum(dim=2, keepdim=True)\n",
    "    return A\n",
    "\n",
    "\n",
    "class SimpleConvNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple convolutional neural network shared among all pieces.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 3 x 16 x 16 input\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3)\n",
    "        # 8 x 14 x 14\n",
    "        self.conv2 = nn.Conv2d(8, 8, 3)\n",
    "        self.conv2_bn = nn.BatchNorm2d(8)\n",
    "        # 8 x 12 x 12\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        # 8 x 6 x 6\n",
    "        self.conv3 = nn.Conv2d(8, 16, 3)\n",
    "        self.conv3_bn = nn.BatchNorm2d(16)\n",
    "        # 16 x 4 x 4\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 128)\n",
    "        self.fc1_bn = nn.BatchNorm1d(128)\n",
    "        # 128-d features\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc2_bn = nn.BatchNorm1d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2_bn(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv3_bn(self.conv3(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = F.relu(self.fc2_bn(self.fc2(x)))\n",
    "        return x\n",
    "\n",
    "\n",
    "class JigsawNet(nn.Module):\n",
    "    \"\"\"\n",
    "    A neural network that solves 2x2 jigsaw puzzles.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sinkhorn_iter=0):\n",
    "        super().__init__()\n",
    "        self.conv_net = SimpleConvNet()\n",
    "        self.fc1 = nn.Linear(128 * 4, 256)\n",
    "        self.fc1_bn = nn.BatchNorm1d(256)\n",
    "        # 4 x 4 assigment matrix\n",
    "        self.fc2 = nn.Linear(256, 16)\n",
    "        self.sinkhorn_iter = sinkhorn_iter\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Split the input into four pieces and pass them into the\n",
    "        # same convolutional neural network.\n",
    "        x0 = self.conv_net(x[:, :, 0:16, 0:16])\n",
    "        x1 = self.conv_net(x[:, :, 16:32, 0:16])\n",
    "        x2 = self.conv_net(x[:, :, 16:32, 16:32])\n",
    "        x3 = self.conv_net(x[:, :, 0:16, 16:32])\n",
    "        # Cat\n",
    "        x = torch.cat([x0, x1, x2, x3], dim=1)\n",
    "        # Dense layer\n",
    "        x = F.dropout(x, p=0.1, training=self.training)\n",
    "        x = F.relu(self.fc1_bn(self.fc1(x)))\n",
    "        x = F.sigmoid(self.fc2(x))\n",
    "        if self.sinkhorn_iter > 0:\n",
    "            x = x.view(-1, 4, 4)\n",
    "            x = sinkhorn(x, self.sinkhorn_iter)\n",
    "            x = x.view(-1, 16)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# CIFAR images are 32x32\n",
    "# We consider a simple 2x2 jigsaw puzzle.\n",
    "# 0 1\n",
    "# 3 2\n",
    "perm_inds = [(0, 0), (16, 0), (16, 16), (0, 16)]\n",
    "# Simply maps each pixel to [-1, 1]\n",
    "img_mean = 0.5\n",
    "img_std = 0.5\n",
    "    \n",
    "def permute2x2(images):\n",
    "    \"\"\"\n",
    "    Splits the images into 2x2 = 4 pieces and randomly permutes the pieces.\n",
    "    \"\"\"\n",
    "    p_images = torch.FloatTensor(images.size())\n",
    "    perms = torch.LongTensor(images.size()[0], 4)\n",
    "    for i in range(images.size()[0]):\n",
    "        p = torch.randperm(4)\n",
    "        for j in range(4):\n",
    "            sr, sc = perm_inds[j]\n",
    "            tr, tc = perm_inds[p[j]]\n",
    "            p_images[i, :, tr:tr+16, tc:tc+16] = images[i, :, sr:sr+16, sc:sc+16]\n",
    "        perms[i,:] = p\n",
    "    return(p_images, perms)\n",
    "\n",
    "def restore2x2(p_images, perms):\n",
    "    \"\"\"\n",
    "    Restores the original image from the pieces and the given permutation.\n",
    "    \"\"\"\n",
    "    images = torch.FloatTensor(p_images.size())\n",
    "    for i in range(images.size()[0]):\n",
    "        for j in range(4):\n",
    "            sr, sc = perm_inds[j]\n",
    "            tr, tc = perm_inds[perms[i, j]]\n",
    "            images[i, :, sr:sr+16, sc:sc+16] = p_images[i, :, tr:tr+16, tc:tc+16]\n",
    "    return images\n",
    "\n",
    "def perm2vecmat2x2(perms):\n",
    "    \"\"\"\n",
    "    Converts permutation vectors to vectorized assignment matrices.\n",
    "    \"\"\"\n",
    "    n = perms.size()[0]\n",
    "    mat = torch.zeros(n, 4, 4)\n",
    "    for i in range(n):\n",
    "        for k in range(4):\n",
    "            mat[i, k, perms[i, k]] = 1.\n",
    "    return mat.view(n, -1)\n",
    "\n",
    "def vecmat2perm2x2(x):\n",
    "    \"\"\"\n",
    "    Converts vectorized assignment matrices back to permutation vectors.\n",
    "    \"\"\"\n",
    "    n = x.size()[0]\n",
    "    x = x.view(n, 4, 4)\n",
    "    _, ind = x.max(2)\n",
    "    return ind\n",
    "    \n",
    "def imshow(img, title=None):\n",
    "    \"\"\"\n",
    "    Displays a torch image.\n",
    "    \"\"\"\n",
    "    img = img * img_std + img_mean\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "batch_size = 32\n",
    "dataset_dir = './data'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((img_mean, img_mean, img_mean), (img_std, img_std, img_std))\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR100(root=dataset_dir, train=True, download=True, transform=transform)\n",
    "sample_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "dataiter = iter(sample_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "p_images, perms = permute2x2(images)\n",
    "\n",
    "# Check the implementation of per2vecmat and vecmat2perm.\n",
    "assert(vecmat2perm2x2(perm2vecmat2x2(perms)).equal(perms))\n",
    "\n",
    "# Show permuted images.\n",
    "plt.figure()\n",
    "imshow(torchvision.utils.make_grid(p_images))\n",
    "# Show restored images.\n",
    "plt.figure()\n",
    "imshow(torchvision.utils.make_grid(restore2x2(p_images, perms)))\n",
    "\n",
    "validation_ratio = 0.1\n",
    "total = len(train_set)\n",
    "ind = list(range(total))\n",
    "n_train = int(np.floor((1. - validation_ratio) * total))\n",
    "train_ind, validation_ind = ind[:n_train], ind[n_train:]\n",
    "train_subsampler = torch.utils.data.sampler.SubsetRandomSampler(train_ind)\n",
    "validation_subsampler = torch.utils.data.sampler.SubsetRandomSampler(validation_ind)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, sampler=train_subsampler, num_workers=0)\n",
    "validation_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, sampler=validation_subsampler, num_workers=0)\n",
    "\n",
    "print('Number of training batches: {}'.format(len(train_loader)))\n",
    "print('Number of validation batches: {}'.format(len(validation_loader)))\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR100(root=dataset_dir, train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test helper\n",
    "def compute_acc(p_pred, p_true, average=True):\n",
    "    \"\"\"\n",
    "    We require that the location of all four pieces are correctly predicted.\n",
    "    Note: this function is compatible with GPU tensors.\n",
    "    \"\"\"\n",
    "    # Remember to cast to float.\n",
    "    n = torch.sum((torch.sum(p_pred == p_true, 1) == 4).float())\n",
    "    if average:\n",
    "        return n / p_pred.size()[0]\n",
    "    else:\n",
    "        return n\n",
    "\n",
    "\n",
    "# Training process\n",
    "def train_model(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    validation_loader,\n",
    "    n_epochs=40,\n",
    "    save_file_name=None,\n",
    "):\n",
    "    loss_history = []\n",
    "    val_loss_history = []\n",
    "    acc_history = []\n",
    "    val_acc_history = []\n",
    "    for epoch in range(n_epochs):\n",
    "        with tqdm_notebook(\n",
    "            total=len(train_loader),\n",
    "            desc=\"Epoch {}\".format(epoch + 1),\n",
    "            unit=\"b\",\n",
    "            leave=False,\n",
    "        ) as pbar:\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            n_correct_pred = 0\n",
    "            n_samples = 0\n",
    "            for i, data in enumerate(train_loader, 0):\n",
    "                inputs, _ = data\n",
    "                x_in, perms = permute2x2(inputs)\n",
    "                y_in = perm2vecmat2x2(perms)\n",
    "                n_samples += inputs.size()[0]\n",
    "                if is_cuda_available:\n",
    "                    x_in, y_in = Variable(x_in.cuda()), Variable(y_in.cuda())\n",
    "                    perms = Variable(perms.cuda())\n",
    "                else:\n",
    "                    x_in, y_in = Variable(x_in), Variable(y_in)\n",
    "                    perms = Variable(perms)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x_in)\n",
    "                n_correct_pred += compute_acc(\n",
    "                    vecmat2perm2x2(outputs), perms, False\n",
    "                ).data[0]\n",
    "                loss = criterion(outputs, y_in)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.data[0] * x_in.size()[0]\n",
    "                pbar.update(1)\n",
    "            loss_history.append(running_loss / n_samples)\n",
    "            acc_history.append(n_correct_pred / n_samples)\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            running_loss = 0.0\n",
    "            n_correct_pred = 0\n",
    "            n_samples = 0\n",
    "            for i, data in enumerate(validation_loader, 0):\n",
    "                inputs, _ = data\n",
    "                x_in, perms = permute2x2(inputs)\n",
    "                y_in = perm2vecmat2x2(perms)\n",
    "                n_samples += inputs.size()[0]\n",
    "                if is_cuda_available:\n",
    "                    x_in, y_in = Variable(x_in.cuda()), Variable(y_in.cuda())\n",
    "                    perms = Variable(perms.cuda())\n",
    "                else:\n",
    "                    x_in, y_in = Variable(x_in), Variable(y_in)\n",
    "                    perms = Variable(perms)\n",
    "                outputs = model(x_in)\n",
    "                n_correct_pred += compute_acc(\n",
    "                    vecmat2perm2x2(outputs), perms, False\n",
    "                ).data[0]\n",
    "                loss = criterion(outputs, y_in)\n",
    "                running_loss += loss.data[0] * x_in.size()[0]\n",
    "            val_loss_history.append(running_loss / n_samples)\n",
    "            val_acc_history.append(n_correct_pred / n_samples)\n",
    "\n",
    "            # Update the progress bar.\n",
    "            print(\n",
    "                \"Epoch {0:03d}: loss={1:.4f}, val_loss={2:.4f}, acc={3:.2%}, val_acc={4:.2%}\".format(\n",
    "                    epoch + 1,\n",
    "                    loss_history[-1],\n",
    "                    val_loss_history[-1],\n",
    "                    acc_history[-1],\n",
    "                    val_acc_history[-1],\n",
    "                )\n",
    "            )\n",
    "    print(\"Training completed\")\n",
    "    history = {\n",
    "        \"loss\": loss_history,\n",
    "        \"val_loss\": val_loss_history,\n",
    "        \"acc\": acc_history,\n",
    "        \"val_acc\": val_acc_history,\n",
    "    }\n",
    "    # Save the model when requested.\n",
    "    if save_file_name is not None:\n",
    "        torch.save(\n",
    "            {\n",
    "                \"history\": history,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "            },\n",
    "            save_file_name,\n",
    "        )\n",
    "    return history\n",
    "\n",
    "\n",
    "# Test process\n",
    "# Compute the accuracy\n",
    "def test_model(model, test_loader):\n",
    "    running_acc = 0.0\n",
    "    n = 0\n",
    "    model.eval()\n",
    "    for i, data in enumerate(test_loader, 0):\n",
    "        inputs, _ = data\n",
    "        x_in, perms = permute2x2(inputs)\n",
    "        y_in = perm2vecmat2x2(perms)\n",
    "        if is_cuda_available:\n",
    "            x_in, y_in = Variable(x_in.cuda()), Variable(y_in.cuda())\n",
    "        else:\n",
    "            x_in, y_in = Variable(x_in), Variable(y_in)\n",
    "        pred = model(x_in)\n",
    "        perms_pred = vecmat2perm2x2(pred.cpu().data)\n",
    "        running_acc += compute_acc(perms_pred, perms, False)\n",
    "        n += x_in.size()[0]\n",
    "    acc = running_acc / n\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "sinkhorn_iter = 5\n",
    "\n",
    "# Create the neural network.\n",
    "model = JigsawNet(sinkhorn_iter=sinkhorn_iter)\n",
    "is_cuda_available = torch.cuda.is_available()\n",
    "if is_cuda_available:\n",
    "    model.cuda()\n",
    "\n",
    "n_params = 0\n",
    "for p in model.parameters():\n",
    "    n_params += np.prod(p.size())\n",
    "print(\"# of parameters: {}\".format(n_params))\n",
    "\n",
    "# We use binary cross-entropy loss here.\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Train\n",
    "save_file_name = \"jigsaw_cifar100_e{}_s{}.pk\".format(n_epochs, sinkhorn_iter)\n",
    "history = train_model(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    validation_loader,\n",
    "    n_epochs=n_epochs,\n",
    "    save_file_name=save_file_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history[\"loss\"])\n",
    "plt.plot(history[\"val_loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(history[\"acc\"])\n",
    "plt.plot(history[\"val_acc\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "print(\"Training accuracy: {}\".format(test_model(model, train_loader)))\n",
    "print(\"Validation accuracy: {}\".format(test_model(model, validation_loader)))\n",
    "print(\"Test accuracy: {}\".format(test_model(model, test_loader)))\n",
    "# Here training accuracy will be higher because dropout is disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us try some test images.\n",
    "test_data_iter = iter(test_loader)\n",
    "test_images, _ = test_data_iter.next()\n",
    "p_images, perms = permute2x2(test_images)\n",
    "\n",
    "# Show permuted images.\n",
    "plt.figure()\n",
    "imshow(torchvision.utils.make_grid(p_images))\n",
    "plt.title(\"Inputs\")\n",
    "plt.show()\n",
    "\n",
    "model.eval()\n",
    "if is_cuda_available:\n",
    "    pred = model(Variable(p_images.cuda()))\n",
    "else:\n",
    "    pred = model(Variable(p_images))\n",
    "perms_pred = vecmat2perm2x2(pred.cpu().data)\n",
    "\n",
    "# Show restored images.\n",
    "plt.figure()\n",
    "imshow(torchvision.utils.make_grid(restore2x2(p_images, perms_pred)))\n",
    "plt.title(\"Restored\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
