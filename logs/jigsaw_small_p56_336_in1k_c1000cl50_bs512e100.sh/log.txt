batch_size: 128
epochs: 100
bce_loss: True
unscale_lr: True
rec: False
freeze: False
model: jigsaw_small_patch56_336
input_size: 336
permcls: 1000
drop: 0.0
drop_path: 0.1
model_ema: True
model_ema_decay: 0.99996
model_ema_force_cpu: False
opt: adamw
opt_eps: 1e-08
opt_betas: None
clip_grad: None
momentum: 0.9
weight_decay: 0.05
sched: cosine
lr: 0.001
lr_noise: None
lr_noise_pct: 0.67
lr_noise_std: 1.0
warmup_lr: 1e-06
min_lr: 1e-08
decay_epochs: 30
warmup_epochs: 0
cooldown_epochs: 10
patience_epochs: 10
decay_rate: 0.1
color_jitter: 0.3
aa: rand-m9-mstd0.5-inc1
smoothing: None
train_interpolation: bicubic
repeated_aug: True
train_mode: True
ThreeAugment: False
src: False
reprob: 0.25
remode: pixel
recount: 1
resplit: False
mixup: 0.0
cutmix: 0.0
cutmix_minmax: None
mixup_prob: 1.0
mixup_switch_prob: 0.5
mixup_mode: batch
teacher_model: regnety_160
teacher_path: 
distillation_type: none
distillation_alpha: 0.5
distillation_tau: 1.0
finetune: ./outputs/in1k_jigsaw_small_patch56_336_e30_c1000/best_checkpoint.pth
attn_only: False
data_path: /workspace/data/imagenet/ILSVRC/Data/CLS-LOC
data_set: IMNET
nb_classes: 50
inat_category: name
output_dir: ./outputs/jigsaw_small_p56_336_in1k_c1000cl50_bs512e100.sh
log_dir: ./logs/jigsaw_small_p56_336_in1k_c1000cl50_bs512e100.sh
device: cuda
seed: 0
resume: 
start_epoch: 0
eval: False
eval_crop_ratio: 0.875
dist_eval: False
num_workers: 10
pin_mem: True
world_size: 4
dist_url: env://
local_rank: 0
use_jigsaw: True
use_cls: True
lambda_rec: 0.1
mask_ratio: 0.0
rank: 0
gpu: 0
distributed: True
dist_backend: nccl

Evaluation on epoch 0: loss: 22.259, acc1_cls: 1.907, acc5_cls: 10.593
{"train_lr": 0.001, "train_loss_total": 4.215037286281586, "train_loss_cls": 4.215037286281586, "train_acc1_cls": 6.005859375, "train_acc5_cls": 19.140625, "epoch": 0, "n_parameters": 319077484}
Evaluation on epoch 1: loss: 17.269, acc1_cls: 1.907, acc5_cls: 11.653
{"train_lr": 0.001, "train_loss_total": 4.195353984832764, "train_loss_cls": 4.195353984832764, "train_acc1_cls": 6.982421875, "train_acc5_cls": 22.65625, "epoch": 1, "n_parameters": 319077484}
Evaluation on epoch 2: loss: 10.283, acc1_cls: 1.907, acc5_cls: 11.653
{"train_lr": 0.000999753282650064, "train_loss_total": 3.96928334236145, "train_loss_cls": 3.96928334236145, "train_acc1_cls": 8.49609375, "train_acc5_cls": 25.87890625, "epoch": 2, "n_parameters": 319077484}
Evaluation on epoch 3: loss: 5.997, acc1_cls: 2.119, acc5_cls: 11.017
{"train_lr": 0.0009990133740804936, "train_loss_total": 3.953616142272949, "train_loss_cls": 3.953616142272949, "train_acc1_cls": 7.275390625, "train_acc5_cls": 25.87890625, "epoch": 3, "n_parameters": 319077484}
Evaluation on epoch 4: loss: 7.933, acc1_cls: 2.119, acc5_cls: 10.593
{"train_lr": 0.000997781004491717, "train_loss_total": 3.887396812438965, "train_loss_cls": 3.887396812438965, "train_acc1_cls": 10.693359375, "train_acc5_cls": 30.908203125, "epoch": 4, "n_parameters": 319077484}
Evaluation on epoch 5: loss: 6.947, acc1_cls: 2.754, acc5_cls: 10.381
{"train_lr": 0.0009960573900837325, "train_loss_total": 3.7816578149795532, "train_loss_cls": 3.7816578149795532, "train_acc1_cls": 15.185546875, "train_acc5_cls": 32.470703125, "epoch": 5, "n_parameters": 319077484}
Evaluation on epoch 6: loss: 8.316, acc1_cls: 2.119, acc5_cls: 16.102
{"train_lr": 0.000993844231855866, "train_loss_total": 3.6723233461380005, "train_loss_cls": 3.6723233461380005, "train_acc1_cls": 17.919921875, "train_acc5_cls": 35.05859375, "epoch": 6, "n_parameters": 319077484}
Evaluation on epoch 7: loss: 6.447, acc1_cls: 5.720, acc5_cls: 14.407
{"train_lr": 0.0009911437139280908, "train_loss_total": 3.442199945449829, "train_loss_cls": 3.442199945449829, "train_acc1_cls": 23.14453125, "train_acc5_cls": 42.919921875, "epoch": 7, "n_parameters": 319077484}
Evaluation on epoch 8: loss: 8.192, acc1_cls: 2.542, acc5_cls: 16.737
{"train_lr": 0.000987958501385564, "train_loss_total": 3.293759047985077, "train_loss_cls": 3.293759047985077, "train_acc1_cls": 26.708984375, "train_acc5_cls": 45.751953125, "epoch": 8, "n_parameters": 319077484}
Evaluation on epoch 9: loss: 7.081, acc1_cls: 3.602, acc5_cls: 12.288
{"train_lr": 0.00098429173764851, "train_loss_total": 3.1030824780464172, "train_loss_cls": 3.1030824780464172, "train_acc1_cls": 31.93359375, "train_acc5_cls": 53.271484375, "epoch": 9, "n_parameters": 319077484}
Evaluation on epoch 10: loss: 6.362, acc1_cls: 4.661, acc5_cls: 16.102
{"train_lr": 0.0009801470413700432, "train_loss_total": 3.0142619013786316, "train_loss_cls": 3.0142619013786316, "train_acc1_cls": 34.228515625, "train_acc5_cls": 57.2265625, "epoch": 10, "n_parameters": 319077484}
Evaluation on epoch 11: loss: 6.522, acc1_cls: 4.025, acc5_cls: 18.644
{"train_lr": 0.0009755285028649954, "train_loss_total": 2.819252163171768, "train_loss_cls": 2.819252163171768, "train_acc1_cls": 41.89453125, "train_acc5_cls": 60.83984375, "epoch": 11, "n_parameters": 319077484}
Evaluation on epoch 12: loss: 6.738, acc1_cls: 6.780, acc5_cls: 18.432
{"train_lr": 0.0009704406800732681, "train_loss_total": 2.5342160165309906, "train_loss_cls": 2.5342160165309906, "train_acc1_cls": 47.16796875, "train_acc5_cls": 70.41015625, "epoch": 12, "n_parameters": 319077484}
Evaluation on epoch 13: loss: 6.571, acc1_cls: 8.898, acc5_cls: 17.373
{"train_lr": 0.0009648885940616963, "train_loss_total": 2.5028473138809204, "train_loss_cls": 2.5028473138809204, "train_acc1_cls": 49.560546875, "train_acc5_cls": 69.23828125, "epoch": 13, "n_parameters": 319077484}
Evaluation on epoch 14: loss: 5.853, acc1_cls: 9.534, acc5_cls: 20.127
{"train_lr": 0.0009588777240688622, "train_loss_total": 2.3884113430976868, "train_loss_cls": 2.3884113430976868, "train_acc1_cls": 53.90625, "train_acc5_cls": 71.044921875, "epoch": 14, "n_parameters": 319077484}
Evaluation on epoch 15: loss: 5.142, acc1_cls: 12.500, acc5_cls: 22.881
{"train_lr": 0.0009524140020977476, "train_loss_total": 2.219634562730789, "train_loss_cls": 2.219634562730789, "train_acc1_cls": 57.080078125, "train_acc5_cls": 75.537109375, "epoch": 15, "n_parameters": 319077484}
Evaluation on epoch 16: loss: 4.620, acc1_cls: 16.102, acc5_cls: 28.178
{"train_lr": 0.0009455038070615631, "train_loss_total": 2.0861189365386963, "train_loss_cls": 2.0861189365386963, "train_acc1_cls": 62.20703125, "train_acc5_cls": 78.80859375, "epoch": 16, "n_parameters": 319077484}
Evaluation on epoch 17: loss: 4.653, acc1_cls: 11.653, acc5_cls: 31.356
{"train_lr": 0.0009381539584885317, "train_loss_total": 1.8845852762460709, "train_loss_cls": 1.8845852762460709, "train_acc1_cls": 68.017578125, "train_acc5_cls": 83.154296875, "epoch": 17, "n_parameters": 319077484}
Evaluation on epoch 18: loss: 4.977, acc1_cls: 8.475, acc5_cls: 35.169
{"train_lr": 0.0009303717097918369, "train_loss_total": 1.8031930103898048, "train_loss_cls": 1.8031930103898048, "train_acc1_cls": 70.166015625, "train_acc5_cls": 83.59375, "epoch": 18, "n_parameters": 319077484}
Evaluation on epoch 19: loss: 5.287, acc1_cls: 6.568, acc5_cls: 42.373
{"train_lr": 0.0009221647411113801, "train_loss_total": 1.675808660686016, "train_loss_cls": 1.675808660686016, "train_acc1_cls": 72.314453125, "train_acc5_cls": 86.181640625, "epoch": 19, "n_parameters": 319077484}
Evaluation on epoch 20: loss: 5.129, acc1_cls: 6.144, acc5_cls: 45.551
{"train_lr": 0.0009135411517344096, "train_loss_total": 1.5460136160254478, "train_loss_cls": 1.5460136160254478, "train_acc1_cls": 75.1953125, "train_acc5_cls": 88.818359375, "epoch": 20, "n_parameters": 319077484}
Evaluation on epoch 21: loss: 4.596, acc1_cls: 6.568, acc5_cls: 48.517
{"train_lr": 0.000904509452102502, "train_loss_total": 1.4218531772494316, "train_loss_cls": 1.4218531772494316, "train_acc1_cls": 78.955078125, "train_acc5_cls": 89.94140625, "epoch": 21, "n_parameters": 319077484}
Evaluation on epoch 22: loss: 3.566, acc1_cls: 18.008, acc5_cls: 46.398
{"train_lr": 0.0008950785554127834, "train_loss_total": 1.2853076681494713, "train_loss_cls": 1.2853076681494713, "train_acc1_cls": 82.666015625, "train_acc5_cls": 92.333984375, "epoch": 22, "n_parameters": 319077484}
Evaluation on epoch 23: loss: 3.093, acc1_cls: 27.331, acc5_cls: 48.941
{"train_lr": 0.0008852577688216809, "train_loss_total": 1.1479252725839615, "train_loss_cls": 1.1479252725839615, "train_acc1_cls": 84.1796875, "train_acc5_cls": 93.017578125, "epoch": 23, "n_parameters": 319077484}
Evaluation on epoch 24: loss: 2.735, acc1_cls: 35.169, acc5_cls: 59.322
{"train_lr": 0.0008750567842598818, "train_loss_total": 1.0363399311900139, "train_loss_cls": 1.0363399311900139, "train_acc1_cls": 87.98828125, "train_acc5_cls": 95.458984375, "epoch": 24, "n_parameters": 319077484}
Evaluation on epoch 25: loss: 2.753, acc1_cls: 34.110, acc5_cls: 59.534
{"train_lr": 0.0008644856688675688, "train_loss_total": 0.9707394167780876, "train_loss_cls": 0.9707394167780876, "train_acc1_cls": 87.79296875, "train_acc5_cls": 95.1171875, "epoch": 25, "n_parameters": 319077484}
Evaluation on epoch 26: loss: 2.656, acc1_cls: 37.712, acc5_cls: 59.322
{"train_lr": 0.0008535548550593679, "train_loss_total": 0.8622654788196087, "train_loss_cls": 0.8622654788196087, "train_acc1_cls": 89.84375, "train_acc5_cls": 96.09375, "epoch": 26, "n_parameters": 319077484}
Evaluation on epoch 27: loss: 2.421, acc1_cls: 47.246, acc5_cls: 64.831
{"train_lr": 0.0008422751302288148, "train_loss_total": 0.7805328033864498, "train_loss_cls": 0.7805328033864498, "train_acc1_cls": 90.8203125, "train_acc5_cls": 97.021484375, "epoch": 27, "n_parameters": 319077484}
Evaluation on epoch 28: loss: 2.406, acc1_cls: 48.093, acc5_cls: 66.737
{"train_lr": 0.0008306576261024994, "train_loss_total": 0.7225649692118168, "train_loss_cls": 0.7225649692118168, "train_acc1_cls": 91.259765625, "train_acc5_cls": 97.94921875, "epoch": 28, "n_parameters": 319077484}
Evaluation on epoch 29: loss: 2.216, acc1_cls: 53.390, acc5_cls: 68.220
{"train_lr": 0.0008187138077543962, "train_loss_total": 0.6518296301364899, "train_loss_cls": 0.6518296301364899, "train_acc1_cls": 93.701171875, "train_acc5_cls": 98.486328125, "epoch": 29, "n_parameters": 319077484}
Evaluation on epoch 30: loss: 2.296, acc1_cls: 46.398, acc5_cls: 65.678
{"train_lr": 0.0008064554622912201, "train_loss_total": 0.5849881544709206, "train_loss_cls": 0.5849881544709206, "train_acc1_cls": 94.775390625, "train_acc5_cls": 98.779296875, "epoch": 30, "n_parameters": 319077484}
Evaluation on epoch 31: loss: 2.296, acc1_cls: 40.042, acc5_cls: 67.161
{"train_lr": 0.0007938946872199753, "train_loss_total": 0.5283357333391905, "train_loss_cls": 0.5283357333391905, "train_acc1_cls": 95.361328125, "train_acc5_cls": 98.779296875, "epoch": 31, "n_parameters": 319077484}
Evaluation on epoch 32: loss: 2.084, acc1_cls: 56.568, acc5_cls: 73.729
{"train_lr": 0.0007810438785091762, "train_loss_total": 0.5152780897915363, "train_loss_cls": 0.5152780897915363, "train_acc1_cls": 95.068359375, "train_acc5_cls": 98.92578125, "epoch": 32, "n_parameters": 319077484}
Evaluation on epoch 33: loss: 2.113, acc1_cls: 55.720, acc5_cls: 69.703
{"train_lr": 0.0007679157183555235, "train_loss_total": 0.46352544240653515, "train_loss_cls": 0.46352544240653515, "train_acc1_cls": 95.947265625, "train_acc5_cls": 99.4140625, "epoch": 33, "n_parameters": 319077484}
Evaluation on epoch 34: loss: 2.034, acc1_cls: 58.051, acc5_cls: 72.881
{"train_lr": 0.0007545231626681071, "train_loss_total": 0.42630889266729355, "train_loss_cls": 0.42630889266729355, "train_acc1_cls": 96.77734375, "train_acc5_cls": 99.31640625, "epoch": 34, "n_parameters": 319077484}
Evaluation on epoch 35: loss: 2.132, acc1_cls: 51.271, acc5_cls: 68.432
{"train_lr": 0.0007408794282824872, "train_loss_total": 0.356787595897913, "train_loss_cls": 0.356787595897913, "train_acc1_cls": 97.314453125, "train_acc5_cls": 99.4140625, "epoch": 35, "n_parameters": 319077484}
Evaluation on epoch 36: loss: 2.013, acc1_cls: 55.297, acc5_cls: 72.458
{"train_lr": 0.0007269979799172748, "train_loss_total": 0.35150998272001743, "train_loss_cls": 0.35150998272001743, "train_acc1_cls": 97.705078125, "train_acc5_cls": 99.658203125, "epoch": 36, "n_parameters": 319077484}
Evaluation on epoch 37: loss: 2.005, acc1_cls: 53.814, acc5_cls: 75.636
{"train_lr": 0.0007128925168860787, "train_loss_total": 0.3268113490194082, "train_loss_cls": 0.3268113490194082, "train_acc1_cls": 97.802734375, "train_acc5_cls": 99.70703125, "epoch": 37, "n_parameters": 319077484}
Evaluation on epoch 38: loss: 1.905, acc1_cls: 62.288, acc5_cls: 76.059
{"train_lr": 0.0006985769595779372, "train_loss_total": 0.32975633814930916, "train_loss_cls": 0.32975633814930916, "train_acc1_cls": 97.65625, "train_acc5_cls": 99.4140625, "epoch": 38, "n_parameters": 319077484}
Evaluation on epoch 39: loss: 1.790, acc1_cls: 63.983, acc5_cls: 76.483
{"train_lr": 0.0006840654357195757, "train_loss_total": 0.3092314787209034, "train_loss_cls": 0.3092314787209034, "train_acc1_cls": 98.33984375, "train_acc5_cls": 99.90234375, "epoch": 39, "n_parameters": 319077484}
Evaluation on epoch 40: loss: 1.801, acc1_cls: 60.593, acc5_cls: 79.237
{"train_lr": 0.0006693722664330447, "train_loss_total": 0.28267583064734936, "train_loss_cls": 0.28267583064734936, "train_acc1_cls": 98.291015625, "train_acc5_cls": 99.853515625, "epoch": 40, "n_parameters": 319077484}
Evaluation on epoch 41: loss: 1.767, acc1_cls: 63.983, acc5_cls: 78.178
{"train_lr": 0.000654511952102502, "train_loss_total": 0.2701919684186578, "train_loss_cls": 0.2701919684186578, "train_acc1_cls": 98.6328125, "train_acc5_cls": 100.0, "epoch": 41, "n_parameters": 319077484}
Evaluation on epoch 42: loss: 1.844, acc1_cls: 64.831, acc5_cls: 76.271
{"train_lr": 0.0006394991580640846, "train_loss_total": 0.2788350349292159, "train_loss_cls": 0.2788350349292159, "train_acc1_cls": 98.388671875, "train_acc5_cls": 99.90234375, "epoch": 42, "n_parameters": 319077484}
Evaluation on epoch 43: loss: 1.830, acc1_cls: 64.195, acc5_cls: 78.178
{"train_lr": 0.0006243487001329916, "train_loss_total": 0.2422128189355135, "train_loss_cls": 0.2422128189355135, "train_acc1_cls": 98.974609375, "train_acc5_cls": 99.755859375, "epoch": 43, "n_parameters": 319077484}
Evaluation on epoch 44: loss: 1.911, acc1_cls: 62.500, acc5_cls: 74.788
{"train_lr": 0.0006090755299820645, "train_loss_total": 0.2643721839413047, "train_loss_cls": 0.2643721839413047, "train_acc1_cls": 97.998046875, "train_acc5_cls": 99.8046875, "epoch": 44, "n_parameters": 319077484}
Evaluation on epoch 45: loss: 1.849, acc1_cls: 61.864, acc5_cls: 76.695
{"train_lr": 0.0005936947203862895, "train_loss_total": 0.24492335598915815, "train_loss_cls": 0.24492335598915815, "train_acc1_cls": 98.681640625, "train_acc5_cls": 99.755859375, "epoch": 45, "n_parameters": 319077484}
Evaluation on epoch 46: loss: 1.758, acc1_cls: 58.263, acc5_cls: 78.814
{"train_lr": 0.0005782214503477904, "train_loss_total": 0.22820709832012653, "train_loss_cls": 0.22820709832012653, "train_acc1_cls": 98.779296875, "train_acc5_cls": 99.951171875, "epoch": 46, "n_parameters": 319077484}
Evaluation on epoch 47: loss: 1.704, acc1_cls: 64.195, acc5_cls: 77.754
{"train_lr": 0.0005626709901159846, "train_loss_total": 0.2321491027250886, "train_loss_cls": 0.2321491027250886, "train_acc1_cls": 98.779296875, "train_acc5_cls": 99.951171875, "epoch": 47, "n_parameters": 319077484}
Evaluation on epoch 48: loss: 1.738, acc1_cls: 64.619, acc5_cls: 78.602
{"train_lr": 0.0005470586861176907, "train_loss_total": 0.19187785312533379, "train_loss_cls": 0.19187785312533379, "train_acc1_cls": 99.4140625, "train_acc5_cls": 99.951171875, "epoch": 48, "n_parameters": 319077484}
Evaluation on epoch 49: loss: 1.748, acc1_cls: 65.678, acc5_cls: 81.356
{"train_lr": 0.0005313999458120592, "train_loss_total": 0.20922535937279463, "train_loss_cls": 0.20922535937279463, "train_acc1_cls": 98.779296875, "train_acc5_cls": 99.853515625, "epoch": 49, "n_parameters": 319077484}
Evaluation on epoch 50: loss: 1.764, acc1_cls: 63.983, acc5_cls: 80.720
{"train_lr": 0.0005157102224852689, "train_loss_total": 0.19373134430497885, "train_loss_cls": 0.19373134430497885, "train_acc1_cls": 99.267578125, "train_acc5_cls": 99.90234375, "epoch": 50, "n_parameters": 319077484}
Evaluation on epoch 51: loss: 1.818, acc1_cls: 63.771, acc5_cls: 77.754
{"train_lr": 0.0005000050000000001, "train_loss_total": 0.1991497315466404, "train_loss_cls": 0.1991497315466404, "train_acc1_cls": 99.31640625, "train_acc5_cls": 99.853515625, "epoch": 51, "n_parameters": 319077484}
Evaluation on epoch 52: loss: 1.816, acc1_cls: 65.042, acc5_cls: 78.178
{"train_lr": 0.0004842997775147313, "train_loss_total": 0.20304157864302397, "train_loss_cls": 0.20304157864302397, "train_acc1_cls": 99.12109375, "train_acc5_cls": 99.951171875, "epoch": 52, "n_parameters": 319077484}
Evaluation on epoch 53: loss: 1.804, acc1_cls: 64.619, acc5_cls: 77.754
{"train_lr": 0.000468610054187941, "train_loss_total": 0.19217620510607958, "train_loss_cls": 0.19217620510607958, "train_acc1_cls": 99.267578125, "train_acc5_cls": 100.0, "epoch": 53, "n_parameters": 319077484}
Evaluation on epoch 54: loss: 1.826, acc1_cls: 64.619, acc5_cls: 76.271
{"train_lr": 0.00045295131388230946, "train_loss_total": 0.19223543349653482, "train_loss_cls": 0.19223543349653482, "train_acc1_cls": 99.12109375, "train_acc5_cls": 99.90234375, "epoch": 54, "n_parameters": 319077484}
Evaluation on epoch 55: loss: 1.824, acc1_cls: 64.407, acc5_cls: 74.788
{"train_lr": 0.0004373390098840158, "train_loss_total": 0.20568079128861427, "train_loss_cls": 0.20568079128861427, "train_acc1_cls": 99.072265625, "train_acc5_cls": 99.951171875, "epoch": 55, "n_parameters": 319077484}
Evaluation on epoch 56: loss: 1.886, acc1_cls: 57.627, acc5_cls: 75.000
{"train_lr": 0.0004217885496522098, "train_loss_total": 0.1956142745912075, "train_loss_cls": 0.1956142745912075, "train_acc1_cls": 99.0234375, "train_acc5_cls": 99.90234375, "epoch": 56, "n_parameters": 319077484}
Evaluation on epoch 57: loss: 1.802, acc1_cls: 63.136, acc5_cls: 77.754
{"train_lr": 0.00040631527961371063, "train_loss_total": 0.186380160972476, "train_loss_cls": 0.186380160972476, "train_acc1_cls": 99.31640625, "train_acc5_cls": 99.90234375, "epoch": 57, "n_parameters": 319077484}
Evaluation on epoch 58: loss: 1.739, acc1_cls: 68.220, acc5_cls: 79.237
{"train_lr": 0.0003909344700179359, "train_loss_total": 0.15837433421984315, "train_loss_cls": 0.15837433421984315, "train_acc1_cls": 99.462890625, "train_acc5_cls": 99.90234375, "epoch": 58, "n_parameters": 319077484}
Evaluation on epoch 59: loss: 1.703, acc1_cls: 67.797, acc5_cls: 79.449
{"train_lr": 0.0003756612998670084, "train_loss_total": 0.1783057302236557, "train_loss_cls": 0.1783057302236557, "train_acc1_cls": 99.267578125, "train_acc5_cls": 99.951171875, "epoch": 59, "n_parameters": 319077484}
Evaluation on epoch 60: loss: 1.723, acc1_cls: 66.102, acc5_cls: 80.085
{"train_lr": 0.00036051084193591565, "train_loss_total": 0.19558138120919466, "train_loss_cls": 0.19558138120919466, "train_acc1_cls": 98.92578125, "train_acc5_cls": 99.90234375, "epoch": 60, "n_parameters": 319077484}
Evaluation on epoch 61: loss: 1.734, acc1_cls: 65.890, acc5_cls: 81.992
{"train_lr": 0.0003454980478974983, "train_loss_total": 0.16494411788880825, "train_loss_cls": 0.16494411788880825, "train_acc1_cls": 99.51171875, "train_acc5_cls": 100.0, "epoch": 61, "n_parameters": 319077484}
Evaluation on epoch 62: loss: 1.737, acc1_cls: 68.856, acc5_cls: 80.297
{"train_lr": 0.00033063773356695555, "train_loss_total": 0.16639605071395636, "train_loss_cls": 0.16639605071395636, "train_acc1_cls": 99.365234375, "train_acc5_cls": 100.0, "epoch": 62, "n_parameters": 319077484}
Evaluation on epoch 63: loss: 1.771, acc1_cls: 68.644, acc5_cls: 78.814
{"train_lr": 0.0003159445642804246, "train_loss_total": 0.1747995698824525, "train_loss_cls": 0.1747995698824525, "train_acc1_cls": 99.462890625, "train_acc5_cls": 100.0, "epoch": 63, "n_parameters": 319077484}
Evaluation on epoch 64: loss: 1.702, acc1_cls: 69.280, acc5_cls: 79.661
{"train_lr": 0.0003014330404220628, "train_loss_total": 0.16544272378087044, "train_loss_cls": 0.16544272378087044, "train_acc1_cls": 99.365234375, "train_acc5_cls": 99.951171875, "epoch": 64, "n_parameters": 319077484}
Evaluation on epoch 65: loss: 1.656, acc1_cls: 70.551, acc5_cls: 81.992
{"train_lr": 0.0002871174831139215, "train_loss_total": 0.16898311022669077, "train_loss_cls": 0.16898311022669077, "train_acc1_cls": 99.31640625, "train_acc5_cls": 99.951171875, "epoch": 65, "n_parameters": 319077484}
Evaluation on epoch 66: loss: 1.636, acc1_cls: 71.186, acc5_cls: 81.356
{"train_lr": 0.00027301202008272535, "train_loss_total": 0.16398069635033607, "train_loss_cls": 0.16398069635033607, "train_acc1_cls": 99.609375, "train_acc5_cls": 99.951171875, "epoch": 66, "n_parameters": 319077484}
Evaluation on epoch 67: loss: 1.637, acc1_cls: 71.186, acc5_cls: 82.203
{"train_lr": 0.0002591305717175128, "train_loss_total": 0.15413626097142696, "train_loss_cls": 0.15413626097142696, "train_acc1_cls": 99.658203125, "train_acc5_cls": 100.0, "epoch": 67, "n_parameters": 319077484}
Evaluation on epoch 68: loss: 1.666, acc1_cls: 71.398, acc5_cls: 82.415
{"train_lr": 0.0002454868373318931, "train_loss_total": 0.16231969092041254, "train_loss_cls": 0.16231969092041254, "train_acc1_cls": 99.365234375, "train_acc5_cls": 100.0, "epoch": 68, "n_parameters": 319077484}
Evaluation on epoch 69: loss: 1.695, acc1_cls: 70.339, acc5_cls: 80.297
{"train_lr": 0.00023209428164447648, "train_loss_total": 0.16713431617245078, "train_loss_cls": 0.16713431617245078, "train_acc1_cls": 99.4140625, "train_acc5_cls": 100.0, "epoch": 69, "n_parameters": 319077484}
Evaluation on epoch 70: loss: 1.679, acc1_cls: 70.339, acc5_cls: 81.144
{"train_lr": 0.00021896612149082393, "train_loss_total": 0.14610591670498252, "train_loss_cls": 0.14610591670498252, "train_acc1_cls": 99.658203125, "train_acc5_cls": 100.0, "epoch": 70, "n_parameters": 319077484}
Evaluation on epoch 71: loss: 1.690, acc1_cls: 69.280, acc5_cls: 81.780
{"train_lr": 0.00020611531278002496, "train_loss_total": 0.15972694382071495, "train_loss_cls": 0.15972694382071495, "train_acc1_cls": 99.169921875, "train_acc5_cls": 99.951171875, "epoch": 71, "n_parameters": 319077484}
Evaluation on epoch 72: loss: 1.712, acc1_cls: 68.220, acc5_cls: 80.085
{"train_lr": 0.00019355453770877998, "train_loss_total": 0.15205151867121458, "train_loss_cls": 0.15205151867121458, "train_acc1_cls": 99.365234375, "train_acc5_cls": 99.90234375, "epoch": 72, "n_parameters": 319077484}
Evaluation on epoch 73: loss: 1.733, acc1_cls: 65.466, acc5_cls: 80.932
{"train_lr": 0.00018129619224560388, "train_loss_total": 0.1518668793141842, "train_loss_cls": 0.1518668793141842, "train_acc1_cls": 99.462890625, "train_acc5_cls": 100.0, "epoch": 73, "n_parameters": 319077484}
Evaluation on epoch 74: loss: 1.702, acc1_cls: 68.432, acc5_cls: 80.508
{"train_lr": 0.00016935237389750077, "train_loss_total": 0.1463503548875451, "train_loss_cls": 0.1463503548875451, "train_acc1_cls": 99.658203125, "train_acc5_cls": 99.90234375, "epoch": 74, "n_parameters": 319077484}
Evaluation on epoch 75: loss: 1.651, acc1_cls: 70.975, acc5_cls: 83.475
{"train_lr": 0.00015773486977118528, "train_loss_total": 0.15815127873793244, "train_loss_cls": 0.15815127873793244, "train_acc1_cls": 99.365234375, "train_acc5_cls": 99.951171875, "epoch": 75, "n_parameters": 319077484}
Evaluation on epoch 76: loss: 1.641, acc1_cls: 72.458, acc5_cls: 83.686
{"train_lr": 0.0001464551449406322, "train_loss_total": 0.14537938544526696, "train_loss_cls": 0.14537938544526696, "train_acc1_cls": 99.755859375, "train_acc5_cls": 100.0, "epoch": 76, "n_parameters": 319077484}
Evaluation on epoch 77: loss: 1.657, acc1_cls: 71.822, acc5_cls: 83.686
{"train_lr": 0.00013552433113243144, "train_loss_total": 0.15502472827211022, "train_loss_cls": 0.15502472827211022, "train_acc1_cls": 99.169921875, "train_acc5_cls": 100.0, "epoch": 77, "n_parameters": 319077484}
Evaluation on epoch 78: loss: 1.665, acc1_cls: 71.610, acc5_cls: 82.627
{"train_lr": 0.00012495321574011836, "train_loss_total": 0.14586804574355483, "train_loss_cls": 0.14586804574355483, "train_acc1_cls": 99.4140625, "train_acc5_cls": 100.0, "epoch": 78, "n_parameters": 319077484}
Evaluation on epoch 79: loss: 1.670, acc1_cls: 71.610, acc5_cls: 83.475
{"train_lr": 0.00011475223117831931, "train_loss_total": 0.14915377274155617, "train_loss_cls": 0.14915377274155617, "train_acc1_cls": 99.560546875, "train_acc5_cls": 100.0, "epoch": 79, "n_parameters": 319077484}
Evaluation on epoch 80: loss: 1.659, acc1_cls: 70.975, acc5_cls: 83.686
{"train_lr": 0.00010493144458721668, "train_loss_total": 0.15231948252767324, "train_loss_cls": 0.15231948252767324, "train_acc1_cls": 99.658203125, "train_acc5_cls": 100.0, "epoch": 80, "n_parameters": 319077484}
Evaluation on epoch 81: loss: 1.643, acc1_cls: 70.975, acc5_cls: 83.263
{"train_lr": 9.550054789749821e-05, "train_loss_total": 0.1343866907991469, "train_loss_cls": 0.1343866907991469, "train_acc1_cls": 99.658203125, "train_acc5_cls": 100.0, "epoch": 81, "n_parameters": 319077484}
Evaluation on epoch 82: loss: 1.621, acc1_cls: 72.881, acc5_cls: 84.110
{"train_lr": 8.646884826559051e-05, "train_loss_total": 0.1502415258437395, "train_loss_cls": 0.1502415258437395, "train_acc1_cls": 99.70703125, "train_acc5_cls": 100.0, "epoch": 82, "n_parameters": 319077484}
Evaluation on epoch 83: loss: 1.609, acc1_cls: 73.093, acc5_cls: 84.322
{"train_lr": 7.784525888862008e-05, "train_loss_total": 0.15434242691844702, "train_loss_cls": 0.15434242691844702, "train_acc1_cls": 99.31640625, "train_acc5_cls": 100.0, "epoch": 83, "n_parameters": 319077484}
Evaluation on epoch 84: loss: 1.604, acc1_cls: 73.305, acc5_cls: 84.746
{"train_lr": 6.963829020816314e-05, "train_loss_total": 0.13489443808794022, "train_loss_cls": 0.13489443808794022, "train_acc1_cls": 99.70703125, "train_acc5_cls": 100.0, "epoch": 84, "n_parameters": 319077484}
Evaluation on epoch 85: loss: 1.596, acc1_cls: 73.305, acc5_cls: 85.169
{"train_lr": 6.185604151146843e-05, "train_loss_total": 0.1386747290380299, "train_loss_cls": 0.1386747290380299, "train_acc1_cls": 99.51171875, "train_acc5_cls": 100.0, "epoch": 85, "n_parameters": 319077484}
Evaluation on epoch 86: loss: 1.602, acc1_cls: 73.517, acc5_cls: 84.958
{"train_lr": 5.450619293843705e-05, "train_loss_total": 0.14570264937356114, "train_loss_cls": 0.14570264937356114, "train_acc1_cls": 99.462890625, "train_acc5_cls": 100.0, "epoch": 86, "n_parameters": 319077484}
Evaluation on epoch 87: loss: 1.601, acc1_cls: 73.941, acc5_cls: 85.593
{"train_lr": 4.759599790225266e-05, "train_loss_total": 0.13893001060932875, "train_loss_cls": 0.13893001060932875, "train_acc1_cls": 99.70703125, "train_acc5_cls": 100.0, "epoch": 87, "n_parameters": 319077484}
Evaluation on epoch 88: loss: 1.600, acc1_cls: 74.576, acc5_cls: 86.229
{"train_lr": 4.113227593113796e-05, "train_loss_total": 0.14946375787258148, "train_loss_cls": 0.14946375787258148, "train_acc1_cls": 99.560546875, "train_acc5_cls": 100.0, "epoch": 88, "n_parameters": 319077484}
Evaluation on epoch 89: loss: 1.599, acc1_cls: 73.941, acc5_cls: 85.805
{"train_lr": 3.512140593830377e-05, "train_loss_total": 0.1594426310621202, "train_loss_cls": 0.1594426310621202, "train_acc1_cls": 99.462890625, "train_acc5_cls": 100.0, "epoch": 89, "n_parameters": 319077484}
Evaluation on epoch 90: loss: 1.600, acc1_cls: 74.153, acc5_cls: 86.017
{"train_lr": 2.9569319926732046e-05, "train_loss_total": 0.14042997593060136, "train_loss_cls": 0.14042997593060136, "train_acc1_cls": 99.755859375, "train_acc5_cls": 100.0, "epoch": 90, "n_parameters": 319077484}
Evaluation on epoch 91: loss: 1.601, acc1_cls: 74.153, acc5_cls: 86.017
{"train_lr": 2.4481497135004713e-05, "train_loss_total": 0.13050228171050549, "train_loss_cls": 0.13050228171050549, "train_acc1_cls": 99.609375, "train_acc5_cls": 100.0, "epoch": 91, "n_parameters": 319077484}
Evaluation on epoch 92: loss: 1.597, acc1_cls: 75.000, acc5_cls: 86.017
{"train_lr": 1.986295862995691e-05, "train_loss_total": 0.12881992477923632, "train_loss_cls": 0.12881992477923632, "train_acc1_cls": 99.70703125, "train_acc5_cls": 100.0, "epoch": 92, "n_parameters": 319077484}
Evaluation on epoch 93: loss: 1.594, acc1_cls: 74.788, acc5_cls: 86.017
{"train_lr": 1.5718262351490163e-05, "train_loss_total": 0.12930756574496627, "train_loss_cls": 0.12930756574496627, "train_acc1_cls": 99.8046875, "train_acc5_cls": 100.0, "epoch": 93, "n_parameters": 319077484}
Evaluation on epoch 94: loss: 1.590, acc1_cls: 74.788, acc5_cls: 85.805
{"train_lr": 1.2051498614436032e-05, "train_loss_total": 0.15489539690315723, "train_loss_cls": 0.15489539690315723, "train_acc1_cls": 99.31640625, "train_acc5_cls": 100.0, "epoch": 94, "n_parameters": 319077484}
Evaluation on epoch 95: loss: 1.593, acc1_cls: 74.576, acc5_cls: 86.017
{"train_lr": 8.866286071909284e-06, "train_loss_total": 0.12204711604863405, "train_loss_cls": 0.12204711604863405, "train_acc1_cls": 99.853515625, "train_acc5_cls": 100.0, "epoch": 95, "n_parameters": 319077484}
Evaluation on epoch 96: loss: 1.596, acc1_cls: 74.364, acc5_cls: 86.229
{"train_lr": 6.165768144134146e-06, "train_loss_total": 0.13658221811056137, "train_loss_cls": 0.13658221811056137, "train_acc1_cls": 99.560546875, "train_acc5_cls": 100.0, "epoch": 96, "n_parameters": 319077484}
Evaluation on epoch 97: loss: 1.590, acc1_cls: 75.000, acc5_cls: 86.017
{"train_lr": 3.95260991626769e-06, "train_loss_total": 0.13566046534106135, "train_loss_cls": 0.13566046534106135, "train_acc1_cls": 99.755859375, "train_acc5_cls": 100.0, "epoch": 97, "n_parameters": 319077484}
Evaluation on epoch 98: loss: 1.592, acc1_cls: 75.000, acc5_cls: 86.017
{"train_lr": 2.2289955082830174e-06, "train_loss_total": 0.11750832200050354, "train_loss_cls": 0.11750832200050354, "train_acc1_cls": 99.755859375, "train_acc5_cls": 100.0, "epoch": 98, "n_parameters": 319077484}
Evaluation on epoch 99: loss: 1.588, acc1_cls: 75.212, acc5_cls: 86.441
{"train_lr": 9.966259195063618e-07, "train_loss_total": 0.1365275108255446, "train_loss_cls": 0.1365275108255446, "train_acc1_cls": 99.462890625, "train_acc5_cls": 100.0, "epoch": 99, "n_parameters": 319077484}
