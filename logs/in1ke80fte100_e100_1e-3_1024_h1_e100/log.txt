batch_size: 256
epochs: 100
bce_loss: True
unscale_lr: True
rec: False
freeze: False
model: jigsaw_base_patch56_336
input_size: 336
permcls: 50
drop: 0.0
drop_path: 0.1
model_ema: True
model_ema_decay: 0.99996
model_ema_force_cpu: False
opt: adamw
opt_eps: 1e-08
opt_betas: None
clip_grad: None
momentum: 0.9
weight_decay: 0.05
sched: cosine
lr: 0.001
lr_noise: None
lr_noise_pct: 0.67
lr_noise_std: 1.0
warmup_lr: 1e-06
min_lr: 1e-05
decay_epochs: 30
warmup_epochs: 0
cooldown_epochs: 10
patience_epochs: 10
decay_rate: 0.1
color_jitter: 0.3
aa: rand-m9-mstd0.5-inc1
smoothing: None
train_interpolation: bicubic
repeated_aug: True
train_mode: True
ThreeAugment: False
src: False
reprob: 0.25
remode: pixel
recount: 1
resplit: False
mixup: 0.0
cutmix: 0.0
cutmix_minmax: None
mixup_prob: 1.0
mixup_switch_prob: 0.5
mixup_mode: batch
teacher_model: regnety_160
teacher_path: 
distillation_type: none
distillation_alpha: 0.5
distillation_tau: 1.0
finetune: ./outputs/jigsaw_base_p56_336_f101_shuffle_in1ke10fte300/best_checkpoint_e100.pth
attn_only: False
data_path: ./data/food101/
data_set: IMNET
nb_classes: 50
inat_category: name
output_dir: ./outputs/in1ke80fte100_e100_1e-3_1024_h1_e100
log_dir: ./logs/in1ke80fte100_e100_1e-3_1024_h1_e100
device: cuda
seed: 0
resume: 
start_epoch: 0
eval: False
eval_crop_ratio: 0.875
dist_eval: False
num_workers: 10
pin_mem: True
world_size: 4
dist_url: env://
local_rank: 0
use_jigsaw: True
use_cls: True
lambda_rec: 0.1
mask_ratio: 0.0
rank: 0
gpu: 0
distributed: True
dist_backend: nccl

Evaluation on epoch 0: loss: 23.984, acc1_cls: 6.144, acc5_cls: 17.585
{"train_lr": 0.001, "train_loss_total": 4.206559538841248, "train_loss_cls": 4.206559538841248, "train_acc1_cls": 5.419921875, "train_acc5_cls": 17.236328125, "epoch": 0, "n_parameters": 613877740}
batch_size: 256
epochs: 100
bce_loss: True
unscale_lr: True
rec: False
freeze: False
model: jigsaw_base_patch56_336
input_size: 336
permcls: 50
drop: 0.0
drop_path: 0.1
model_ema: True
model_ema_decay: 0.99996
model_ema_force_cpu: False
opt: adamw
opt_eps: 1e-08
opt_betas: None
clip_grad: None
momentum: 0.9
weight_decay: 0.05
sched: cosine
lr: 0.001
lr_noise: None
lr_noise_pct: 0.67
lr_noise_std: 1.0
warmup_lr: 1e-06
min_lr: 1e-06
decay_epochs: 30
warmup_epochs: 0
cooldown_epochs: 10
patience_epochs: 10
decay_rate: 0.1
color_jitter: 0.3
aa: rand-m9-mstd0.5-inc1
smoothing: None
train_interpolation: bicubic
repeated_aug: True
train_mode: True
ThreeAugment: False
src: False
reprob: 0.25
remode: pixel
recount: 1
resplit: False
mixup: 0.0
cutmix: 0.0
cutmix_minmax: None
mixup_prob: 1.0
mixup_switch_prob: 0.5
mixup_mode: batch
teacher_model: regnety_160
teacher_path: 
distillation_type: none
distillation_alpha: 0.5
distillation_tau: 1.0
finetune: ./outputs/jigsaw_base_p56_336_f101_shuffle_in1ke10fte300/best_checkpoint_e100.pth
attn_only: False
data_path: ./data/food101/
data_set: IMNET
nb_classes: 50
inat_category: name
output_dir: ./outputs/in1ke80fte100_e100_1e-3_1024_h1_e100
log_dir: ./logs/in1ke80fte100_e100_1e-3_1024_h1_e100
device: cuda
seed: 0
resume: 
start_epoch: 0
eval: False
eval_crop_ratio: 0.875
dist_eval: False
num_workers: 10
pin_mem: True
world_size: 4
dist_url: env://
local_rank: 0
use_jigsaw: True
use_cls: True
lambda_rec: 0.1
mask_ratio: 0.0
rank: 0
gpu: 0
distributed: True
dist_backend: nccl

Evaluation on epoch 0: loss: 45.223, acc1_cls: 3.390, acc5_cls: 18.856
{"train_lr": 0.001, "train_loss_total": 4.202756345272064, "train_loss_cls": 4.202756345272064, "train_acc1_cls": 6.0546875, "train_acc5_cls": 16.69921875, "epoch": 0, "n_parameters": 613877740}
Evaluation on epoch 1: loss: 16.447, acc1_cls: 5.085, acc5_cls: 19.915
{"train_lr": 0.001, "train_loss_total": 3.3672529757022858, "train_loss_cls": 3.3672529757022858, "train_acc1_cls": 25.244140625, "train_acc5_cls": 43.603515625, "epoch": 1, "n_parameters": 613877740}
Evaluation on epoch 2: loss: 9.180, acc1_cls: 12.288, acc5_cls: 32.627
{"train_lr": 0.0009997535269026829, "train_loss_total": 3.0007713735103607, "train_loss_cls": 3.0007713735103607, "train_acc1_cls": 35.791015625, "train_acc5_cls": 54.296875, "epoch": 2, "n_parameters": 613877740}
Evaluation on epoch 3: loss: 6.139, acc1_cls: 13.136, acc5_cls: 43.432
{"train_lr": 0.0009990143508499217, "train_loss_total": 2.6236322224140167, "train_loss_cls": 2.6236322224140167, "train_acc1_cls": 43.84765625, "train_acc5_cls": 62.646484375, "epoch": 3, "n_parameters": 613877740}
Evaluation on epoch 4: loss: 5.452, acc1_cls: 20.975, acc5_cls: 41.949
{"train_lr": 0.0009977832013192385, "train_loss_total": 2.439246356487274, "train_loss_cls": 2.439246356487274, "train_acc1_cls": 50.341796875, "train_acc5_cls": 69.091796875, "epoch": 4, "n_parameters": 613877740}
Evaluation on epoch 5: loss: 4.669, acc1_cls: 20.127, acc5_cls: 45.127
{"train_lr": 0.0009960612933065818, "train_loss_total": 2.3159067928791046, "train_loss_cls": 2.3159067928791046, "train_acc1_cls": 54.052734375, "train_acc5_cls": 71.2890625, "epoch": 5, "n_parameters": 613877740}
Evaluation on epoch 6: loss: 3.315, acc1_cls: 34.110, acc5_cls: 53.390
{"train_lr": 0.0009938503261272714, "train_loss_total": 2.1402978897094727, "train_loss_cls": 2.1402978897094727, "train_acc1_cls": 57.32421875, "train_acc5_cls": 75.927734375, "epoch": 6, "n_parameters": 613877740}
Evaluation on epoch 7: loss: 2.764, acc1_cls: 40.042, acc5_cls: 58.898
{"train_lr": 0.00099115248173898, "train_loss_total": 1.8825419545173645, "train_loss_cls": 1.8825419545173645, "train_acc1_cls": 66.650390625, "train_acc5_cls": 79.833984375, "epoch": 7, "n_parameters": 613877740}
Evaluation on epoch 8: loss: 2.340, acc1_cls: 47.246, acc5_cls: 65.678
{"train_lr": 0.0009879704225884043, "train_loss_total": 1.739217296242714, "train_loss_cls": 1.739217296242714, "train_acc1_cls": 69.53125, "train_acc5_cls": 84.1796875, "epoch": 8, "n_parameters": 613877740}
Evaluation on epoch 9: loss: 2.221, acc1_cls: 48.305, acc5_cls: 67.585
{"train_lr": 0.0009843072889837512, "train_loss_total": 1.5576441287994385, "train_loss_cls": 1.5576441287994385, "train_acc1_cls": 76.025390625, "train_acc5_cls": 87.5, "epoch": 9, "n_parameters": 613877740}
Evaluation on epoch 10: loss: 2.191, acc1_cls: 49.788, acc5_cls: 67.161
{"train_lr": 0.000980166695995633, "train_loss_total": 1.4585787653923035, "train_loss_cls": 1.4585787653923035, "train_acc1_cls": 78.90625, "train_acc5_cls": 89.2578125, "epoch": 10, "n_parameters": 613877740}
Evaluation on epoch 11: loss: 2.129, acc1_cls: 51.483, acc5_cls: 68.008
{"train_lr": 0.0009755527298894294, "train_loss_total": 1.413840264081955, "train_loss_cls": 1.413840264081955, "train_acc1_cls": 79.6875, "train_acc5_cls": 89.697265625, "epoch": 11, "n_parameters": 613877740}
Evaluation on epoch 12: loss: 2.107, acc1_cls: 51.907, acc5_cls: 69.915
{"train_lr": 0.0009704699440926358, "train_loss_total": 1.237724632024765, "train_loss_cls": 1.237724632024765, "train_acc1_cls": 85.3515625, "train_acc5_cls": 93.75, "epoch": 12, "n_parameters": 613877740}
Evaluation on epoch 13: loss: 2.033, acc1_cls: 57.203, acc5_cls: 73.517
{"train_lr": 0.0009649233547011816, "train_loss_total": 1.2051053047180176, "train_loss_cls": 1.2051053047180176, "train_acc1_cls": 84.814453125, "train_acc5_cls": 93.310546875, "epoch": 13, "n_parameters": 613877740}
Evaluation on epoch 14: loss: 1.929, acc1_cls: 59.534, acc5_cls: 76.271
{"train_lr": 0.0009589184355291487, "train_loss_total": 1.1644784361124039, "train_loss_cls": 1.1644784361124039, "train_acc1_cls": 83.837890625, "train_acc5_cls": 93.75, "epoch": 14, "n_parameters": 613877740}
Evaluation on epoch 15: loss: 1.829, acc1_cls: 62.924, acc5_cls: 78.602
{"train_lr": 0.0009524611127067769, "train_loss_total": 1.0574171766638756, "train_loss_cls": 1.0574171766638756, "train_acc1_cls": 87.890625, "train_acc5_cls": 94.775390625, "epoch": 15, "n_parameters": 613877740}
Evaluation on epoch 16: loss: 1.895, acc1_cls: 63.347, acc5_cls: 77.754
{"train_lr": 0.0009455577588320898, "train_loss_total": 0.9561571329832077, "train_loss_cls": 0.9561571329832077, "train_acc1_cls": 89.55078125, "train_acc5_cls": 96.044921875, "epoch": 16, "n_parameters": 613877740}
Evaluation on epoch 17: loss: 1.929, acc1_cls: 64.195, acc5_cls: 76.907
{"train_lr": 0.0009382151866819099, "train_loss_total": 0.8456477969884872, "train_loss_cls": 0.8456477969884872, "train_acc1_cls": 92.041015625, "train_acc5_cls": 97.0703125, "epoch": 17, "n_parameters": 613877740}
Evaluation on epoch 18: loss: 1.953, acc1_cls: 65.678, acc5_cls: 78.602
{"train_lr": 0.00093044064248847, "train_loss_total": 0.8280015662312508, "train_loss_cls": 0.8280015662312508, "train_acc1_cls": 92.822265625, "train_acc5_cls": 97.021484375, "epoch": 18, "n_parameters": 613877740}
Evaluation on epoch 19: loss: 1.887, acc1_cls: 66.949, acc5_cls: 79.661
{"train_lr": 0.0009222417987882566, "train_loss_total": 0.7399578765034676, "train_loss_cls": 0.7399578765034676, "train_acc1_cls": 94.384765625, "train_acc5_cls": 97.36328125, "epoch": 19, "n_parameters": 613877740}
Evaluation on epoch 20: loss: 1.791, acc1_cls: 68.220, acc5_cls: 81.780
{"train_lr": 0.0009136267468501438, "train_loss_total": 0.6756507530808449, "train_loss_cls": 0.6756507530808449, "train_acc1_cls": 95.263671875, "train_acc5_cls": 98.4375, "epoch": 20, "n_parameters": 613877740}
Evaluation on epoch 21: loss: 1.789, acc1_cls: 68.644, acc5_cls: 82.203
{"train_lr": 0.0009046039886902864, "train_loss_total": 0.6401865631341934, "train_loss_cls": 0.6401865631341934, "train_acc1_cls": 95.01953125, "train_acc5_cls": 98.388671875, "epoch": 21, "n_parameters": 613877740}
Evaluation on epoch 22: loss: 1.778, acc1_cls: 69.280, acc5_cls: 83.898
{"train_lr": 0.0008951824286816573, "train_loss_total": 0.5946541503071785, "train_loss_cls": 0.5946541503071785, "train_acc1_cls": 95.60546875, "train_acc5_cls": 98.583984375, "epoch": 22, "n_parameters": 613877740}
Evaluation on epoch 23: loss: 1.826, acc1_cls: 69.703, acc5_cls: 82.839
{"train_lr": 0.0008853713647665069, "train_loss_total": 0.537206094712019, "train_loss_cls": 0.537206094712019, "train_acc1_cls": 96.923828125, "train_acc5_cls": 98.876953125, "epoch": 23, "n_parameters": 613877740}
Evaluation on epoch 24: loss: 1.862, acc1_cls: 69.915, acc5_cls: 81.992
{"train_lr": 0.0008751804792804147, "train_loss_total": 0.5431951731443405, "train_loss_cls": 0.5431951731443405, "train_acc1_cls": 96.337890625, "train_acc5_cls": 98.974609375, "epoch": 24, "n_parameters": 613877740}
Evaluation on epoch 25: loss: 1.859, acc1_cls: 70.975, acc5_cls: 81.992
{"train_lr": 0.0008646198293969952, "train_loss_total": 0.4876520484685898, "train_loss_cls": 0.4876520484685898, "train_acc1_cls": 97.265625, "train_acc5_cls": 99.365234375, "epoch": 25, "n_parameters": 613877740}
Evaluation on epoch 26: loss: 1.847, acc1_cls: 70.339, acc5_cls: 82.839
{"train_lr": 0.0008536998372026805, "train_loss_total": 0.4590861350297928, "train_loss_cls": 0.4590861350297928, "train_acc1_cls": 97.65625, "train_acc5_cls": 99.169921875, "epoch": 26, "n_parameters": 613877740}
Evaluation on epoch 27: loss: 1.809, acc1_cls: 71.398, acc5_cls: 83.475
{"train_lr": 0.0008424312794113801, "train_loss_total": 0.4089282751083374, "train_loss_cls": 0.4089282751083374, "train_acc1_cls": 98.53515625, "train_acc5_cls": 99.658203125, "epoch": 27, "n_parameters": 613877740}
Evaluation on epoch 28: loss: 1.792, acc1_cls: 71.398, acc5_cls: 84.746
{"train_lr": 0.0008308252767291642, "train_loss_total": 0.37988442555069923, "train_loss_cls": 0.37988442555069923, "train_acc1_cls": 98.779296875, "train_acc5_cls": 99.70703125, "epoch": 28, "n_parameters": 613877740}
Evaluation on epoch 29: loss: 1.810, acc1_cls: 71.398, acc5_cls: 84.746
{"train_lr": 0.0008188932828794706, "train_loss_total": 0.40063587203621864, "train_loss_cls": 0.40063587203621864, "train_acc1_cls": 97.802734375, "train_acc5_cls": 99.658203125, "epoch": 29, "n_parameters": 613877740}
Evaluation on epoch 30: loss: 1.852, acc1_cls: 72.034, acc5_cls: 84.958
{"train_lr": 0.0008066470732996619, "train_loss_total": 0.3831417113542557, "train_loss_cls": 0.3831417113542557, "train_acc1_cls": 97.998046875, "train_acc5_cls": 99.560546875, "epoch": 30, "n_parameters": 613877740}
Evaluation on epoch 31: loss: 1.882, acc1_cls: 74.364, acc5_cls: 84.322
{"train_lr": 0.0007940987335200905, "train_loss_total": 0.3391561061143875, "train_loss_cls": 0.3391561061143875, "train_acc1_cls": 98.4375, "train_acc5_cls": 99.609375, "epoch": 31, "n_parameters": 613877740}
Evaluation on epoch 32: loss: 1.880, acc1_cls: 73.517, acc5_cls: 85.169
{"train_lr": 0.0007812606472371394, "train_loss_total": 0.3124042712152004, "train_loss_cls": 0.3124042712152004, "train_acc1_cls": 98.486328125, "train_acc5_cls": 99.8046875, "epoch": 32, "n_parameters": 613877740}
Evaluation on epoch 33: loss: 1.869, acc1_cls: 73.305, acc5_cls: 85.381
{"train_lr": 0.0007681454840920089, "train_loss_total": 0.3034559562802315, "train_loss_cls": 0.3034559562802315, "train_acc1_cls": 98.73046875, "train_acc5_cls": 99.658203125, "epoch": 33, "n_parameters": 613877740}
Evaluation on epoch 34: loss: 1.847, acc1_cls: 73.941, acc5_cls: 85.381
{"train_lr": 0.0007547661871673105, "train_loss_total": 0.3124404326081276, "train_loss_cls": 0.3124404326081276, "train_acc1_cls": 98.388671875, "train_acc5_cls": 99.658203125, "epoch": 34, "n_parameters": 613877740}
Evaluation on epoch 35: loss: 1.855, acc1_cls: 73.941, acc5_cls: 84.534
{"train_lr": 0.0007411359602138069, "train_loss_total": 0.2487526573240757, "train_loss_cls": 0.2487526573240757, "train_acc1_cls": 98.92578125, "train_acc5_cls": 99.658203125, "epoch": 35, "n_parameters": 613877740}
Evaluation on epoch 36: loss: 1.858, acc1_cls: 72.881, acc5_cls: 85.381
{"train_lr": 0.0007272682546199037, "train_loss_total": 0.27091107331216335, "train_loss_cls": 0.27091107331216335, "train_acc1_cls": 99.12109375, "train_acc5_cls": 99.853515625, "epoch": 36, "n_parameters": 613877740}
Evaluation on epoch 37: loss: 1.808, acc1_cls: 72.669, acc5_cls: 86.017
{"train_lr": 0.0007131767561367538, "train_loss_total": 0.2610092107206583, "train_loss_cls": 0.2610092107206583, "train_acc1_cls": 98.828125, "train_acc5_cls": 99.853515625, "epoch": 37, "n_parameters": 613877740}
Evaluation on epoch 38: loss: 1.779, acc1_cls: 73.517, acc5_cls: 84.110
{"train_lr": 0.0006988753713720729, "train_loss_total": 0.2372139897197485, "train_loss_cls": 0.2372139897197485, "train_acc1_cls": 99.267578125, "train_acc5_cls": 99.8046875, "epoch": 38, "n_parameters": 613877740}
Evaluation on epoch 39: loss: 1.790, acc1_cls: 73.729, acc5_cls: 83.475
{"train_lr": 0.0006843782140659968, "train_loss_total": 0.2409448828548193, "train_loss_cls": 0.2409448828548193, "train_acc1_cls": 99.169921875, "train_acc5_cls": 99.8046875, "epoch": 39, "n_parameters": 613877740}
Evaluation on epoch 40: loss: 1.801, acc1_cls: 73.517, acc5_cls: 84.322
{"train_lr": 0.0006696995911625233, "train_loss_total": 0.21898815035820007, "train_loss_cls": 0.21898815035820007, "train_acc1_cls": 99.4140625, "train_acc5_cls": 99.90234375, "epoch": 40, "n_parameters": 613877740}
Evaluation on epoch 41: loss: 1.827, acc1_cls: 71.822, acc5_cls: 83.475
{"train_lr": 0.0006548539886902864, "train_loss_total": 0.20106863789260387, "train_loss_cls": 0.20106863789260387, "train_acc1_cls": 99.365234375, "train_acc5_cls": 99.951171875, "epoch": 41, "n_parameters": 613877740}
Evaluation on epoch 42: loss: 1.836, acc1_cls: 71.610, acc5_cls: 84.110
{"train_lr": 0.0006398560574665951, "train_loss_total": 0.22427429631352425, "train_loss_cls": 0.22427429631352425, "train_acc1_cls": 99.31640625, "train_acc5_cls": 99.90234375, "epoch": 42, "n_parameters": 613877740}
Evaluation on epoch 43: loss: 1.816, acc1_cls: 71.822, acc5_cls: 85.381
{"train_lr": 0.0006247205986388449, "train_loss_total": 0.1930373888462782, "train_loss_cls": 0.1930373888462782, "train_acc1_cls": 99.462890625, "train_acc5_cls": 99.8046875, "epoch": 43, "n_parameters": 613877740}
Evaluation on epoch 44: loss: 1.774, acc1_cls: 72.246, acc5_cls: 84.958
{"train_lr": 0.0006094625490775732, "train_loss_total": 0.21428462862968445, "train_loss_cls": 0.21428462862968445, "train_acc1_cls": 98.779296875, "train_acc5_cls": 99.8046875, "epoch": 44, "n_parameters": 613877740}
Evaluation on epoch 45: loss: 1.761, acc1_cls: 73.305, acc5_cls: 84.534
{"train_lr": 0.0005940969666355697, "train_loss_total": 0.18678795918822289, "train_loss_cls": 0.18678795918822289, "train_acc1_cls": 99.70703125, "train_acc5_cls": 100.0, "epoch": 45, "n_parameters": 613877740}
Evaluation on epoch 46: loss: 1.754, acc1_cls: 74.576, acc5_cls: 85.381
{"train_lr": 0.0005786390152875954, "train_loss_total": 0.18397842906415462, "train_loss_cls": 0.18397842906415462, "train_acc1_cls": 99.12109375, "train_acc5_cls": 99.90234375, "epoch": 46, "n_parameters": 613877740}
Evaluation on epoch 47: loss: 1.753, acc1_cls: 76.059, acc5_cls: 85.805
{"train_lr": 0.0005631039501653701, "train_loss_total": 0.17328942008316517, "train_loss_cls": 0.17328942008316517, "train_acc1_cls": 99.8046875, "train_acc5_cls": 100.0, "epoch": 47, "n_parameters": 613877740}
Evaluation on epoch 48: loss: 1.778, acc1_cls: 75.212, acc5_cls: 86.229
{"train_lr": 0.000547507102502598, "train_loss_total": 0.17131341993808746, "train_loss_cls": 0.17131341993808746, "train_acc1_cls": 99.365234375, "train_acc5_cls": 99.8046875, "epoch": 48, "n_parameters": 613877740}
Evaluation on epoch 49: loss: 1.802, acc1_cls: 75.212, acc5_cls: 84.958
{"train_lr": 0.0005318638645048922, "train_loss_total": 0.1678414959460497, "train_loss_cls": 0.1678414959460497, "train_acc1_cls": 99.4140625, "train_acc5_cls": 99.90234375, "epoch": 49, "n_parameters": 613877740}
Evaluation on epoch 50: loss: 1.771, acc1_cls: 75.212, acc5_cls: 84.746
{"train_lr": 0.0005161896741595252, "train_loss_total": 0.16612645238637924, "train_loss_cls": 0.16612645238637924, "train_acc1_cls": 99.560546875, "train_acc5_cls": 99.90234375, "epoch": 50, "n_parameters": 613877740}
Evaluation on epoch 51: loss: 1.694, acc1_cls: 74.788, acc5_cls: 86.441
{"train_lr": 0.0005005000000000001, "train_loss_total": 0.166641715914011, "train_loss_cls": 0.166641715914011, "train_acc1_cls": 99.169921875, "train_acc5_cls": 99.90234375, "epoch": 51, "n_parameters": 613877740}
Evaluation on epoch 52: loss: 1.669, acc1_cls: 73.941, acc5_cls: 87.924
{"train_lr": 0.000484810325840475, "train_loss_total": 0.15454303193837404, "train_loss_cls": 0.15454303193837404, "train_acc1_cls": 99.462890625, "train_acc5_cls": 100.0, "epoch": 52, "n_parameters": 613877740}
Evaluation on epoch 53: loss: 1.673, acc1_cls: 74.576, acc5_cls: 87.288
{"train_lr": 0.00046913613549510807, "train_loss_total": 0.1548590324819088, "train_loss_cls": 0.1548590324819088, "train_acc1_cls": 99.658203125, "train_acc5_cls": 100.0, "epoch": 53, "n_parameters": 613877740}
Evaluation on epoch 54: loss: 1.706, acc1_cls: 74.153, acc5_cls: 87.500
{"train_lr": 0.0004534928974974022, "train_loss_total": 0.1494883457198739, "train_loss_cls": 0.1494883457198739, "train_acc1_cls": 99.609375, "train_acc5_cls": 99.951171875, "epoch": 54, "n_parameters": 613877740}
Evaluation on epoch 55: loss: 1.726, acc1_cls: 74.153, acc5_cls: 86.017
{"train_lr": 0.00043789604983463014, "train_loss_total": 0.14767847396433353, "train_loss_cls": 0.14767847396433353, "train_acc1_cls": 99.51171875, "train_acc5_cls": 100.0, "epoch": 55, "n_parameters": 613877740}
Evaluation on epoch 56: loss: 1.696, acc1_cls: 73.729, acc5_cls: 85.593
{"train_lr": 0.00042236098471240476, "train_loss_total": 0.1584814079105854, "train_loss_cls": 0.1584814079105854, "train_acc1_cls": 99.462890625, "train_acc5_cls": 100.0, "epoch": 56, "n_parameters": 613877740}
Evaluation on epoch 57: loss: 1.676, acc1_cls: 75.212, acc5_cls: 84.958
{"train_lr": 0.00040690303336443065, "train_loss_total": 0.14331317692995071, "train_loss_cls": 0.14331317692995071, "train_acc1_cls": 99.609375, "train_acc5_cls": 99.853515625, "epoch": 57, "n_parameters": 613877740}
Evaluation on epoch 58: loss: 1.683, acc1_cls: 75.636, acc5_cls: 84.746
{"train_lr": 0.0003915374509224272, "train_loss_total": 0.13064391911029816, "train_loss_cls": 0.13064391911029816, "train_acc1_cls": 99.658203125, "train_acc5_cls": 99.951171875, "epoch": 58, "n_parameters": 613877740}
Evaluation on epoch 59: loss: 1.700, acc1_cls: 75.424, acc5_cls: 84.746
{"train_lr": 0.00037627940136115507, "train_loss_total": 0.14925003424286842, "train_loss_cls": 0.14925003424286842, "train_acc1_cls": 99.609375, "train_acc5_cls": 99.951171875, "epoch": 59, "n_parameters": 613877740}
Evaluation on epoch 60: loss: 1.713, acc1_cls: 75.212, acc5_cls: 84.746
{"train_lr": 0.0003611439425334051, "train_loss_total": 0.14518543519079685, "train_loss_cls": 0.14518543519079685, "train_acc1_cls": 99.658203125, "train_acc5_cls": 99.90234375, "epoch": 60, "n_parameters": 613877740}
Evaluation on epoch 61: loss: 1.707, acc1_cls: 74.576, acc5_cls: 84.110
{"train_lr": 0.000346146011309714, "train_loss_total": 0.13595095928758383, "train_loss_cls": 0.13595095928758383, "train_acc1_cls": 99.267578125, "train_acc5_cls": 99.951171875, "epoch": 61, "n_parameters": 613877740}
Evaluation on epoch 62: loss: 1.708, acc1_cls: 73.305, acc5_cls: 84.746
{"train_lr": 0.00033130040883747703, "train_loss_total": 0.12877776753157377, "train_loss_cls": 0.12877776753157377, "train_acc1_cls": 99.70703125, "train_acc5_cls": 99.951171875, "epoch": 62, "n_parameters": 613877740}
Evaluation on epoch 63: loss: 1.699, acc1_cls: 73.517, acc5_cls: 84.958
{"train_lr": 0.00031662178593400354, "train_loss_total": 0.1314605800434947, "train_loss_cls": 0.1314605800434947, "train_acc1_cls": 99.8046875, "train_acc5_cls": 99.951171875, "epoch": 63, "n_parameters": 613877740}
Evaluation on epoch 64: loss: 1.677, acc1_cls: 73.941, acc5_cls: 85.805
{"train_lr": 0.0003021246286279271, "train_loss_total": 0.13245914969593287, "train_loss_cls": 0.13245914969593287, "train_acc1_cls": 99.658203125, "train_acc5_cls": 100.0, "epoch": 64, "n_parameters": 613877740}
Evaluation on epoch 65: loss: 1.657, acc1_cls: 73.517, acc5_cls: 86.441
{"train_lr": 0.00028782324386324626, "train_loss_total": 0.12736877612769604, "train_loss_cls": 0.12736877612769604, "train_acc1_cls": 99.755859375, "train_acc5_cls": 100.0, "epoch": 65, "n_parameters": 613877740}
Evaluation on epoch 66: loss: 1.655, acc1_cls: 74.364, acc5_cls: 86.864
{"train_lr": 0.00027373174538009644, "train_loss_total": 0.1198448771610856, "train_loss_cls": 0.1198448771610856, "train_acc1_cls": 99.90234375, "train_acc5_cls": 100.0, "epoch": 66, "n_parameters": 613877740}
Evaluation on epoch 67: loss: 1.646, acc1_cls: 74.364, acc5_cls: 87.288
{"train_lr": 0.00025986403978619317, "train_loss_total": 0.12131254654377699, "train_loss_cls": 0.12131254654377699, "train_acc1_cls": 99.755859375, "train_acc5_cls": 100.0, "epoch": 67, "n_parameters": 613877740}
Evaluation on epoch 68: loss: 1.625, acc1_cls: 74.364, acc5_cls: 87.288
{"train_lr": 0.00024623381283268956, "train_loss_total": 0.13053830713033676, "train_loss_cls": 0.13053830713033676, "train_acc1_cls": 99.658203125, "train_acc5_cls": 99.853515625, "epoch": 68, "n_parameters": 613877740}
Evaluation on epoch 69: loss: 1.606, acc1_cls: 75.212, acc5_cls: 86.441
{"train_lr": 0.00023285451590799108, "train_loss_total": 0.1210889108479023, "train_loss_cls": 0.1210889108479023, "train_acc1_cls": 99.70703125, "train_acc5_cls": 99.90234375, "epoch": 69, "n_parameters": 613877740}
Evaluation on epoch 70: loss: 1.591, acc1_cls: 75.847, acc5_cls: 86.441
{"train_lr": 0.00021973935276286074, "train_loss_total": 0.11482677701860666, "train_loss_cls": 0.11482677701860666, "train_acc1_cls": 99.90234375, "train_acc5_cls": 100.0, "epoch": 70, "n_parameters": 613877740}
Evaluation on epoch 71: loss: 1.583, acc1_cls: 75.636, acc5_cls: 86.229
{"train_lr": 0.00020690126647990973, "train_loss_total": 0.1208722097799182, "train_loss_cls": 0.1208722097799182, "train_acc1_cls": 99.853515625, "train_acc5_cls": 100.0, "epoch": 71, "n_parameters": 613877740}
Evaluation on epoch 72: loss: 1.585, acc1_cls: 75.636, acc5_cls: 86.017
{"train_lr": 0.0001943529267003382, "train_loss_total": 0.11821214947849512, "train_loss_cls": 0.11821214947849512, "train_acc1_cls": 99.560546875, "train_acc5_cls": 100.0, "epoch": 72, "n_parameters": 613877740}
Evaluation on epoch 73: loss: 1.592, acc1_cls: 76.059, acc5_cls: 86.229
{"train_lr": 0.00018210671712052948, "train_loss_total": 0.11771366372704506, "train_loss_cls": 0.11771366372704506, "train_acc1_cls": 99.8046875, "train_acc5_cls": 99.951171875, "epoch": 73, "n_parameters": 613877740}
Evaluation on epoch 74: loss: 1.612, acc1_cls: 75.847, acc5_cls: 86.017
{"train_lr": 0.00017017472327083598, "train_loss_total": 0.12858725432306528, "train_loss_cls": 0.12858725432306528, "train_acc1_cls": 99.70703125, "train_acc5_cls": 100.0, "epoch": 74, "n_parameters": 613877740}
Evaluation on epoch 75: loss: 1.630, acc1_cls: 76.059, acc5_cls: 86.229
{"train_lr": 0.00015856872058862, "train_loss_total": 0.12401362136006355, "train_loss_cls": 0.12401362136006355, "train_acc1_cls": 99.70703125, "train_acc5_cls": 100.0, "epoch": 75, "n_parameters": 613877740}
Evaluation on epoch 76: loss: 1.633, acc1_cls: 75.424, acc5_cls: 86.017
{"train_lr": 0.00014730016279731955, "train_loss_total": 0.10944384895265102, "train_loss_cls": 0.10944384895265102, "train_acc1_cls": 99.8046875, "train_acc5_cls": 100.0, "epoch": 76, "n_parameters": 613877740}
Evaluation on epoch 77: loss: 1.632, acc1_cls: 75.424, acc5_cls: 85.593
{"train_lr": 0.00013638017060300505, "train_loss_total": 0.11322458367794752, "train_loss_cls": 0.11322458367794752, "train_acc1_cls": 99.90234375, "train_acc5_cls": 100.0, "epoch": 77, "n_parameters": 613877740}
Evaluation on epoch 78: loss: 1.623, acc1_cls: 75.424, acc5_cls: 85.593
{"train_lr": 0.00012581952071958545, "train_loss_total": 0.11551017127931118, "train_loss_cls": 0.11551017127931118, "train_acc1_cls": 99.90234375, "train_acc5_cls": 99.951171875, "epoch": 78, "n_parameters": 613877740}
Evaluation on epoch 79: loss: 1.620, acc1_cls: 74.576, acc5_cls: 86.229
{"train_lr": 0.00011562863523349333, "train_loss_total": 0.11176672205328941, "train_loss_cls": 0.11176672205328941, "train_acc1_cls": 99.658203125, "train_acc5_cls": 99.853515625, "epoch": 79, "n_parameters": 613877740}
Evaluation on epoch 80: loss: 1.617, acc1_cls: 75.000, acc5_cls: 86.441
{"train_lr": 0.00010581757131834264, "train_loss_total": 0.12803234159946442, "train_loss_cls": 0.12803234159946442, "train_acc1_cls": 99.8046875, "train_acc5_cls": 100.0, "epoch": 80, "n_parameters": 613877740}
Evaluation on epoch 81: loss: 1.617, acc1_cls: 75.847, acc5_cls: 86.229
{"train_lr": 9.639601130971382e-05, "train_loss_total": 0.10728448070585728, "train_loss_cls": 0.10728448070585728, "train_acc1_cls": 99.8046875, "train_acc5_cls": 100.0, "epoch": 81, "n_parameters": 613877740}
Evaluation on epoch 82: loss: 1.612, acc1_cls: 75.636, acc5_cls: 86.229
{"train_lr": 8.737325314985643e-05, "train_loss_total": 0.11881061643362045, "train_loss_cls": 0.11881061643362045, "train_acc1_cls": 99.853515625, "train_acc5_cls": 100.0, "epoch": 82, "n_parameters": 613877740}
Evaluation on epoch 83: loss: 1.605, acc1_cls: 75.424, acc5_cls: 86.441
{"train_lr": 7.875820121174359e-05, "train_loss_total": 0.10688065178692341, "train_loss_cls": 0.10688065178692341, "train_acc1_cls": 99.755859375, "train_acc5_cls": 100.0, "epoch": 83, "n_parameters": 613877740}
Evaluation on epoch 84: loss: 1.603, acc1_cls: 75.424, acc5_cls: 86.441
{"train_lr": 7.05593575115301e-05, "train_loss_total": 0.10692411381751299, "train_loss_cls": 0.10692411381751299, "train_acc1_cls": 99.90234375, "train_acc5_cls": 99.951171875, "epoch": 84, "n_parameters": 613877740}
Evaluation on epoch 85: loss: 1.602, acc1_cls: 75.636, acc5_cls: 86.229
{"train_lr": 6.278481331809015e-05, "train_loss_total": 0.11032880935817957, "train_loss_cls": 0.11032880935817957, "train_acc1_cls": 99.755859375, "train_acc5_cls": 100.0, "epoch": 85, "n_parameters": 613877740}
Evaluation on epoch 86: loss: 1.597, acc1_cls: 75.212, acc5_cls: 86.017
{"train_lr": 5.544224116791029e-05, "train_loss_total": 0.10672296676784754, "train_loss_cls": 0.10672296676784754, "train_acc1_cls": 99.853515625, "train_acc5_cls": 100.0, "epoch": 86, "n_parameters": 613877740}
Evaluation on epoch 87: loss: 1.596, acc1_cls: 75.212, acc5_cls: 86.441
{"train_lr": 4.853888729322333e-05, "train_loss_total": 0.10630917549133301, "train_loss_cls": 0.10630917549133301, "train_acc1_cls": 99.951171875, "train_acc5_cls": 100.0, "epoch": 87, "n_parameters": 613877740}
Evaluation on epoch 88: loss: 1.593, acc1_cls: 75.000, acc5_cls: 86.653
{"train_lr": 4.2081564470851536e-05, "train_loss_total": 0.103892358019948, "train_loss_cls": 0.103892358019948, "train_acc1_cls": 99.8046875, "train_acc5_cls": 100.0, "epoch": 88, "n_parameters": 613877740}
Evaluation on epoch 89: loss: 1.591, acc1_cls: 74.788, acc5_cls: 86.441
{"train_lr": 3.6076645298818454e-05, "train_loss_total": 0.11877519264817238, "train_loss_cls": 0.11877519264817238, "train_acc1_cls": 99.560546875, "train_acc5_cls": 99.951171875, "epoch": 89, "n_parameters": 613877740}
Evaluation on epoch 90: loss: 1.588, acc1_cls: 75.000, acc5_cls: 86.441
{"train_lr": 3.0530055907364385e-05, "train_loss_total": 0.111789895221591, "train_loss_cls": 0.111789895221591, "train_acc1_cls": 99.90234375, "train_acc5_cls": 100.0, "epoch": 90, "n_parameters": 613877740}
Evaluation on epoch 91: loss: 1.583, acc1_cls: 75.212, acc5_cls: 86.441
{"train_lr": 2.5447270110570814e-05, "train_loss_total": 0.106326999142766, "train_loss_cls": 0.106326999142766, "train_acc1_cls": 99.90234375, "train_acc5_cls": 100.0, "epoch": 91, "n_parameters": 613877740}
Evaluation on epoch 92: loss: 1.583, acc1_cls: 74.788, acc5_cls: 86.864
{"train_lr": 2.0833304004366997e-05, "train_loss_total": 0.10275510512292385, "train_loss_cls": 0.10275510512292385, "train_acc1_cls": 99.853515625, "train_acc5_cls": 100.0, "epoch": 92, "n_parameters": 613877740}
Evaluation on epoch 93: loss: 1.580, acc1_cls: 75.212, acc5_cls: 86.864
{"train_lr": 1.6692711016248837e-05, "train_loss_total": 0.09406931139528751, "train_loss_cls": 0.09406931139528751, "train_acc1_cls": 99.951171875, "train_acc5_cls": 100.0, "epoch": 93, "n_parameters": 613877740}
Evaluation on epoch 94: loss: 1.580, acc1_cls: 75.636, acc5_cls: 86.864
{"train_lr": 1.3029577411595713e-05, "train_loss_total": 0.10674277879297733, "train_loss_cls": 0.10674277879297733, "train_acc1_cls": 99.8046875, "train_acc5_cls": 100.0, "epoch": 94, "n_parameters": 613877740}
Evaluation on epoch 95: loss: 1.580, acc1_cls: 75.847, acc5_cls: 86.653
{"train_lr": 9.847518261019985e-06, "train_loss_total": 0.09245847538113594, "train_loss_cls": 0.09245847538113594, "train_acc1_cls": 99.90234375, "train_acc5_cls": 100.0, "epoch": 95, "n_parameters": 613877740}
Evaluation on epoch 96: loss: 1.579, acc1_cls: 76.059, acc5_cls: 86.864
{"train_lr": 7.149673872728739e-06, "train_loss_total": 0.10785257536917925, "train_loss_cls": 0.10785257536917925, "train_acc1_cls": 99.853515625, "train_acc5_cls": 99.951171875, "epoch": 96, "n_parameters": 613877740}
Evaluation on epoch 97: loss: 1.576, acc1_cls: 76.059, acc5_cls: 86.653
{"train_lr": 4.938706693418357e-06, "train_loss_total": 0.11358544696122408, "train_loss_cls": 0.11358544696122408, "train_acc1_cls": 99.90234375, "train_acc5_cls": 99.951171875, "epoch": 97, "n_parameters": 613877740}
Evaluation on epoch 98: loss: 1.576, acc1_cls: 76.059, acc5_cls: 87.288
{"train_lr": 3.2167986807615416e-06, "train_loss_total": 0.09369305428117514, "train_loss_cls": 0.09369305428117514, "train_acc1_cls": 99.951171875, "train_acc5_cls": 100.0, "epoch": 98, "n_parameters": 613877740}
Evaluation on epoch 99: loss: 1.573, acc1_cls: 75.212, acc5_cls: 87.288
{"train_lr": 1.9856491500783564e-06, "train_loss_total": 0.10850299708545208, "train_loss_cls": 0.10850299708545208, "train_acc1_cls": 99.951171875, "train_acc5_cls": 100.0, "epoch": 99, "n_parameters": 613877740}
