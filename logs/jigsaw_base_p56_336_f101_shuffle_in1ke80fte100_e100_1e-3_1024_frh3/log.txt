batch_size: 256
epochs: 100
bce_loss: True
unscale_lr: True
rec: False
freeze: True
model: jigsaw_base_patch56_336
input_size: 336
permcls: 50
drop: 0.0
drop_path: 0.1
model_ema: True
model_ema_decay: 0.99996
model_ema_force_cpu: False
opt: adamw
opt_eps: 1e-08
opt_betas: None
clip_grad: None
momentum: 0.9
weight_decay: 0.05
sched: cosine
lr: 0.001
lr_noise: None
lr_noise_pct: 0.67
lr_noise_std: 1.0
warmup_lr: 1e-06
min_lr: 1e-05
decay_epochs: 30
warmup_epochs: 0
cooldown_epochs: 10
patience_epochs: 10
decay_rate: 0.1
color_jitter: 0.3
aa: rand-m9-mstd0.5-inc1
smoothing: None
train_interpolation: bicubic
repeated_aug: True
train_mode: True
ThreeAugment: False
src: False
reprob: 0.25
remode: pixel
recount: 1
resplit: False
mixup: 0.0
cutmix: 0.0
cutmix_minmax: None
mixup_prob: 1.0
mixup_switch_prob: 0.5
mixup_mode: batch
teacher_model: regnety_160
teacher_path: 
distillation_type: none
distillation_alpha: 0.5
distillation_tau: 1.0
finetune: ./outputs/jigsaw_base_p56_336_f101_shuffle_in1ke10fte300/best_checkpoint_e100.pth
attn_only: False
data_path: ./data/food101/
data_set: IMNET
nb_classes: 50
inat_category: name
output_dir: ./outputs/jigsaw_base_p56_336_f101_shuffle_in1ke80fte100_e100_1e-3_1024_frh3
log_dir: ./logs/jigsaw_base_p56_336_f101_shuffle_in1ke80fte100_e100_1e-3_1024_frh3
device: cuda
seed: 0
resume: 
start_epoch: 0
eval: False
eval_crop_ratio: 0.875
dist_eval: False
num_workers: 10
pin_mem: True
world_size: 4
dist_url: env://
local_rank: 0
use_jigsaw: True
use_cls: True
lambda_rec: 0.1
mask_ratio: 0.0
rank: 0
gpu: 0
distributed: True
dist_backend: nccl

Evaluation on epoch 0: loss: 8.944, acc1_cls: 2.542, acc5_cls: 11.441
{"train_lr": 0.001, "train_loss_total": 4.3937249183654785, "train_loss_cls": 4.3937249183654785, "train_acc1_cls": 2.490234375, "train_acc5_cls": 10.25390625, "epoch": 0, "n_parameters": 93623564}
Evaluation on epoch 1: loss: 6.954, acc1_cls: 3.390, acc5_cls: 13.347
{"train_lr": 0.001, "train_loss_total": 4.226589798927307, "train_loss_cls": 4.226589798927307, "train_acc1_cls": 4.248046875, "train_acc5_cls": 13.96484375, "epoch": 1, "n_parameters": 93623564}
Evaluation on epoch 2: loss: 5.558, acc1_cls: 4.449, acc5_cls: 18.432
{"train_lr": 0.0009997557473810372, "train_loss_total": 3.9421314001083374, "train_loss_cls": 3.9421314001083374, "train_acc1_cls": 6.8359375, "train_acc5_cls": 21.484375, "epoch": 2, "n_parameters": 93623564}
Evaluation on epoch 3: loss: 4.773, acc1_cls: 7.627, acc5_cls: 20.975
{"train_lr": 0.0009990232305719944, "train_loss_total": 3.7105876803398132, "train_loss_cls": 3.7105876803398132, "train_acc1_cls": 10.546875, "train_acc5_cls": 28.125, "epoch": 3, "n_parameters": 93623564}
Evaluation on epoch 4: loss: 4.336, acc1_cls: 8.051, acc5_cls: 26.483
{"train_lr": 0.0009978031724785245, "train_loss_total": 3.608550101518631, "train_loss_cls": 3.608550101518631, "train_acc1_cls": 14.404296875, "train_acc5_cls": 33.642578125, "epoch": 4, "n_parameters": 93623564}
Evaluation on epoch 5: loss: 4.100, acc1_cls: 10.169, acc5_cls: 28.602
{"train_lr": 0.0009960967771506667, "train_loss_total": 3.466972440481186, "train_loss_cls": 3.466972440481186, "train_acc1_cls": 18.5546875, "train_acc5_cls": 38.0859375, "epoch": 5, "n_parameters": 93623564}
Evaluation on epoch 6: loss: 3.964, acc1_cls: 11.653, acc5_cls: 30.297
{"train_lr": 0.0009939057285945933, "train_loss_total": 3.2981238961219788, "train_loss_cls": 3.2981238961219788, "train_acc1_cls": 23.486328125, "train_acc5_cls": 45.556640625, "epoch": 6, "n_parameters": 93623564}
Evaluation on epoch 7: loss: 3.855, acc1_cls: 14.619, acc5_cls: 33.475
{"train_lr": 0.000991232189110701, "train_loss_total": 3.1693824529647827, "train_loss_cls": 3.1693824529647827, "train_acc1_cls": 27.587890625, "train_acc5_cls": 48.6328125, "epoch": 7, "n_parameters": 93623564}
Evaluation on epoch 8: loss: 3.733, acc1_cls: 16.737, acc5_cls: 35.169
{"train_lr": 0.00098807879715968, "train_loss_total": 3.146325260400772, "train_loss_cls": 3.146325260400772, "train_acc1_cls": 28.515625, "train_acc5_cls": 50.390625, "epoch": 8, "n_parameters": 93623564}
Evaluation on epoch 9: loss: 3.616, acc1_cls: 18.856, acc5_cls: 37.924
{"train_lr": 0.0009844486647586723, "train_loss_total": 3.0010249614715576, "train_loss_cls": 3.0010249614715576, "train_acc1_cls": 32.470703125, "train_acc5_cls": 54.78515625, "epoch": 9, "n_parameters": 93623564}
Evaluation on epoch 10: loss: 3.549, acc1_cls: 20.975, acc5_cls: 38.347
{"train_lr": 0.0009803453744100868, "train_loss_total": 2.986752539873123, "train_loss_cls": 2.986752539873123, "train_acc1_cls": 34.08203125, "train_acc5_cls": 54.931640625, "epoch": 10, "n_parameters": 93623564}
Evaluation on epoch 11: loss: 3.510, acc1_cls: 20.339, acc5_cls: 41.314
{"train_lr": 0.0009757729755661011, "train_loss_total": 2.8964962363243103, "train_loss_cls": 2.8964962363243103, "train_acc1_cls": 37.890625, "train_acc5_cls": 58.544921875, "epoch": 11, "n_parameters": 93623564}
Evaluation on epoch 12: loss: 3.448, acc1_cls: 21.822, acc5_cls: 42.585
{"train_lr": 0.0009707359806323416, "train_loss_total": 2.823080688714981, "train_loss_cls": 2.823080688714981, "train_acc1_cls": 38.427734375, "train_acc5_cls": 59.765625, "epoch": 12, "n_parameters": 93623564}
Evaluation on epoch 13: loss: 3.401, acc1_cls: 21.822, acc5_cls: 42.797
{"train_lr": 0.0009652393605146844, "train_loss_total": 2.7817249298095703, "train_loss_cls": 2.7817249298095703, "train_acc1_cls": 41.064453125, "train_acc5_cls": 60.83984375, "epoch": 13, "n_parameters": 93623564}
Evaluation on epoch 14: loss: 3.325, acc1_cls: 24.788, acc5_cls: 41.737
{"train_lr": 0.0009592885397135706, "train_loss_total": 2.7651093304157257, "train_loss_cls": 2.7651093304157257, "train_acc1_cls": 40.283203125, "train_acc5_cls": 61.42578125, "epoch": 14, "n_parameters": 93623564}
Evaluation on epoch 15: loss: 3.270, acc1_cls: 25.424, acc5_cls: 44.703
{"train_lr": 0.0009528893909706797, "train_loss_total": 2.6894355714321136, "train_loss_cls": 2.6894355714321136, "train_acc1_cls": 43.212890625, "train_acc5_cls": 64.16015625, "epoch": 15, "n_parameters": 93623564}
Evaluation on epoch 16: loss: 3.231, acc1_cls: 26.271, acc5_cls: 46.186
{"train_lr": 0.0009460482294732421, "train_loss_total": 2.7093739211559296, "train_loss_cls": 2.7093739211559296, "train_acc1_cls": 42.822265625, "train_acc5_cls": 62.98828125, "epoch": 16, "n_parameters": 93623564}
Evaluation on epoch 17: loss: 3.195, acc1_cls: 27.754, acc5_cls: 46.398
{"train_lr": 0.0009387718066217125, "train_loss_total": 2.571934938430786, "train_loss_cls": 2.571934938430786, "train_acc1_cls": 47.412109375, "train_acc5_cls": 66.650390625, "epoch": 17, "n_parameters": 93623564}
Evaluation on epoch 18: loss: 3.178, acc1_cls: 28.390, acc5_cls: 46.186
{"train_lr": 0.0009310673033669522, "train_loss_total": 2.626166492700577, "train_loss_cls": 2.626166492700577, "train_acc1_cls": 44.921875, "train_acc5_cls": 65.283203125, "epoch": 18, "n_parameters": 93623564}
Evaluation on epoch 19: loss: 3.188, acc1_cls: 26.695, acc5_cls: 47.246
{"train_lr": 0.0009229423231234975, "train_loss_total": 2.5431628227233887, "train_loss_cls": 2.5431628227233887, "train_acc1_cls": 49.31640625, "train_acc5_cls": 65.966796875, "epoch": 19, "n_parameters": 93623564}
Evaluation on epoch 20: loss: 3.188, acc1_cls: 25.000, acc5_cls: 48.093
{"train_lr": 0.0009144048842659081, "train_loss_total": 2.5650391280651093, "train_loss_cls": 2.5650391280651093, "train_acc1_cls": 48.291015625, "train_acc5_cls": 66.064453125, "epoch": 20, "n_parameters": 93623564}
Evaluation on epoch 21: loss: 3.160, acc1_cls: 26.059, acc5_cls: 49.364
{"train_lr": 0.000905463412215599, "train_loss_total": 2.5543686747550964, "train_loss_cls": 2.5543686747550964, "train_acc1_cls": 48.828125, "train_acc5_cls": 65.673828125, "epoch": 21, "n_parameters": 93623564}
Evaluation on epoch 22: loss: 3.116, acc1_cls: 28.814, acc5_cls: 50.424
{"train_lr": 0.0008961267311259666, "train_loss_total": 2.5232370495796204, "train_loss_cls": 2.5232370495796204, "train_acc1_cls": 49.21875, "train_acc5_cls": 68.45703125, "epoch": 22, "n_parameters": 93623564}
Evaluation on epoch 23: loss: 3.079, acc1_cls: 31.144, acc5_cls: 51.271
{"train_lr": 0.0008864040551740157, "train_loss_total": 2.479519307613373, "train_loss_cls": 2.479519307613373, "train_acc1_cls": 49.951171875, "train_acc5_cls": 68.45703125, "epoch": 23, "n_parameters": 93623564}
Evaluation on epoch 24: loss: 3.071, acc1_cls: 31.356, acc5_cls: 50.212
{"train_lr": 0.0008763049794670775, "train_loss_total": 2.464912235736847, "train_loss_cls": 2.464912235736847, "train_acc1_cls": 50.29296875, "train_acc5_cls": 68.45703125, "epoch": 24, "n_parameters": 93623564}
Evaluation on epoch 25: loss: 3.073, acc1_cls: 30.297, acc5_cls: 51.059
{"train_lr": 0.0008658394705735987, "train_loss_total": 2.4577210545539856, "train_loss_cls": 2.4577210545539856, "train_acc1_cls": 50.439453125, "train_acc5_cls": 69.04296875, "epoch": 25, "n_parameters": 93623564}
Evaluation on epoch 26: loss: 3.080, acc1_cls: 32.203, acc5_cls: 50.636
{"train_lr": 0.000855017856687341, "train_loss_total": 2.4199110865592957, "train_loss_cls": 2.4199110865592957, "train_acc1_cls": 51.5625, "train_acc5_cls": 70.80078125, "epoch": 26, "n_parameters": 93623564}
Evaluation on epoch 27: loss: 3.077, acc1_cls: 31.568, acc5_cls: 51.907
{"train_lr": 0.0008438508174347009, "train_loss_total": 2.336136519908905, "train_loss_cls": 2.336136519908905, "train_acc1_cls": 54.58984375, "train_acc5_cls": 73.095703125, "epoch": 27, "n_parameters": 93623564}
Evaluation on epoch 28: loss: 3.073, acc1_cls: 31.780, acc5_cls: 52.331
{"train_lr": 0.0008323493733352077, "train_loss_total": 2.3865297734737396, "train_loss_cls": 2.3865297734737396, "train_acc1_cls": 52.734375, "train_acc5_cls": 70.703125, "epoch": 28, "n_parameters": 93623564}
Evaluation on epoch 29: loss: 3.076, acc1_cls: 29.661, acc5_cls: 51.907
{"train_lr": 0.0008205248749256015, "train_loss_total": 2.412282884120941, "train_loss_cls": 2.412282884120941, "train_acc1_cls": 52.099609375, "train_acc5_cls": 71.09375, "epoch": 29, "n_parameters": 93623564}
Evaluation on epoch 30: loss: 3.069, acc1_cls: 30.932, acc5_cls: 52.754
{"train_lr": 0.0008083889915582234, "train_loss_total": 2.422087848186493, "train_loss_cls": 2.422087848186493, "train_acc1_cls": 51.611328125, "train_acc5_cls": 69.43359375, "epoch": 30, "n_parameters": 93623564}
Evaluation on epoch 31: loss: 3.066, acc1_cls: 31.568, acc5_cls: 52.542
{"train_lr": 0.0007959536998847743, "train_loss_total": 2.3305473923683167, "train_loss_cls": 2.3305473923683167, "train_acc1_cls": 54.19921875, "train_acc5_cls": 73.046875, "epoch": 31, "n_parameters": 93623564}
Evaluation on epoch 32: loss: 3.056, acc1_cls: 30.508, acc5_cls: 51.907
{"train_lr": 0.0007832312720368048, "train_loss_total": 2.346417784690857, "train_loss_cls": 2.346417784690857, "train_acc1_cls": 53.271484375, "train_acc5_cls": 73.291015625, "epoch": 32, "n_parameters": 93623564}
Evaluation on epoch 33: loss: 3.045, acc1_cls: 30.932, acc5_cls: 52.119
{"train_lr": 0.0007702342635146033, "train_loss_total": 2.2989520728588104, "train_loss_cls": 2.2989520728588104, "train_acc1_cls": 56.0546875, "train_acc5_cls": 73.4375, "epoch": 33, "n_parameters": 93623564}
Evaluation on epoch 34: loss: 3.037, acc1_cls: 31.568, acc5_cls: 51.907
{"train_lr": 0.0007569755007964338, "train_loss_total": 2.306798756122589, "train_loss_cls": 2.306798756122589, "train_acc1_cls": 55.46875, "train_acc5_cls": 73.4375, "epoch": 34, "n_parameters": 93623564}
Evaluation on epoch 35: loss: 3.033, acc1_cls: 31.356, acc5_cls: 51.271
{"train_lr": 0.000743468068680349, "train_loss_total": 2.303736090660095, "train_loss_cls": 2.303736090660095, "train_acc1_cls": 55.46875, "train_acc5_cls": 73.974609375, "epoch": 35, "n_parameters": 93623564}
Evaluation on epoch 36: loss: 3.033, acc1_cls: 31.568, acc5_cls: 52.119
{"train_lr": 0.0007297252973710757, "train_loss_total": 2.3136487305164337, "train_loss_cls": 2.3136487305164337, "train_acc1_cls": 53.955078125, "train_acc5_cls": 73.876953125, "epoch": 36, "n_parameters": 93623564}
Evaluation on epoch 37: loss: 3.035, acc1_cls: 31.356, acc5_cls: 52.119
{"train_lr": 0.000715760749324711, "train_loss_total": 2.2894297540187836, "train_loss_cls": 2.2894297540187836, "train_acc1_cls": 55.46875, "train_acc5_cls": 74.267578125, "epoch": 37, "n_parameters": 93623564}
Evaluation on epoch 38: loss: 3.037, acc1_cls: 31.780, acc5_cls: 52.119
{"train_lr": 0.0007015882058642164, "train_loss_total": 2.2369688153266907, "train_loss_cls": 2.2369688153266907, "train_acc1_cls": 57.12890625, "train_acc5_cls": 75.537109375, "epoch": 38, "n_parameters": 93623564}
Evaluation on epoch 39: loss: 3.037, acc1_cls: 31.992, acc5_cls: 52.331
{"train_lr": 0.0006872216535789157, "train_loss_total": 2.2389309406280518, "train_loss_cls": 2.2389309406280518, "train_acc1_cls": 57.71484375, "train_acc5_cls": 75.048828125, "epoch": 39, "n_parameters": 93623564}
Evaluation on epoch 40: loss: 3.040, acc1_cls: 33.475, acc5_cls: 51.907
{"train_lr": 0.0006726752705214194, "train_loss_total": 2.232614189386368, "train_loss_cls": 2.232614189386368, "train_acc1_cls": 56.54296875, "train_acc5_cls": 75.927734375, "epoch": 40, "n_parameters": 93623564}
Evaluation on epoch 41: loss: 3.049, acc1_cls: 31.780, acc5_cls: 51.695
{"train_lr": 0.000657963412215599, "train_loss_total": 2.243415057659149, "train_loss_cls": 2.243415057659149, "train_acc1_cls": 56.8359375, "train_acc5_cls": 75.537109375, "epoch": 41, "n_parameters": 93623564}
Evaluation on epoch 42: loss: 3.048, acc1_cls: 32.415, acc5_cls: 53.178
{"train_lr": 0.0006431005974894186, "train_loss_total": 2.245669186115265, "train_loss_cls": 2.245669186115265, "train_acc1_cls": 56.73828125, "train_acc5_cls": 76.123046875, "epoch": 42, "n_parameters": 93623564}
Evaluation on epoch 43: loss: 3.048, acc1_cls: 32.839, acc5_cls: 53.178
{"train_lr": 0.000628101494146603, "train_loss_total": 2.226371169090271, "train_loss_cls": 2.226371169090271, "train_acc1_cls": 58.837890625, "train_acc5_cls": 75.830078125, "epoch": 43, "n_parameters": 93623564}
Evaluation on epoch 44: loss: 3.042, acc1_cls: 33.686, acc5_cls: 53.178
{"train_lr": 0.0006129809044912887, "train_loss_total": 2.2314572632312775, "train_loss_cls": 2.2314572632312775, "train_acc1_cls": 56.982421875, "train_acc5_cls": 75.830078125, "epoch": 44, "n_parameters": 93623564}
Evaluation on epoch 45: loss: 3.035, acc1_cls: 32.415, acc5_cls: 51.695
{"train_lr": 0.0005977537507199338, "train_loss_total": 2.2407162487506866, "train_loss_cls": 2.2407162487506866, "train_acc1_cls": 56.787109375, "train_acc5_cls": 76.025390625, "epoch": 45, "n_parameters": 93623564}
Evaluation on epoch 46: loss: 3.037, acc1_cls: 33.051, acc5_cls: 52.542
{"train_lr": 0.0005824350601949143, "train_loss_total": 2.1773205399513245, "train_loss_cls": 2.1773205399513245, "train_acc1_cls": 59.27734375, "train_acc5_cls": 77.587890625, "epoch": 46, "n_parameters": 93623564}
Evaluation on epoch 47: loss: 3.033, acc1_cls: 33.263, acc5_cls: 51.907
{"train_lr": 0.0005670399506143307, "train_loss_total": 2.18437260389328, "train_loss_cls": 2.18437260389328, "train_acc1_cls": 57.861328125, "train_acc5_cls": 75.634765625, "epoch": 47, "n_parameters": 93623564}
Evaluation on epoch 48: loss: 3.025, acc1_cls: 33.686, acc5_cls: 52.542
{"train_lr": 0.0005515836150926646, "train_loss_total": 2.1619239449501038, "train_loss_cls": 2.1619239449501038, "train_acc1_cls": 59.375, "train_acc5_cls": 77.099609375, "epoch": 48, "n_parameters": 93623564}
Evaluation on epoch 49: loss: 3.016, acc1_cls: 33.263, acc5_cls: 51.695
{"train_lr": 0.0005360813071670102, "train_loss_total": 2.225023329257965, "train_loss_cls": 2.225023329257965, "train_acc1_cls": 56.0546875, "train_acc5_cls": 74.70703125, "epoch": 49, "n_parameters": 93623564}
Evaluation on epoch 50: loss: 3.008, acc1_cls: 33.263, acc5_cls: 52.331
{"train_lr": 0.0005205483257436735, "train_loss_total": 2.2085644900798798, "train_loss_cls": 2.2085644900798798, "train_acc1_cls": 58.447265625, "train_acc5_cls": 76.416015625, "epoch": 50, "n_parameters": 93623564}
Evaluation on epoch 51: loss: 3.006, acc1_cls: 34.746, acc5_cls: 52.331
{"train_lr": 0.000505, "train_loss_total": 2.1640601456165314, "train_loss_cls": 2.1640601456165314, "train_acc1_cls": 59.375, "train_acc5_cls": 76.66015625, "epoch": 51, "n_parameters": 93623564}
Evaluation on epoch 52: loss: 3.006, acc1_cls: 34.110, acc5_cls: 52.331
{"train_lr": 0.0004894516742563265, "train_loss_total": 2.179123342037201, "train_loss_cls": 2.179123342037201, "train_acc1_cls": 60.05859375, "train_acc5_cls": 77.24609375, "epoch": 52, "n_parameters": 93623564}
Evaluation on epoch 53: loss: 3.009, acc1_cls: 34.534, acc5_cls: 54.025
{"train_lr": 0.0004739186928329899, "train_loss_total": 2.1718839704990387, "train_loss_cls": 2.1718839704990387, "train_acc1_cls": 58.837890625, "train_acc5_cls": 76.025390625, "epoch": 53, "n_parameters": 93623564}
Evaluation on epoch 54: loss: 3.007, acc1_cls: 34.746, acc5_cls: 53.814
{"train_lr": 0.00045841638490733545, "train_loss_total": 2.176401525735855, "train_loss_cls": 2.176401525735855, "train_acc1_cls": 58.7890625, "train_acc5_cls": 76.220703125, "epoch": 54, "n_parameters": 93623564}
Evaluation on epoch 55: loss: 3.005, acc1_cls: 33.898, acc5_cls: 54.025
{"train_lr": 0.0004429600493856695, "train_loss_total": 2.172515630722046, "train_loss_cls": 2.172515630722046, "train_acc1_cls": 58.447265625, "train_acc5_cls": 76.7578125, "epoch": 55, "n_parameters": 93623564}
Evaluation on epoch 56: loss: 3.002, acc1_cls: 33.898, acc5_cls: 52.754
{"train_lr": 0.00042756493980508576, "train_loss_total": 2.175854355096817, "train_loss_cls": 2.175854355096817, "train_acc1_cls": 59.716796875, "train_acc5_cls": 77.1484375, "epoch": 56, "n_parameters": 93623564}
Evaluation on epoch 57: loss: 3.001, acc1_cls: 33.475, acc5_cls: 52.966
{"train_lr": 0.0004122462492800663, "train_loss_total": 2.100475564599037, "train_loss_cls": 2.100475564599037, "train_acc1_cls": 62.109375, "train_acc5_cls": 78.02734375, "epoch": 57, "n_parameters": 93623564}
Evaluation on epoch 58: loss: 2.999, acc1_cls: 33.686, acc5_cls: 52.119
{"train_lr": 0.0003970190955087116, "train_loss_total": 2.1147321164608, "train_loss_cls": 2.1147321164608, "train_acc1_cls": 60.693359375, "train_acc5_cls": 78.80859375, "epoch": 58, "n_parameters": 93623564}
Evaluation on epoch 59: loss: 2.999, acc1_cls: 33.686, acc5_cls: 52.966
{"train_lr": 0.00038189850585339686, "train_loss_total": 2.1377539336681366, "train_loss_cls": 2.1377539336681366, "train_acc1_cls": 59.912109375, "train_acc5_cls": 77.9296875, "epoch": 59, "n_parameters": 93623564}
Evaluation on epoch 60: loss: 2.999, acc1_cls: 34.322, acc5_cls: 53.178
{"train_lr": 0.00036689940251058157, "train_loss_total": 2.1485030949115753, "train_loss_cls": 2.1485030949115753, "train_acc1_cls": 58.7890625, "train_acc5_cls": 78.7109375, "epoch": 60, "n_parameters": 93623564}
Evaluation on epoch 61: loss: 2.995, acc1_cls: 34.322, acc5_cls: 53.602
{"train_lr": 0.0003520365877844012, "train_loss_total": 2.171918511390686, "train_loss_cls": 2.171918511390686, "train_acc1_cls": 57.421875, "train_acc5_cls": 76.513671875, "epoch": 61, "n_parameters": 93623564}
Evaluation on epoch 62: loss: 2.997, acc1_cls: 33.475, acc5_cls: 53.178
{"train_lr": 0.0003373247294785808, "train_loss_total": 2.102528691291809, "train_loss_cls": 2.102528691291809, "train_acc1_cls": 60.791015625, "train_acc5_cls": 78.61328125, "epoch": 62, "n_parameters": 93623564}
Evaluation on epoch 63: loss: 3.003, acc1_cls: 33.686, acc5_cls: 52.754
{"train_lr": 0.00032277834642108455, "train_loss_total": 2.1422320306301117, "train_loss_cls": 2.1422320306301117, "train_acc1_cls": 59.814453125, "train_acc5_cls": 77.734375, "epoch": 63, "n_parameters": 93623564}
Evaluation on epoch 64: loss: 3.003, acc1_cls: 33.051, acc5_cls: 52.542
{"train_lr": 0.0003084117941357836, "train_loss_total": 2.19152969121933, "train_loss_cls": 2.19152969121933, "train_acc1_cls": 58.349609375, "train_acc5_cls": 75.439453125, "epoch": 64, "n_parameters": 93623564}
Evaluation on epoch 65: loss: 3.002, acc1_cls: 32.839, acc5_cls: 51.907
{"train_lr": 0.0002942392506752891, "train_loss_total": 2.047513008117676, "train_loss_cls": 2.047513008117676, "train_acc1_cls": 62.548828125, "train_acc5_cls": 79.8828125, "epoch": 65, "n_parameters": 93623564}
Evaluation on epoch 66: loss: 3.001, acc1_cls: 32.839, acc5_cls: 51.907
{"train_lr": 0.0002802747026289244, "train_loss_total": 2.13643117249012, "train_loss_cls": 2.13643117249012, "train_acc1_cls": 60.498046875, "train_acc5_cls": 76.85546875, "epoch": 66, "n_parameters": 93623564}
Evaluation on epoch 67: loss: 2.999, acc1_cls: 32.839, acc5_cls: 52.542
{"train_lr": 0.0002665319313196509, "train_loss_total": 2.081577390432358, "train_loss_cls": 2.081577390432358, "train_acc1_cls": 61.9140625, "train_acc5_cls": 79.296875, "epoch": 67, "n_parameters": 93623564}
Evaluation on epoch 68: loss: 2.999, acc1_cls: 33.898, acc5_cls: 52.542
{"train_lr": 0.0002530244992035662, "train_loss_total": 2.0654444992542267, "train_loss_cls": 2.0654444992542267, "train_acc1_cls": 61.1328125, "train_acc5_cls": 79.78515625, "epoch": 68, "n_parameters": 93623564}
Evaluation on epoch 69: loss: 2.997, acc1_cls: 33.475, acc5_cls: 53.390
{"train_lr": 0.00023976573648539653, "train_loss_total": 2.1258602291345596, "train_loss_cls": 2.1258602291345596, "train_acc1_cls": 59.814453125, "train_acc5_cls": 77.63671875, "epoch": 69, "n_parameters": 93623564}
Evaluation on epoch 70: loss: 2.996, acc1_cls: 34.110, acc5_cls: 52.754
{"train_lr": 0.0002267687279631953, "train_loss_total": 2.141642779111862, "train_loss_cls": 2.141642779111862, "train_acc1_cls": 59.765625, "train_acc5_cls": 77.490234375, "epoch": 70, "n_parameters": 93623564}
Evaluation on epoch 71: loss: 2.995, acc1_cls: 33.686, acc5_cls: 52.331
{"train_lr": 0.00021404630011522585, "train_loss_total": 2.119477093219757, "train_loss_cls": 2.119477093219757, "train_acc1_cls": 60.546875, "train_acc5_cls": 78.41796875, "epoch": 71, "n_parameters": 93623564}
Evaluation on epoch 72: loss: 2.994, acc1_cls: 33.263, acc5_cls: 52.966
{"train_lr": 0.00020161100844177658, "train_loss_total": 2.138576850295067, "train_loss_cls": 2.138576850295067, "train_acc1_cls": 60.25390625, "train_acc5_cls": 77.734375, "epoch": 72, "n_parameters": 93623564}
Evaluation on epoch 73: loss: 2.991, acc1_cls: 33.263, acc5_cls: 52.754
{"train_lr": 0.00018947512507439858, "train_loss_total": 2.1463428139686584, "train_loss_cls": 2.1463428139686584, "train_acc1_cls": 58.544921875, "train_acc5_cls": 77.978515625, "epoch": 73, "n_parameters": 93623564}
Evaluation on epoch 74: loss: 2.989, acc1_cls: 33.898, acc5_cls: 53.178
{"train_lr": 0.00017765062666479239, "train_loss_total": 2.111554265022278, "train_loss_cls": 2.111554265022278, "train_acc1_cls": 60.546875, "train_acc5_cls": 77.9296875, "epoch": 74, "n_parameters": 93623564}
Evaluation on epoch 75: loss: 2.986, acc1_cls: 33.475, acc5_cls: 53.178
{"train_lr": 0.00016614918256529907, "train_loss_total": 2.115539461374283, "train_loss_cls": 2.115539461374283, "train_acc1_cls": 60.400390625, "train_acc5_cls": 78.80859375, "epoch": 75, "n_parameters": 93623564}
Evaluation on epoch 76: loss: 2.984, acc1_cls: 33.051, acc5_cls: 53.390
{"train_lr": 0.000154982143312659, "train_loss_total": 2.0680891573429108, "train_loss_cls": 2.0680891573429108, "train_acc1_cls": 62.79296875, "train_acc5_cls": 80.46875, "epoch": 76, "n_parameters": 93623564}
Evaluation on epoch 77: loss: 2.983, acc1_cls: 33.898, acc5_cls: 53.390
{"train_lr": 0.0001441605294264014, "train_loss_total": 2.0484756529331207, "train_loss_cls": 2.0484756529331207, "train_acc1_cls": 62.255859375, "train_acc5_cls": 79.8828125, "epoch": 77, "n_parameters": 93623564}
Evaluation on epoch 78: loss: 2.981, acc1_cls: 33.898, acc5_cls: 53.178
{"train_lr": 0.0001336950205329225, "train_loss_total": 2.0908761471509933, "train_loss_cls": 2.0908761471509933, "train_acc1_cls": 60.546875, "train_acc5_cls": 78.7109375, "epoch": 78, "n_parameters": 93623564}
Evaluation on epoch 79: loss: 2.980, acc1_cls: 33.898, acc5_cls: 53.178
{"train_lr": 0.00012359594482598438, "train_loss_total": 2.086589962244034, "train_loss_cls": 2.086589962244034, "train_acc1_cls": 61.962890625, "train_acc5_cls": 78.3203125, "epoch": 79, "n_parameters": 93623564}
Evaluation on epoch 80: loss: 2.981, acc1_cls: 34.110, acc5_cls: 52.966
{"train_lr": 0.00011387326887403324, "train_loss_total": 2.107869327068329, "train_loss_cls": 2.107869327068329, "train_acc1_cls": 60.498046875, "train_acc5_cls": 78.22265625, "epoch": 80, "n_parameters": 93623564}
Evaluation on epoch 81: loss: 2.982, acc1_cls: 33.898, acc5_cls: 52.966
{"train_lr": 0.00010453658778440107, "train_loss_total": 2.032112345099449, "train_loss_cls": 2.032112345099449, "train_acc1_cls": 62.01171875, "train_acc5_cls": 81.34765625, "epoch": 81, "n_parameters": 93623564}
Evaluation on epoch 82: loss: 2.981, acc1_cls: 33.475, acc5_cls: 52.966
{"train_lr": 9.559511573409194e-05, "train_loss_total": 2.0953227877616882, "train_loss_cls": 2.0953227877616882, "train_acc1_cls": 61.083984375, "train_acc5_cls": 79.00390625, "epoch": 82, "n_parameters": 93623564}
Evaluation on epoch 83: loss: 2.981, acc1_cls: 33.263, acc5_cls: 53.390
{"train_lr": 8.705767687650265e-05, "train_loss_total": 1.9750800132751465, "train_loss_cls": 1.9750800132751465, "train_acc1_cls": 65.576171875, "train_acc5_cls": 81.396484375, "epoch": 83, "n_parameters": 93623564}
Evaluation on epoch 84: loss: 2.980, acc1_cls: 33.898, acc5_cls: 53.178
{"train_lr": 7.893269663304783e-05, "train_loss_total": 2.10809588432312, "train_loss_cls": 2.10809588432312, "train_acc1_cls": 60.498046875, "train_acc5_cls": 78.3203125, "epoch": 84, "n_parameters": 93623564}
Evaluation on epoch 85: loss: 2.978, acc1_cls: 34.322, acc5_cls: 53.390
{"train_lr": 7.122819337828752e-05, "train_loss_total": 2.1106537580490112, "train_loss_cls": 2.1106537580490112, "train_acc1_cls": 61.23046875, "train_acc5_cls": 79.00390625, "epoch": 85, "n_parameters": 93623564}
Evaluation on epoch 86: loss: 2.977, acc1_cls: 34.958, acc5_cls: 53.390
{"train_lr": 6.395177052675794e-05, "train_loss_total": 2.1571592688560486, "train_loss_cls": 2.1571592688560486, "train_acc1_cls": 58.3984375, "train_acc5_cls": 77.44140625, "epoch": 86, "n_parameters": 93623564}
Evaluation on epoch 87: loss: 2.977, acc1_cls: 35.169, acc5_cls: 53.602
{"train_lr": 5.711060902932042e-05, "train_loss_total": 2.07832869887352, "train_loss_cls": 2.07832869887352, "train_acc1_cls": 62.20703125, "train_acc5_cls": 79.150390625, "epoch": 87, "n_parameters": 93623564}
Evaluation on epoch 88: loss: 2.976, acc1_cls: 35.381, acc5_cls: 53.602
{"train_lr": 5.0711460286429444e-05, "train_loss_total": 1.9986648857593536, "train_loss_cls": 1.9986648857593536, "train_acc1_cls": 64.111328125, "train_acc5_cls": 82.2265625, "epoch": 88, "n_parameters": 93623564}
Evaluation on epoch 89: loss: 2.977, acc1_cls: 35.169, acc5_cls: 53.814
{"train_lr": 4.4760639485315584e-05, "train_loss_total": 2.122373878955841, "train_loss_cls": 2.122373878955841, "train_acc1_cls": 59.619140625, "train_acc5_cls": 78.61328125, "epoch": 89, "n_parameters": 93623564}
Evaluation on epoch 90: loss: 2.977, acc1_cls: 35.169, acc5_cls: 53.602
{"train_lr": 3.92640193676584e-05, "train_loss_total": 2.119410961866379, "train_loss_cls": 2.119410961866379, "train_acc1_cls": 60.05859375, "train_acc5_cls": 78.955078125, "epoch": 90, "n_parameters": 93623564}
Evaluation on epoch 91: loss: 2.978, acc1_cls: 34.746, acc5_cls: 53.602
{"train_lr": 3.4227024433899005e-05, "train_loss_total": 2.006348356604576, "train_loss_cls": 2.006348356604576, "train_acc1_cls": 64.306640625, "train_acc5_cls": 80.615234375, "epoch": 91, "n_parameters": 93623564}
Evaluation on epoch 92: loss: 2.979, acc1_cls: 35.169, acc5_cls: 53.178
{"train_lr": 2.9654625589913237e-05, "train_loss_total": 2.04295152425766, "train_loss_cls": 2.04295152425766, "train_acc1_cls": 61.669921875, "train_acc5_cls": 79.541015625, "epoch": 92, "n_parameters": 93623564}
Evaluation on epoch 93: loss: 2.978, acc1_cls: 35.593, acc5_cls: 53.178
{"train_lr": 2.5551335241327672e-05, "train_loss_total": 2.1041309237480164, "train_loss_cls": 2.1041309237480164, "train_acc1_cls": 61.279296875, "train_acc5_cls": 78.515625, "epoch": 93, "n_parameters": 93623564}
Evaluation on epoch 94: loss: 2.978, acc1_cls: 35.381, acc5_cls: 53.390
{"train_lr": 2.1921202840320077e-05, "train_loss_total": 2.0830164700746536, "train_loss_cls": 2.0830164700746536, "train_acc1_cls": 60.546875, "train_acc5_cls": 79.638671875, "epoch": 94, "n_parameters": 93623564}
Evaluation on epoch 95: loss: 2.977, acc1_cls: 34.958, acc5_cls: 53.602
{"train_lr": 1.8767810889299086e-05, "train_loss_total": 1.998030573129654, "train_loss_cls": 1.998030573129654, "train_acc1_cls": 64.0625, "train_acc5_cls": 81.15234375, "epoch": 95, "n_parameters": 93623564}
Evaluation on epoch 96: loss: 2.977, acc1_cls: 35.381, acc5_cls: 53.814
{"train_lr": 1.609427140540686e-05, "train_loss_total": 2.059216648340225, "train_loss_cls": 2.059216648340225, "train_acc1_cls": 62.646484375, "train_acc5_cls": 79.931640625, "epoch": 96, "n_parameters": 93623564}
Evaluation on epoch 97: loss: 2.977, acc1_cls: 35.381, acc5_cls: 53.814
{"train_lr": 1.3903222849333507e-05, "train_loss_total": 2.10814893245697, "train_loss_cls": 2.10814893245697, "train_acc1_cls": 59.9609375, "train_acc5_cls": 78.759765625, "epoch": 97, "n_parameters": 93623564}
Evaluation on epoch 98: loss: 2.976, acc1_cls: 34.746, acc5_cls: 53.814
{"train_lr": 1.2196827521475402e-05, "train_loss_total": 2.1240997314453125, "train_loss_cls": 2.1240997314453125, "train_acc1_cls": 59.716796875, "train_acc5_cls": 78.173828125, "epoch": 98, "n_parameters": 93623564}
Evaluation on epoch 99: loss: 2.976, acc1_cls: 34.958, acc5_cls: 53.390
{"train_lr": 1.0976769428005579e-05, "train_loss_total": 2.06503726541996, "train_loss_cls": 2.06503726541996, "train_acc1_cls": 62.109375, "train_acc5_cls": 80.615234375, "epoch": 99, "n_parameters": 93623564}
batch_size: 256
epochs: 100
bce_loss: True
unscale_lr: True
rec: False
freeze: True
model: jigsaw_base_patch56_336
input_size: 336
permcls: 50
drop: 0.0
drop_path: 0.1
model_ema: True
model_ema_decay: 0.99996
model_ema_force_cpu: False
opt: adamw
opt_eps: 1e-08
opt_betas: None
clip_grad: None
momentum: 0.9
weight_decay: 0.05
sched: cosine
lr: 0.001
lr_noise: None
lr_noise_pct: 0.67
lr_noise_std: 1.0
warmup_lr: 1e-06
min_lr: 1e-05
decay_epochs: 30
warmup_epochs: 0
cooldown_epochs: 10
patience_epochs: 10
decay_rate: 0.1
color_jitter: 0.3
aa: rand-m9-mstd0.5-inc1
smoothing: None
train_interpolation: bicubic
repeated_aug: True
train_mode: True
ThreeAugment: False
src: False
reprob: 0.25
remode: pixel
recount: 1
resplit: False
mixup: 0.0
cutmix: 0.0
cutmix_minmax: None
mixup_prob: 1.0
mixup_switch_prob: 0.5
mixup_mode: batch
teacher_model: regnety_160
teacher_path: 
distillation_type: none
distillation_alpha: 0.5
distillation_tau: 1.0
finetune: ./outputs/jigsaw_base_p56_336_f101_shuffle_in1ke10fte300/best_checkpoint_e100.pth
attn_only: False
data_path: ./data/food101/
data_set: IMNET
nb_classes: 50
inat_category: name
output_dir: ./outputs/jigsaw_base_p56_336_f101_shuffle_in1ke80fte100_e100_1e-3_1024_frh3
log_dir: ./logs/jigsaw_base_p56_336_f101_shuffle_in1ke80fte100_e100_1e-3_1024_frh3
device: cuda
seed: 0
resume: 
start_epoch: 0
eval: False
eval_crop_ratio: 0.875
dist_eval: False
num_workers: 10
pin_mem: True
world_size: 4
dist_url: env://
local_rank: 0
use_jigsaw: True
use_cls: True
lambda_rec: 0.1
mask_ratio: 0.0
rank: 0
gpu: 0
distributed: True
dist_backend: nccl

Evaluation on epoch 0: loss: 19.903, acc1_cls: 4.237, acc5_cls: 12.500
{"train_lr": 0.001, "train_loss_total": 4.265418529510498, "train_loss_cls": 4.265418529510498, "train_acc1_cls": 4.4921875, "train_acc5_cls": 14.599609375, "epoch": 0, "n_parameters": 99076076}
Evaluation on epoch 1: loss: 10.782, acc1_cls: 5.508, acc5_cls: 16.949
{"train_lr": 0.001, "train_loss_total": 3.613475114107132, "train_loss_cls": 3.613475114107132, "train_acc1_cls": 18.408203125, "train_acc5_cls": 34.9609375, "epoch": 1, "n_parameters": 99076076}
Evaluation on epoch 2: loss: 9.170, acc1_cls: 5.720, acc5_cls: 20.339
{"train_lr": 0.0009997557473810372, "train_loss_total": 3.26066055893898, "train_loss_cls": 3.26066055893898, "train_acc1_cls": 28.759765625, "train_acc5_cls": 45.703125, "epoch": 2, "n_parameters": 99076076}
Evaluation on epoch 3: loss: 7.175, acc1_cls: 10.169, acc5_cls: 21.398
{"train_lr": 0.0009990232305719944, "train_loss_total": 3.139570951461792, "train_loss_cls": 3.139570951461792, "train_acc1_cls": 31.591796875, "train_acc5_cls": 49.853515625, "epoch": 3, "n_parameters": 99076076}
Evaluation on epoch 4: loss: 5.649, acc1_cls: 12.076, acc5_cls: 29.025
{"train_lr": 0.0009978031724785245, "train_loss_total": 3.05070361495018, "train_loss_cls": 3.05070361495018, "train_acc1_cls": 34.08203125, "train_acc5_cls": 52.783203125, "epoch": 4, "n_parameters": 99076076}
Evaluation on epoch 5: loss: 6.424, acc1_cls: 4.873, acc5_cls: 28.814
{"train_lr": 0.0009960967771506667, "train_loss_total": 2.782168835401535, "train_loss_cls": 2.782168835401535, "train_acc1_cls": 40.91796875, "train_acc5_cls": 60.302734375, "epoch": 5, "n_parameters": 99076076}
Evaluation on epoch 6: loss: 5.504, acc1_cls: 6.992, acc5_cls: 29.873
{"train_lr": 0.0009939057285945933, "train_loss_total": 2.754195898771286, "train_loss_cls": 2.754195898771286, "train_acc1_cls": 42.431640625, "train_acc5_cls": 61.62109375, "epoch": 6, "n_parameters": 99076076}
Evaluation on epoch 7: loss: 4.520, acc1_cls: 11.017, acc5_cls: 34.322
{"train_lr": 0.000991232189110701, "train_loss_total": 2.6810794174671173, "train_loss_cls": 2.6810794174671173, "train_acc1_cls": 44.04296875, "train_acc5_cls": 61.962890625, "epoch": 7, "n_parameters": 99076076}
Evaluation on epoch 8: loss: 4.265, acc1_cls: 14.195, acc5_cls: 33.475
{"train_lr": 0.00098807879715968, "train_loss_total": 2.61690753698349, "train_loss_cls": 2.61690753698349, "train_acc1_cls": 45.654296875, "train_acc5_cls": 64.013671875, "epoch": 8, "n_parameters": 99076076}
Evaluation on epoch 9: loss: 3.919, acc1_cls: 17.373, acc5_cls: 38.347
{"train_lr": 0.0009844486647586723, "train_loss_total": 2.5639435946941376, "train_loss_cls": 2.5639435946941376, "train_acc1_cls": 46.630859375, "train_acc5_cls": 66.552734375, "epoch": 9, "n_parameters": 99076076}
Evaluation on epoch 10: loss: 3.615, acc1_cls: 20.127, acc5_cls: 39.619
{"train_lr": 0.0009803453744100868, "train_loss_total": 2.5692509412765503, "train_loss_cls": 2.5692509412765503, "train_acc1_cls": 45.068359375, "train_acc5_cls": 64.404296875, "epoch": 10, "n_parameters": 99076076}
Evaluation on epoch 11: loss: 3.356, acc1_cls: 24.788, acc5_cls: 45.763
{"train_lr": 0.0009757729755661011, "train_loss_total": 2.5698616206645966, "train_loss_cls": 2.5698616206645966, "train_acc1_cls": 48.4375, "train_acc5_cls": 65.8203125, "epoch": 11, "n_parameters": 99076076}
Evaluation on epoch 12: loss: 3.379, acc1_cls: 24.153, acc5_cls: 44.915
{"train_lr": 0.0009707359806323416, "train_loss_total": 2.4236687421798706, "train_loss_cls": 2.4236687421798706, "train_acc1_cls": 50.732421875, "train_acc5_cls": 69.287109375, "epoch": 12, "n_parameters": 99076076}
Evaluation on epoch 13: loss: 3.395, acc1_cls: 24.576, acc5_cls: 45.127
{"train_lr": 0.0009652393605146844, "train_loss_total": 2.4171670973300934, "train_loss_cls": 2.4171670973300934, "train_acc1_cls": 51.611328125, "train_acc5_cls": 70.166015625, "epoch": 13, "n_parameters": 99076076}
Evaluation on epoch 14: loss: 3.299, acc1_cls: 26.907, acc5_cls: 45.127
{"train_lr": 0.0009592885397135706, "train_loss_total": 2.450730860233307, "train_loss_cls": 2.450730860233307, "train_acc1_cls": 50.1953125, "train_acc5_cls": 69.091796875, "epoch": 14, "n_parameters": 99076076}
Evaluation on epoch 15: loss: 3.189, acc1_cls: 27.119, acc5_cls: 46.822
{"train_lr": 0.0009528893909706797, "train_loss_total": 2.34029021859169, "train_loss_cls": 2.34029021859169, "train_acc1_cls": 54.443359375, "train_acc5_cls": 71.630859375, "epoch": 15, "n_parameters": 99076076}
Evaluation on epoch 16: loss: 3.203, acc1_cls: 28.814, acc5_cls: 48.729
{"train_lr": 0.0009460482294732421, "train_loss_total": 2.355904668569565, "train_loss_cls": 2.355904668569565, "train_acc1_cls": 53.80859375, "train_acc5_cls": 71.435546875, "epoch": 16, "n_parameters": 99076076}
Evaluation on epoch 17: loss: 3.225, acc1_cls: 27.542, acc5_cls: 47.881
{"train_lr": 0.0009387718066217125, "train_loss_total": 2.2624631226062775, "train_loss_cls": 2.2624631226062775, "train_acc1_cls": 57.568359375, "train_acc5_cls": 74.51171875, "epoch": 17, "n_parameters": 99076076}
Evaluation on epoch 18: loss: 3.227, acc1_cls: 27.331, acc5_cls: 47.458
{"train_lr": 0.0009310673033669522, "train_loss_total": 2.274176448583603, "train_loss_cls": 2.274176448583603, "train_acc1_cls": 54.541015625, "train_acc5_cls": 75.0, "epoch": 18, "n_parameters": 99076076}
Evaluation on epoch 19: loss: 3.161, acc1_cls: 26.695, acc5_cls: 47.246
{"train_lr": 0.0009229423231234975, "train_loss_total": 2.234854370355606, "train_loss_cls": 2.234854370355606, "train_acc1_cls": 56.005859375, "train_acc5_cls": 73.828125, "epoch": 19, "n_parameters": 99076076}
Evaluation on epoch 20: loss: 3.177, acc1_cls: 26.483, acc5_cls: 48.517
{"train_lr": 0.0009144048842659081, "train_loss_total": 2.246670126914978, "train_loss_cls": 2.246670126914978, "train_acc1_cls": 56.103515625, "train_acc5_cls": 75.439453125, "epoch": 20, "n_parameters": 99076076}
Evaluation on epoch 21: loss: 3.138, acc1_cls: 27.754, acc5_cls: 47.669
{"train_lr": 0.000905463412215599, "train_loss_total": 2.2401283979415894, "train_loss_cls": 2.2401283979415894, "train_acc1_cls": 57.666015625, "train_acc5_cls": 73.14453125, "epoch": 21, "n_parameters": 99076076}
Evaluation on epoch 22: loss: 3.110, acc1_cls: 30.297, acc5_cls: 47.669
{"train_lr": 0.0008961267311259666, "train_loss_total": 2.209893673658371, "train_loss_cls": 2.209893673658371, "train_acc1_cls": 57.421875, "train_acc5_cls": 76.806640625, "epoch": 22, "n_parameters": 99076076}
Evaluation on epoch 23: loss: 3.145, acc1_cls: 29.873, acc5_cls: 48.305
{"train_lr": 0.0008864040551740157, "train_loss_total": 2.1896473169326782, "train_loss_cls": 2.1896473169326782, "train_acc1_cls": 58.984375, "train_acc5_cls": 75.537109375, "epoch": 23, "n_parameters": 99076076}
Evaluation on epoch 24: loss: 3.170, acc1_cls: 27.542, acc5_cls: 48.093
{"train_lr": 0.0008763049794670775, "train_loss_total": 2.180573344230652, "train_loss_cls": 2.180573344230652, "train_acc1_cls": 58.0078125, "train_acc5_cls": 76.611328125, "epoch": 24, "n_parameters": 99076076}
Evaluation on epoch 25: loss: 3.098, acc1_cls: 30.932, acc5_cls: 50.847
{"train_lr": 0.0008658394705735987, "train_loss_total": 2.1874845027923584, "train_loss_cls": 2.1874845027923584, "train_acc1_cls": 58.447265625, "train_acc5_cls": 76.123046875, "epoch": 25, "n_parameters": 99076076}
Evaluation on epoch 26: loss: 3.106, acc1_cls: 31.144, acc5_cls: 52.331
{"train_lr": 0.000855017856687341, "train_loss_total": 2.1438222229480743, "train_loss_cls": 2.1438222229480743, "train_acc1_cls": 59.814453125, "train_acc5_cls": 77.24609375, "epoch": 26, "n_parameters": 99076076}
Evaluation on epoch 27: loss: 3.182, acc1_cls: 25.636, acc5_cls: 50.000
{"train_lr": 0.0008438508174347009, "train_loss_total": 2.0667457282543182, "train_loss_cls": 2.0667457282543182, "train_acc1_cls": 62.01171875, "train_acc5_cls": 78.369140625, "epoch": 27, "n_parameters": 99076076}
Evaluation on epoch 28: loss: 3.116, acc1_cls: 27.966, acc5_cls: 49.576
{"train_lr": 0.0008323493733352077, "train_loss_total": 2.1202137172222137, "train_loss_cls": 2.1202137172222137, "train_acc1_cls": 59.86328125, "train_acc5_cls": 78.076171875, "epoch": 28, "n_parameters": 99076076}
Evaluation on epoch 29: loss: 3.080, acc1_cls: 28.390, acc5_cls: 49.364
{"train_lr": 0.0008205248749256015, "train_loss_total": 2.1651305854320526, "train_loss_cls": 2.1651305854320526, "train_acc1_cls": 58.49609375, "train_acc5_cls": 77.587890625, "epoch": 29, "n_parameters": 99076076}
Evaluation on epoch 30: loss: 3.124, acc1_cls: 27.331, acc5_cls: 49.364
{"train_lr": 0.0008083889915582234, "train_loss_total": 2.122338145971298, "train_loss_cls": 2.122338145971298, "train_acc1_cls": 58.203125, "train_acc5_cls": 77.880859375, "epoch": 30, "n_parameters": 99076076}
Evaluation on epoch 31: loss: 3.146, acc1_cls: 27.754, acc5_cls: 48.729
{"train_lr": 0.0007959536998847743, "train_loss_total": 2.080820322036743, "train_loss_cls": 2.080820322036743, "train_acc1_cls": 62.01171875, "train_acc5_cls": 79.1015625, "epoch": 31, "n_parameters": 99076076}
Evaluation on epoch 32: loss: 3.119, acc1_cls: 31.144, acc5_cls: 49.788
{"train_lr": 0.0007832312720368048, "train_loss_total": 2.08602437376976, "train_loss_cls": 2.08602437376976, "train_acc1_cls": 63.134765625, "train_acc5_cls": 79.248046875, "epoch": 32, "n_parameters": 99076076}
Evaluation on epoch 33: loss: 3.124, acc1_cls: 27.542, acc5_cls: 50.424
{"train_lr": 0.0007702342635146033, "train_loss_total": 1.9996739625930786, "train_loss_cls": 1.9996739625930786, "train_acc1_cls": 64.6484375, "train_acc5_cls": 80.859375, "epoch": 33, "n_parameters": 99076076}
Evaluation on epoch 34: loss: 3.158, acc1_cls: 25.000, acc5_cls: 49.153
{"train_lr": 0.0007569755007964338, "train_loss_total": 2.021056666970253, "train_loss_cls": 2.021056666970253, "train_acc1_cls": 63.232421875, "train_acc5_cls": 80.37109375, "epoch": 34, "n_parameters": 99076076}
Evaluation on epoch 35: loss: 3.068, acc1_cls: 30.932, acc5_cls: 51.271
{"train_lr": 0.000743468068680349, "train_loss_total": 1.9895651787519455, "train_loss_cls": 1.9895651787519455, "train_acc1_cls": 65.13671875, "train_acc5_cls": 81.494140625, "epoch": 35, "n_parameters": 99076076}
Evaluation on epoch 36: loss: 3.056, acc1_cls: 31.144, acc5_cls: 49.153
{"train_lr": 0.0007297252973710757, "train_loss_total": 1.988569736480713, "train_loss_cls": 1.988569736480713, "train_acc1_cls": 63.232421875, "train_acc5_cls": 80.322265625, "epoch": 36, "n_parameters": 99076076}
Evaluation on epoch 37: loss: 3.068, acc1_cls: 30.720, acc5_cls: 50.424
{"train_lr": 0.000715760749324711, "train_loss_total": 1.9961843490600586, "train_loss_cls": 1.9961843490600586, "train_acc1_cls": 65.4296875, "train_acc5_cls": 79.248046875, "epoch": 37, "n_parameters": 99076076}
Evaluation on epoch 38: loss: 3.063, acc1_cls: 28.814, acc5_cls: 51.271
{"train_lr": 0.0007015882058642164, "train_loss_total": 1.93328857421875, "train_loss_cls": 1.93328857421875, "train_acc1_cls": 66.6015625, "train_acc5_cls": 81.494140625, "epoch": 38, "n_parameters": 99076076}
Evaluation on epoch 39: loss: 3.072, acc1_cls: 30.297, acc5_cls: 50.847
{"train_lr": 0.0006872216535789157, "train_loss_total": 1.9499540328979492, "train_loss_cls": 1.9499540328979492, "train_acc1_cls": 65.13671875, "train_acc5_cls": 81.689453125, "epoch": 39, "n_parameters": 99076076}
Evaluation on epoch 40: loss: 3.112, acc1_cls: 28.602, acc5_cls: 50.847
{"train_lr": 0.0006726752705214194, "train_loss_total": 1.9693484455347061, "train_loss_cls": 1.9693484455347061, "train_acc1_cls": 63.330078125, "train_acc5_cls": 80.859375, "epoch": 40, "n_parameters": 99076076}
Evaluation on epoch 41: loss: 3.092, acc1_cls: 29.873, acc5_cls: 52.542
{"train_lr": 0.000657963412215599, "train_loss_total": 1.9105813652276993, "train_loss_cls": 1.9105813652276993, "train_acc1_cls": 66.796875, "train_acc5_cls": 83.0078125, "epoch": 41, "n_parameters": 99076076}
Evaluation on epoch 42: loss: 3.070, acc1_cls: 29.873, acc5_cls: 52.119
{"train_lr": 0.0006431005974894186, "train_loss_total": 1.9056451916694641, "train_loss_cls": 1.9056451916694641, "train_acc1_cls": 66.748046875, "train_acc5_cls": 82.421875, "epoch": 42, "n_parameters": 99076076}
Evaluation on epoch 43: loss: 3.059, acc1_cls: 29.449, acc5_cls: 51.059
{"train_lr": 0.000628101494146603, "train_loss_total": 1.8732738643884659, "train_loss_cls": 1.8732738643884659, "train_acc1_cls": 67.1875, "train_acc5_cls": 83.7890625, "epoch": 43, "n_parameters": 99076076}
Evaluation on epoch 44: loss: 3.056, acc1_cls: 31.144, acc5_cls: 51.059
{"train_lr": 0.0006129809044912887, "train_loss_total": 1.8990211188793182, "train_loss_cls": 1.8990211188793182, "train_acc1_cls": 66.6015625, "train_acc5_cls": 82.6171875, "epoch": 44, "n_parameters": 99076076}
Evaluation on epoch 45: loss: 3.044, acc1_cls: 32.627, acc5_cls: 51.695
{"train_lr": 0.0005977537507199338, "train_loss_total": 1.891906976699829, "train_loss_cls": 1.891906976699829, "train_acc1_cls": 66.9921875, "train_acc5_cls": 81.54296875, "epoch": 45, "n_parameters": 99076076}
Evaluation on epoch 46: loss: 3.028, acc1_cls: 33.475, acc5_cls: 52.966
{"train_lr": 0.0005824350601949143, "train_loss_total": 1.8214872628450394, "train_loss_cls": 1.8214872628450394, "train_acc1_cls": 69.482421875, "train_acc5_cls": 83.837890625, "epoch": 46, "n_parameters": 99076076}
Evaluation on epoch 47: loss: 3.046, acc1_cls: 32.627, acc5_cls: 51.695
{"train_lr": 0.0005670399506143307, "train_loss_total": 1.8004151731729507, "train_loss_cls": 1.8004151731729507, "train_acc1_cls": 69.3359375, "train_acc5_cls": 83.935546875, "epoch": 47, "n_parameters": 99076076}
Evaluation on epoch 48: loss: 3.048, acc1_cls: 29.661, acc5_cls: 51.907
{"train_lr": 0.0005515836150926646, "train_loss_total": 1.7914077937602997, "train_loss_cls": 1.7914077937602997, "train_acc1_cls": 69.873046875, "train_acc5_cls": 84.619140625, "epoch": 48, "n_parameters": 99076076}
Evaluation on epoch 49: loss: 3.024, acc1_cls: 31.144, acc5_cls: 52.754
{"train_lr": 0.0005360813071670102, "train_loss_total": 1.7993978708982468, "train_loss_cls": 1.7993978708982468, "train_acc1_cls": 68.45703125, "train_acc5_cls": 82.8125, "epoch": 49, "n_parameters": 99076076}
Evaluation on epoch 50: loss: 3.015, acc1_cls: 31.780, acc5_cls: 51.695
{"train_lr": 0.0005205483257436735, "train_loss_total": 1.7176715284585953, "train_loss_cls": 1.7176715284585953, "train_acc1_cls": 72.119140625, "train_acc5_cls": 85.693359375, "epoch": 50, "n_parameters": 99076076}
Evaluation on epoch 51: loss: 3.027, acc1_cls: 30.720, acc5_cls: 50.424
{"train_lr": 0.000505, "train_loss_total": 1.718358799815178, "train_loss_cls": 1.718358799815178, "train_acc1_cls": 70.8984375, "train_acc5_cls": 85.791015625, "epoch": 51, "n_parameters": 99076076}
Evaluation on epoch 52: loss: 3.007, acc1_cls: 31.992, acc5_cls: 52.331
{"train_lr": 0.0004894516742563265, "train_loss_total": 1.6798135489225388, "train_loss_cls": 1.6798135489225388, "train_acc1_cls": 72.802734375, "train_acc5_cls": 86.865234375, "epoch": 52, "n_parameters": 99076076}
Evaluation on epoch 53: loss: 3.000, acc1_cls: 33.263, acc5_cls: 52.331
{"train_lr": 0.0004739186928329899, "train_loss_total": 1.7155244201421738, "train_loss_cls": 1.7155244201421738, "train_acc1_cls": 71.435546875, "train_acc5_cls": 83.88671875, "epoch": 53, "n_parameters": 99076076}
Evaluation on epoch 54: loss: 3.010, acc1_cls: 34.110, acc5_cls: 52.754
{"train_lr": 0.00045841638490733545, "train_loss_total": 1.6781288534402847, "train_loss_cls": 1.6781288534402847, "train_acc1_cls": 72.607421875, "train_acc5_cls": 85.302734375, "epoch": 54, "n_parameters": 99076076}
Evaluation on epoch 55: loss: 3.005, acc1_cls: 32.203, acc5_cls: 53.814
{"train_lr": 0.0004429600493856695, "train_loss_total": 1.615701213479042, "train_loss_cls": 1.615701213479042, "train_acc1_cls": 74.51171875, "train_acc5_cls": 87.98828125, "epoch": 55, "n_parameters": 99076076}
Evaluation on epoch 56: loss: 3.012, acc1_cls: 30.085, acc5_cls: 53.602
{"train_lr": 0.00042756493980508576, "train_loss_total": 1.645732656121254, "train_loss_cls": 1.645732656121254, "train_acc1_cls": 73.193359375, "train_acc5_cls": 86.083984375, "epoch": 56, "n_parameters": 99076076}
Evaluation on epoch 57: loss: 3.010, acc1_cls: 30.932, acc5_cls: 53.390
{"train_lr": 0.0004122462492800663, "train_loss_total": 1.580132856965065, "train_loss_cls": 1.580132856965065, "train_acc1_cls": 75.1953125, "train_acc5_cls": 87.3046875, "epoch": 57, "n_parameters": 99076076}
Evaluation on epoch 58: loss: 2.989, acc1_cls: 32.203, acc5_cls: 54.873
{"train_lr": 0.0003970190955087116, "train_loss_total": 1.5616523027420044, "train_loss_cls": 1.5616523027420044, "train_acc1_cls": 75.927734375, "train_acc5_cls": 87.5, "epoch": 58, "n_parameters": 99076076}
Evaluation on epoch 59: loss: 2.989, acc1_cls: 32.627, acc5_cls: 54.025
{"train_lr": 0.00038189850585339686, "train_loss_total": 1.5715485364198685, "train_loss_cls": 1.5715485364198685, "train_acc1_cls": 75.78125, "train_acc5_cls": 87.744140625, "epoch": 59, "n_parameters": 99076076}
Evaluation on epoch 60: loss: 3.019, acc1_cls: 31.356, acc5_cls: 52.119
{"train_lr": 0.00036689940251058157, "train_loss_total": 1.5763910114765167, "train_loss_cls": 1.5763910114765167, "train_acc1_cls": 74.951171875, "train_acc5_cls": 87.79296875, "epoch": 60, "n_parameters": 99076076}
Evaluation on epoch 61: loss: 3.009, acc1_cls: 33.686, acc5_cls: 52.754
{"train_lr": 0.0003520365877844012, "train_loss_total": 1.5489225834608078, "train_loss_cls": 1.5489225834608078, "train_acc1_cls": 75.09765625, "train_acc5_cls": 87.548828125, "epoch": 61, "n_parameters": 99076076}
Evaluation on epoch 62: loss: 2.975, acc1_cls: 33.263, acc5_cls: 54.449
{"train_lr": 0.0003373247294785808, "train_loss_total": 1.5687674134969711, "train_loss_cls": 1.5687674134969711, "train_acc1_cls": 74.90234375, "train_acc5_cls": 86.5234375, "epoch": 62, "n_parameters": 99076076}
Evaluation on epoch 63: loss: 2.966, acc1_cls: 32.415, acc5_cls: 53.390
{"train_lr": 0.00032277834642108455, "train_loss_total": 1.5000442266464233, "train_loss_cls": 1.5000442266464233, "train_acc1_cls": 76.708984375, "train_acc5_cls": 88.57421875, "epoch": 63, "n_parameters": 99076076}
Evaluation on epoch 64: loss: 2.970, acc1_cls: 31.992, acc5_cls: 51.695
{"train_lr": 0.0003084117941357836, "train_loss_total": 1.4762691408395767, "train_loss_cls": 1.4762691408395767, "train_acc1_cls": 76.708984375, "train_acc5_cls": 87.890625, "epoch": 64, "n_parameters": 99076076}
Evaluation on epoch 65: loss: 2.955, acc1_cls: 33.051, acc5_cls: 53.178
{"train_lr": 0.0002942392506752891, "train_loss_total": 1.46206396818161, "train_loss_cls": 1.46206396818161, "train_acc1_cls": 77.294921875, "train_acc5_cls": 88.37890625, "epoch": 65, "n_parameters": 99076076}
Evaluation on epoch 66: loss: 2.939, acc1_cls: 33.475, acc5_cls: 53.602
{"train_lr": 0.0002802747026289244, "train_loss_total": 1.4295019060373306, "train_loss_cls": 1.4295019060373306, "train_acc1_cls": 78.02734375, "train_acc5_cls": 88.232421875, "epoch": 66, "n_parameters": 99076076}
Evaluation on epoch 67: loss: 2.928, acc1_cls: 33.475, acc5_cls: 54.025
{"train_lr": 0.0002665319313196509, "train_loss_total": 1.434086725115776, "train_loss_cls": 1.434086725115776, "train_acc1_cls": 78.955078125, "train_acc5_cls": 89.501953125, "epoch": 67, "n_parameters": 99076076}
Evaluation on epoch 68: loss: 2.921, acc1_cls: 33.051, acc5_cls: 53.178
{"train_lr": 0.0002530244992035662, "train_loss_total": 1.3160597532987595, "train_loss_cls": 1.3160597532987595, "train_acc1_cls": 82.373046875, "train_acc5_cls": 90.8203125, "epoch": 68, "n_parameters": 99076076}
Evaluation on epoch 69: loss: 2.905, acc1_cls: 33.051, acc5_cls: 55.720
{"train_lr": 0.00023976573648539653, "train_loss_total": 1.3564379215240479, "train_loss_cls": 1.3564379215240479, "train_acc1_cls": 79.638671875, "train_acc5_cls": 90.380859375, "epoch": 69, "n_parameters": 99076076}
Evaluation on epoch 70: loss: 2.907, acc1_cls: 33.051, acc5_cls: 54.661
{"train_lr": 0.0002267687279631953, "train_loss_total": 1.374785140156746, "train_loss_cls": 1.374785140156746, "train_acc1_cls": 79.8828125, "train_acc5_cls": 88.916015625, "epoch": 70, "n_parameters": 99076076}
Evaluation on epoch 71: loss: 2.914, acc1_cls: 33.475, acc5_cls: 54.025
{"train_lr": 0.00021404630011522585, "train_loss_total": 1.379292979836464, "train_loss_cls": 1.379292979836464, "train_acc1_cls": 78.662109375, "train_acc5_cls": 89.0625, "epoch": 71, "n_parameters": 99076076}
Evaluation on epoch 72: loss: 2.905, acc1_cls: 32.627, acc5_cls: 52.754
{"train_lr": 0.00020161100844177658, "train_loss_total": 1.3595528602600098, "train_loss_cls": 1.3595528602600098, "train_acc1_cls": 79.931640625, "train_acc5_cls": 89.2578125, "epoch": 72, "n_parameters": 99076076}
Evaluation on epoch 73: loss: 2.903, acc1_cls: 33.263, acc5_cls: 53.178
{"train_lr": 0.00018947512507439858, "train_loss_total": 1.366049364209175, "train_loss_cls": 1.366049364209175, "train_acc1_cls": 79.4921875, "train_acc5_cls": 89.453125, "epoch": 73, "n_parameters": 99076076}
Evaluation on epoch 74: loss: 2.888, acc1_cls: 33.686, acc5_cls: 53.602
{"train_lr": 0.00017765062666479239, "train_loss_total": 1.3565188944339752, "train_loss_cls": 1.3565188944339752, "train_acc1_cls": 80.17578125, "train_acc5_cls": 89.2578125, "epoch": 74, "n_parameters": 99076076}
Evaluation on epoch 75: loss: 2.867, acc1_cls: 33.475, acc5_cls: 52.754
{"train_lr": 0.00016614918256529907, "train_loss_total": 1.354273647069931, "train_loss_cls": 1.354273647069931, "train_acc1_cls": 79.541015625, "train_acc5_cls": 90.13671875, "epoch": 75, "n_parameters": 99076076}
Evaluation on epoch 76: loss: 2.853, acc1_cls: 34.534, acc5_cls: 54.025
{"train_lr": 0.000154982143312659, "train_loss_total": 1.2960631996393204, "train_loss_cls": 1.2960631996393204, "train_acc1_cls": 81.103515625, "train_acc5_cls": 90.576171875, "epoch": 76, "n_parameters": 99076076}
Evaluation on epoch 77: loss: 2.846, acc1_cls: 33.686, acc5_cls: 55.508
{"train_lr": 0.0001441605294264014, "train_loss_total": 1.252281293272972, "train_loss_cls": 1.252281293272972, "train_acc1_cls": 81.73828125, "train_acc5_cls": 91.064453125, "epoch": 77, "n_parameters": 99076076}
Evaluation on epoch 78: loss: 2.838, acc1_cls: 34.322, acc5_cls: 54.661
{"train_lr": 0.0001336950205329225, "train_loss_total": 1.3238837867975235, "train_loss_cls": 1.3238837867975235, "train_acc1_cls": 79.98046875, "train_acc5_cls": 90.087890625, "epoch": 78, "n_parameters": 99076076}
Evaluation on epoch 79: loss: 2.825, acc1_cls: 35.381, acc5_cls: 55.085
{"train_lr": 0.00012359594482598438, "train_loss_total": 1.2430941313505173, "train_loss_cls": 1.2430941313505173, "train_acc1_cls": 81.689453125, "train_acc5_cls": 90.576171875, "epoch": 79, "n_parameters": 99076076}
Evaluation on epoch 80: loss: 2.819, acc1_cls: 34.534, acc5_cls: 55.932
{"train_lr": 0.00011387326887403324, "train_loss_total": 1.2716780304908752, "train_loss_cls": 1.2716780304908752, "train_acc1_cls": 80.859375, "train_acc5_cls": 89.892578125, "epoch": 80, "n_parameters": 99076076}
Evaluation on epoch 81: loss: 2.816, acc1_cls: 35.169, acc5_cls: 55.297
{"train_lr": 0.00010453658778440107, "train_loss_total": 1.2360359728336334, "train_loss_cls": 1.2360359728336334, "train_acc1_cls": 82.03125, "train_acc5_cls": 90.966796875, "epoch": 81, "n_parameters": 99076076}
Evaluation on epoch 82: loss: 2.814, acc1_cls: 34.322, acc5_cls: 55.085
{"train_lr": 9.559511573409194e-05, "train_loss_total": 1.2857660949230194, "train_loss_cls": 1.2857660949230194, "train_acc1_cls": 80.76171875, "train_acc5_cls": 90.625, "epoch": 82, "n_parameters": 99076076}
Evaluation on epoch 83: loss: 2.813, acc1_cls: 34.958, acc5_cls: 55.720
{"train_lr": 8.705767687650265e-05, "train_loss_total": 1.1907086074352264, "train_loss_cls": 1.1907086074352264, "train_acc1_cls": 82.763671875, "train_acc5_cls": 91.259765625, "epoch": 83, "n_parameters": 99076076}
Evaluation on epoch 84: loss: 2.813, acc1_cls: 35.381, acc5_cls: 55.720
{"train_lr": 7.893269663304783e-05, "train_loss_total": 1.245527446269989, "train_loss_cls": 1.245527446269989, "train_acc1_cls": 81.689453125, "train_acc5_cls": 90.478515625, "epoch": 84, "n_parameters": 99076076}
Evaluation on epoch 85: loss: 2.807, acc1_cls: 35.805, acc5_cls: 55.297
{"train_lr": 7.122819337828752e-05, "train_loss_total": 1.209013670682907, "train_loss_cls": 1.209013670682907, "train_acc1_cls": 82.12890625, "train_acc5_cls": 90.625, "epoch": 85, "n_parameters": 99076076}
Evaluation on epoch 86: loss: 2.803, acc1_cls: 35.593, acc5_cls: 55.297
{"train_lr": 6.395177052675794e-05, "train_loss_total": 1.1947152763605118, "train_loss_cls": 1.1947152763605118, "train_acc1_cls": 82.421875, "train_acc5_cls": 91.943359375, "epoch": 86, "n_parameters": 99076076}
Evaluation on epoch 87: loss: 2.803, acc1_cls: 35.593, acc5_cls: 55.085
{"train_lr": 5.711060902932042e-05, "train_loss_total": 1.2213879376649857, "train_loss_cls": 1.2213879376649857, "train_acc1_cls": 81.15234375, "train_acc5_cls": 90.966796875, "epoch": 87, "n_parameters": 99076076}
Evaluation on epoch 88: loss: 2.799, acc1_cls: 36.229, acc5_cls: 55.085
{"train_lr": 5.0711460286429444e-05, "train_loss_total": 1.200427606701851, "train_loss_cls": 1.200427606701851, "train_acc1_cls": 82.421875, "train_acc5_cls": 91.650390625, "epoch": 88, "n_parameters": 99076076}
Evaluation on epoch 89: loss: 2.797, acc1_cls: 35.593, acc5_cls: 55.508
{"train_lr": 4.4760639485315584e-05, "train_loss_total": 1.2433720827102661, "train_loss_cls": 1.2433720827102661, "train_acc1_cls": 81.73828125, "train_acc5_cls": 90.72265625, "epoch": 89, "n_parameters": 99076076}
Evaluation on epoch 90: loss: 2.793, acc1_cls: 34.958, acc5_cls: 55.720
{"train_lr": 3.92640193676584e-05, "train_loss_total": 1.1761952638626099, "train_loss_cls": 1.1761952638626099, "train_acc1_cls": 83.88671875, "train_acc5_cls": 91.50390625, "epoch": 90, "n_parameters": 99076076}
Evaluation on epoch 91: loss: 2.790, acc1_cls: 35.593, acc5_cls: 55.508
{"train_lr": 3.4227024433899005e-05, "train_loss_total": 1.1841496676206589, "train_loss_cls": 1.1841496676206589, "train_acc1_cls": 82.568359375, "train_acc5_cls": 90.4296875, "epoch": 91, "n_parameters": 99076076}
Evaluation on epoch 92: loss: 2.786, acc1_cls: 36.017, acc5_cls: 56.356
{"train_lr": 2.9654625589913237e-05, "train_loss_total": 1.2147891819477081, "train_loss_cls": 1.2147891819477081, "train_acc1_cls": 81.689453125, "train_acc5_cls": 91.40625, "epoch": 92, "n_parameters": 99076076}
Evaluation on epoch 93: loss: 2.782, acc1_cls: 35.169, acc5_cls: 56.356
{"train_lr": 2.5551335241327672e-05, "train_loss_total": 1.186680644750595, "train_loss_cls": 1.186680644750595, "train_acc1_cls": 82.861328125, "train_acc5_cls": 91.748046875, "epoch": 93, "n_parameters": 99076076}
Evaluation on epoch 94: loss: 2.779, acc1_cls: 34.958, acc5_cls: 56.992
{"train_lr": 2.1921202840320077e-05, "train_loss_total": 1.227648749947548, "train_loss_cls": 1.227648749947548, "train_acc1_cls": 81.54296875, "train_acc5_cls": 90.52734375, "epoch": 94, "n_parameters": 99076076}
Evaluation on epoch 95: loss: 2.777, acc1_cls: 35.805, acc5_cls: 56.992
{"train_lr": 1.8767810889299086e-05, "train_loss_total": 1.1680363416671753, "train_loss_cls": 1.1680363416671753, "train_acc1_cls": 82.421875, "train_acc5_cls": 90.869140625, "epoch": 95, "n_parameters": 99076076}
