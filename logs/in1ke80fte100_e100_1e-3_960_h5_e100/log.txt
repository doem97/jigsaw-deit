batch_size: 240
epochs: 100
bce_loss: True
unscale_lr: True
rec: False
freeze: False
model: jigsaw_base_patch56_336
input_size: 336
permcls: 50
drop: 0.0
drop_path: 0.1
model_ema: True
model_ema_decay: 0.99996
model_ema_force_cpu: False
opt: adamw
opt_eps: 1e-08
opt_betas: None
clip_grad: None
momentum: 0.9
weight_decay: 0.05
sched: cosine
lr: 0.001
lr_noise: None
lr_noise_pct: 0.67
lr_noise_std: 1.0
warmup_lr: 1e-06
min_lr: 1e-06
decay_epochs: 30
warmup_epochs: 0
cooldown_epochs: 10
patience_epochs: 10
decay_rate: 0.1
color_jitter: 0.3
aa: rand-m9-mstd0.5-inc1
smoothing: None
train_interpolation: bicubic
repeated_aug: True
train_mode: True
ThreeAugment: False
src: False
reprob: 0.25
remode: pixel
recount: 1
resplit: False
mixup: 0.0
cutmix: 0.0
cutmix_minmax: None
mixup_prob: 1.0
mixup_switch_prob: 0.5
mixup_mode: batch
teacher_model: regnety_160
teacher_path: 
distillation_type: none
distillation_alpha: 0.5
distillation_tau: 1.0
finetune: ./outputs/jigsaw_base_p56_336_f101_shuffle_in1ke10fte300/best_checkpoint_e200.pth
attn_only: False
data_path: ./data/food101/
data_set: IMNET
nb_classes: 50
inat_category: name
output_dir: ./outputs/in1ke80fte100_e100_1e-3_960_h5_e100
log_dir: ./logs/in1ke80fte100_e100_1e-3_960_h5_e100
device: cuda
seed: 0
resume: 
start_epoch: 0
eval: False
eval_crop_ratio: 0.875
dist_eval: False
num_workers: 10
pin_mem: True
world_size: 4
dist_url: env://
local_rank: 0
use_jigsaw: True
use_cls: True
lambda_rec: 0.1
mask_ratio: 0.0
rank: 0
gpu: 0
distributed: True
dist_backend: nccl

Evaluation on epoch 0: loss: 25.429, acc1_cls: 1.907, acc5_cls: 10.381
{"train_lr": 0.001, "train_loss_total": 4.334462463855743, "train_loss_cls": 4.334462463855743, "train_acc1_cls": 2.5000001713633537, "train_acc5_cls": 10.364583790302277, "epoch": 0, "n_parameters": 617919468}
Evaluation on epoch 1: loss: 6.580, acc1_cls: 4.237, acc5_cls: 15.254
{"train_lr": 0.001, "train_loss_total": 4.256352186203003, "train_loss_cls": 4.256352186203003, "train_acc1_cls": 3.333333522081375, "train_acc5_cls": 13.593750715255737, "epoch": 1, "n_parameters": 617919468}
Evaluation on epoch 2: loss: 6.915, acc1_cls: 7.203, acc5_cls: 18.856
{"train_lr": 0.0009997535269026829, "train_loss_total": 4.058719098567963, "train_loss_cls": 4.058719098567963, "train_acc1_cls": 4.479166954755783, "train_acc5_cls": 16.666667699813843, "epoch": 2, "n_parameters": 617919468}
Evaluation on epoch 3: loss: 4.193, acc1_cls: 8.898, acc5_cls: 25.636
{"train_lr": 0.0009990143508499217, "train_loss_total": 3.890520602464676, "train_loss_cls": 3.890520602464676, "train_acc1_cls": 8.645833790302277, "train_acc5_cls": 24.062501192092896, "epoch": 3, "n_parameters": 617919468}
Evaluation on epoch 4: loss: 4.391, acc1_cls: 7.627, acc5_cls: 30.085
{"train_lr": 0.0009977832013192385, "train_loss_total": 3.6663797795772552, "train_loss_cls": 3.6663797795772552, "train_acc1_cls": 11.302083969116211, "train_acc5_cls": 30.000001668930054, "epoch": 4, "n_parameters": 617919468}
Evaluation on epoch 5: loss: 4.007, acc1_cls: 11.441, acc5_cls: 31.356
{"train_lr": 0.0009960612933065818, "train_loss_total": 3.5501458048820496, "train_loss_cls": 3.5501458048820496, "train_acc1_cls": 14.895833969116211, "train_acc5_cls": 34.583335161209106, "epoch": 5, "n_parameters": 617919468}
Evaluation on epoch 6: loss: 4.211, acc1_cls: 17.797, acc5_cls: 38.347
{"train_lr": 0.0009938503261272714, "train_loss_total": 3.4144055545330048, "train_loss_cls": 3.4144055545330048, "train_acc1_cls": 18.95833432674408, "train_acc5_cls": 39.427085876464844, "epoch": 6, "n_parameters": 617919468}
Evaluation on epoch 7: loss: 3.417, acc1_cls: 26.907, acc5_cls: 43.856
{"train_lr": 0.00099115248173898, "train_loss_total": 3.307608962059021, "train_loss_cls": 3.307608962059021, "train_acc1_cls": 22.39583468437195, "train_acc5_cls": 42.864585399627686, "epoch": 7, "n_parameters": 617919468}
Evaluation on epoch 8: loss: 3.132, acc1_cls: 25.212, acc5_cls: 49.364
{"train_lr": 0.0009879704225884043, "train_loss_total": 3.094790041446686, "train_loss_cls": 3.094790041446686, "train_acc1_cls": 28.281251668930054, "train_acc5_cls": 49.427086353302, "epoch": 8, "n_parameters": 617919468}
Evaluation on epoch 9: loss: 3.019, acc1_cls: 29.661, acc5_cls: 52.542
{"train_lr": 0.0009843072889837512, "train_loss_total": 2.8559070229530334, "train_loss_cls": 2.8559070229530334, "train_acc1_cls": 34.114585161209106, "train_acc5_cls": 55.62500286102295, "epoch": 9, "n_parameters": 617919468}
Evaluation on epoch 10: loss: 3.020, acc1_cls: 28.814, acc5_cls: 51.695
{"train_lr": 0.000980166695995633, "train_loss_total": 2.742050886154175, "train_loss_cls": 2.742050886154175, "train_acc1_cls": 38.90625238418579, "train_acc5_cls": 60.2604193687439, "epoch": 10, "n_parameters": 617919468}
Evaluation on epoch 11: loss: 2.740, acc1_cls: 36.229, acc5_cls: 56.144
{"train_lr": 0.0009755527298894294, "train_loss_total": 2.6591988801956177, "train_loss_cls": 2.6591988801956177, "train_acc1_cls": 42.7604193687439, "train_acc5_cls": 61.97917032241821, "epoch": 11, "n_parameters": 617919468}
Evaluation on epoch 12: loss: 2.514, acc1_cls: 41.102, acc5_cls: 63.983
{"train_lr": 0.0009704699440926358, "train_loss_total": 2.3305299282073975, "train_loss_cls": 2.3305299282073975, "train_acc1_cls": 52.4479193687439, "train_acc5_cls": 71.30208587646484, "epoch": 12, "n_parameters": 617919468}
Evaluation on epoch 13: loss: 2.331, acc1_cls: 48.729, acc5_cls: 69.280
{"train_lr": 0.0009649233547011816, "train_loss_total": 2.243761718273163, "train_loss_cls": 2.243761718273163, "train_acc1_cls": 55.052085399627686, "train_acc5_cls": 72.81250190734863, "epoch": 13, "n_parameters": 617919468}
Evaluation on epoch 14: loss: 2.177, acc1_cls: 50.847, acc5_cls: 71.822
{"train_lr": 0.0009589184355291487, "train_loss_total": 2.142864555120468, "train_loss_cls": 2.142864555120468, "train_acc1_cls": 57.13541889190674, "train_acc5_cls": 73.59375381469727, "epoch": 14, "n_parameters": 617919468}
Evaluation on epoch 15: loss: 2.182, acc1_cls: 55.085, acc5_cls: 73.093
{"train_lr": 0.0009524611127067769, "train_loss_total": 1.9768107235431671, "train_loss_cls": 1.9768107235431671, "train_acc1_cls": 60.8854193687439, "train_acc5_cls": 77.3437557220459, "epoch": 15, "n_parameters": 617919468}
Evaluation on epoch 16: loss: 2.347, acc1_cls: 52.754, acc5_cls: 69.492
{"train_lr": 0.0009455577588320898, "train_loss_total": 1.9036409109830856, "train_loss_cls": 1.9036409109830856, "train_acc1_cls": 63.177085399627686, "train_acc5_cls": 79.16667079925537, "epoch": 16, "n_parameters": 617919468}
Evaluation on epoch 17: loss: 2.264, acc1_cls: 55.297, acc5_cls: 71.610
{"train_lr": 0.0009382151866819099, "train_loss_total": 1.7082267105579376, "train_loss_cls": 1.7082267105579376, "train_acc1_cls": 68.22917079925537, "train_acc5_cls": 82.03125476837158, "epoch": 17, "n_parameters": 617919468}
Evaluation on epoch 18: loss: 2.163, acc1_cls: 59.322, acc5_cls: 73.729
{"train_lr": 0.00093044064248847, "train_loss_total": 1.6474045515060425, "train_loss_cls": 1.6474045515060425, "train_acc1_cls": 69.42708587646484, "train_acc5_cls": 84.53125476837158, "epoch": 18, "n_parameters": 617919468}
Evaluation on epoch 19: loss: 2.177, acc1_cls: 57.839, acc5_cls: 74.153
{"train_lr": 0.0009222417987882566, "train_loss_total": 1.464167907834053, "train_loss_cls": 1.464167907834053, "train_acc1_cls": 74.16667079925537, "train_acc5_cls": 86.35417175292969, "epoch": 19, "n_parameters": 617919468}
Evaluation on epoch 20: loss: 2.077, acc1_cls: 60.381, acc5_cls: 76.483
{"train_lr": 0.0009136267468501438, "train_loss_total": 1.360217496752739, "train_loss_cls": 1.360217496752739, "train_acc1_cls": 76.40625476837158, "train_acc5_cls": 87.50000476837158, "epoch": 20, "n_parameters": 617919468}
Evaluation on epoch 21: loss: 2.148, acc1_cls: 59.746, acc5_cls: 76.483
{"train_lr": 0.0009046039886902864, "train_loss_total": 1.2605804353952408, "train_loss_cls": 1.2605804353952408, "train_acc1_cls": 78.17708778381348, "train_acc5_cls": 90.20833778381348, "epoch": 21, "n_parameters": 617919468}
Evaluation on epoch 22: loss: 2.099, acc1_cls: 63.983, acc5_cls: 77.542
{"train_lr": 0.0008951824286816573, "train_loss_total": 1.1590793132781982, "train_loss_cls": 1.1590793132781982, "train_acc1_cls": 81.19792175292969, "train_acc5_cls": 91.6145887374878, "epoch": 22, "n_parameters": 617919468}
Evaluation on epoch 23: loss: 2.034, acc1_cls: 65.042, acc5_cls: 79.661
{"train_lr": 0.0008853713647665069, "train_loss_total": 1.074940711259842, "train_loss_cls": 1.074940711259842, "train_acc1_cls": 82.7083387374878, "train_acc5_cls": 91.66666984558105, "epoch": 23, "n_parameters": 617919468}
Evaluation on epoch 24: loss: 2.021, acc1_cls: 67.161, acc5_cls: 79.661
{"train_lr": 0.0008751804792804147, "train_loss_total": 0.9628634452819824, "train_loss_cls": 0.9628634452819824, "train_acc1_cls": 85.00000476837158, "train_acc5_cls": 94.7395887374878, "epoch": 24, "n_parameters": 617919468}
Evaluation on epoch 25: loss: 2.023, acc1_cls: 67.797, acc5_cls: 81.356
{"train_lr": 0.0008646198293969952, "train_loss_total": 0.9216240048408508, "train_loss_cls": 0.9216240048408508, "train_acc1_cls": 86.5625057220459, "train_acc5_cls": 94.11458778381348, "epoch": 25, "n_parameters": 617919468}
Evaluation on epoch 26: loss: 2.015, acc1_cls: 67.373, acc5_cls: 81.568
{"train_lr": 0.0008536998372026805, "train_loss_total": 0.8340670391917229, "train_loss_cls": 0.8340670391917229, "train_acc1_cls": 87.8125057220459, "train_acc5_cls": 95.0000057220459, "epoch": 26, "n_parameters": 617919468}
Evaluation on epoch 27: loss: 2.001, acc1_cls: 67.585, acc5_cls: 80.085
{"train_lr": 0.0008424312794113801, "train_loss_total": 0.7466919124126434, "train_loss_cls": 0.7466919124126434, "train_acc1_cls": 89.7395887374878, "train_acc5_cls": 95.57292175292969, "epoch": 27, "n_parameters": 617919468}
Evaluation on epoch 28: loss: 2.031, acc1_cls: 66.949, acc5_cls: 81.568
{"train_lr": 0.0008308252767291642, "train_loss_total": 0.7355886623263359, "train_loss_cls": 0.7355886623263359, "train_acc1_cls": 90.26042175292969, "train_acc5_cls": 95.9375057220459, "epoch": 28, "n_parameters": 617919468}
Evaluation on epoch 29: loss: 1.985, acc1_cls: 69.703, acc5_cls: 81.356
{"train_lr": 0.0008188932828794706, "train_loss_total": 0.6755460947751999, "train_loss_cls": 0.6755460947751999, "train_acc1_cls": 91.041672706604, "train_acc5_cls": 97.08333778381348, "epoch": 29, "n_parameters": 617919468}
Evaluation on epoch 30: loss: 1.900, acc1_cls: 66.949, acc5_cls: 82.627
{"train_lr": 0.0008066470732996619, "train_loss_total": 0.6230156794190407, "train_loss_cls": 0.6230156794190407, "train_acc1_cls": 92.5520887374878, "train_acc5_cls": 97.34375476837158, "epoch": 30, "n_parameters": 617919468}
Evaluation on epoch 31: loss: 1.866, acc1_cls: 67.585, acc5_cls: 82.839
{"train_lr": 0.0007940987335200905, "train_loss_total": 0.5795375928282738, "train_loss_cls": 0.5795375928282738, "train_acc1_cls": 93.64583778381348, "train_acc5_cls": 97.8125057220459, "epoch": 31, "n_parameters": 617919468}
Evaluation on epoch 32: loss: 1.876, acc1_cls: 69.492, acc5_cls: 82.839
{"train_lr": 0.0007812606472371394, "train_loss_total": 0.5066105276346207, "train_loss_cls": 0.5066105276346207, "train_acc1_cls": 94.5312557220459, "train_acc5_cls": 98.80208778381348, "epoch": 32, "n_parameters": 617919468}
Evaluation on epoch 33: loss: 1.882, acc1_cls: 70.551, acc5_cls: 82.839
{"train_lr": 0.0007681454840920089, "train_loss_total": 0.485626894980669, "train_loss_cls": 0.485626894980669, "train_acc1_cls": 94.47917079925537, "train_acc5_cls": 98.75000476837158, "epoch": 33, "n_parameters": 617919468}
Evaluation on epoch 34: loss: 1.807, acc1_cls: 69.068, acc5_cls: 82.839
{"train_lr": 0.0007547661871673105, "train_loss_total": 0.5104515142738819, "train_loss_cls": 0.5104515142738819, "train_acc1_cls": 94.16667175292969, "train_acc5_cls": 97.91667079925537, "epoch": 34, "n_parameters": 617919468}
Evaluation on epoch 35: loss: 1.707, acc1_cls: 70.975, acc5_cls: 83.686
{"train_lr": 0.0007411359602138069, "train_loss_total": 0.3967091962695122, "train_loss_cls": 0.3967091962695122, "train_acc1_cls": 97.18750476837158, "train_acc5_cls": 99.010422706604, "epoch": 35, "n_parameters": 617919468}
Evaluation on epoch 36: loss: 1.688, acc1_cls: 68.432, acc5_cls: 84.110
{"train_lr": 0.0007272682546199037, "train_loss_total": 0.3968052640557289, "train_loss_cls": 0.3968052640557289, "train_acc1_cls": 96.92708778381348, "train_acc5_cls": 99.32292175292969, "epoch": 36, "n_parameters": 617919468}
Evaluation on epoch 37: loss: 1.711, acc1_cls: 69.703, acc5_cls: 83.898
{"train_lr": 0.0007131767561367538, "train_loss_total": 0.38590413331985474, "train_loss_cls": 0.38590413331985474, "train_acc1_cls": 96.61458778381348, "train_acc5_cls": 99.01042175292969, "epoch": 37, "n_parameters": 617919468}
Evaluation on epoch 38: loss: 1.639, acc1_cls: 70.763, acc5_cls: 83.475
{"train_lr": 0.0006988753713720729, "train_loss_total": 0.37987853959202766, "train_loss_cls": 0.37987853959202766, "train_acc1_cls": 96.56250476837158, "train_acc5_cls": 99.1145887374878, "epoch": 38, "n_parameters": 617919468}
Evaluation on epoch 39: loss: 1.650, acc1_cls: 70.975, acc5_cls: 83.051
{"train_lr": 0.0006843782140659968, "train_loss_total": 0.3572259582579136, "train_loss_cls": 0.3572259582579136, "train_acc1_cls": 97.18750381469727, "train_acc5_cls": 99.42708778381348, "epoch": 39, "n_parameters": 617919468}
Evaluation on epoch 40: loss: 1.634, acc1_cls: 71.398, acc5_cls: 83.263
{"train_lr": 0.0006696995911625233, "train_loss_total": 0.31429049000144005, "train_loss_cls": 0.31429049000144005, "train_acc1_cls": 97.65625667572021, "train_acc5_cls": 99.42708778381348, "epoch": 40, "n_parameters": 617919468}
Evaluation on epoch 41: loss: 1.627, acc1_cls: 70.339, acc5_cls: 84.110
{"train_lr": 0.0006548539886902864, "train_loss_total": 0.32123273983597755, "train_loss_cls": 0.32123273983597755, "train_acc1_cls": 97.2395887374878, "train_acc5_cls": 99.1145887374878, "epoch": 41, "n_parameters": 617919468}
Evaluation on epoch 42: loss: 1.598, acc1_cls: 70.339, acc5_cls: 83.263
{"train_lr": 0.0006398560574665951, "train_loss_total": 0.3422344885766506, "train_loss_cls": 0.3422344885766506, "train_acc1_cls": 97.34375381469727, "train_acc5_cls": 99.27083778381348, "epoch": 42, "n_parameters": 617919468}
Evaluation on epoch 43: loss: 1.586, acc1_cls: 70.339, acc5_cls: 83.051
{"train_lr": 0.0006247205986388449, "train_loss_total": 0.2979968711733818, "train_loss_cls": 0.2979968711733818, "train_acc1_cls": 97.604172706604, "train_acc5_cls": 99.21875476837158, "epoch": 43, "n_parameters": 617919468}
Evaluation on epoch 44: loss: 1.610, acc1_cls: 69.915, acc5_cls: 84.110
{"train_lr": 0.0006094625490775732, "train_loss_total": 0.2820843942463398, "train_loss_cls": 0.2820843942463398, "train_acc1_cls": 98.2812557220459, "train_acc5_cls": 99.6875057220459, "epoch": 44, "n_parameters": 617919468}
Evaluation on epoch 45: loss: 1.595, acc1_cls: 70.975, acc5_cls: 83.475
{"train_lr": 0.0005940969666355697, "train_loss_total": 0.2776931170374155, "train_loss_cls": 0.2776931170374155, "train_acc1_cls": 98.385422706604, "train_acc5_cls": 99.47917175292969, "epoch": 45, "n_parameters": 617919468}
Evaluation on epoch 46: loss: 1.578, acc1_cls: 73.093, acc5_cls: 84.322
{"train_lr": 0.0005786390152875954, "train_loss_total": 0.2394380010664463, "train_loss_cls": 0.2394380010664463, "train_acc1_cls": 98.69792175292969, "train_acc5_cls": 99.791672706604, "epoch": 46, "n_parameters": 617919468}
Evaluation on epoch 47: loss: 1.540, acc1_cls: 73.517, acc5_cls: 85.381
{"train_lr": 0.0005631039501653701, "train_loss_total": 0.255794582888484, "train_loss_cls": 0.255794582888484, "train_acc1_cls": 98.33333778381348, "train_acc5_cls": 99.5312557220459, "epoch": 47, "n_parameters": 617919468}
Evaluation on epoch 48: loss: 1.533, acc1_cls: 72.669, acc5_cls: 85.381
{"train_lr": 0.000547507102502598, "train_loss_total": 0.25965049117803574, "train_loss_cls": 0.25965049117803574, "train_acc1_cls": 98.12500667572021, "train_acc5_cls": 99.58333778381348, "epoch": 48, "n_parameters": 617919468}
Evaluation on epoch 49: loss: 1.541, acc1_cls: 71.610, acc5_cls: 84.322
{"train_lr": 0.0005318638645048922, "train_loss_total": 0.2555552329868078, "train_loss_cls": 0.2555552329868078, "train_acc1_cls": 98.59375476837158, "train_acc5_cls": 99.63542079925537, "epoch": 49, "n_parameters": 617919468}
Evaluation on epoch 50: loss: 1.549, acc1_cls: 71.186, acc5_cls: 85.169
{"train_lr": 0.0005161896741595252, "train_loss_total": 0.23689685389399529, "train_loss_cls": 0.23689685389399529, "train_acc1_cls": 99.0625057220459, "train_acc5_cls": 99.73959064483643, "epoch": 50, "n_parameters": 617919468}
Evaluation on epoch 51: loss: 1.548, acc1_cls: 70.127, acc5_cls: 86.017
{"train_lr": 0.0005005000000000001, "train_loss_total": 0.21646664664149284, "train_loss_cls": 0.21646664664149284, "train_acc1_cls": 99.11458778381348, "train_acc5_cls": 99.8437557220459, "epoch": 51, "n_parameters": 617919468}
Evaluation on epoch 52: loss: 1.519, acc1_cls: 72.458, acc5_cls: 84.322
{"train_lr": 0.000484810325840475, "train_loss_total": 0.23527616821229458, "train_loss_cls": 0.23527616821229458, "train_acc1_cls": 97.96875381469727, "train_acc5_cls": 99.42708683013916, "epoch": 52, "n_parameters": 617919468}
Evaluation on epoch 53: loss: 1.506, acc1_cls: 73.305, acc5_cls: 85.169
{"train_lr": 0.00046913613549510807, "train_loss_total": 0.22884040512144566, "train_loss_cls": 0.22884040512144566, "train_acc1_cls": 98.43750476837158, "train_acc5_cls": 99.94792366027832, "epoch": 53, "n_parameters": 617919468}
Evaluation on epoch 54: loss: 1.508, acc1_cls: 71.822, acc5_cls: 85.381
{"train_lr": 0.0004534928974974022, "train_loss_total": 0.22200461477041245, "train_loss_cls": 0.22200461477041245, "train_acc1_cls": 98.7500057220459, "train_acc5_cls": 99.73958969116211, "epoch": 54, "n_parameters": 617919468}
Evaluation on epoch 55: loss: 1.499, acc1_cls: 72.458, acc5_cls: 85.381
{"train_lr": 0.00043789604983463014, "train_loss_total": 0.2193799763917923, "train_loss_cls": 0.2193799763917923, "train_acc1_cls": 98.48958683013916, "train_acc5_cls": 99.79167175292969, "epoch": 55, "n_parameters": 617919468}
Evaluation on epoch 56: loss: 1.495, acc1_cls: 72.458, acc5_cls: 85.593
{"train_lr": 0.00042236098471240476, "train_loss_total": 0.21825614757835865, "train_loss_cls": 0.21825614757835865, "train_acc1_cls": 98.75000476837158, "train_acc5_cls": 99.8437557220459, "epoch": 56, "n_parameters": 617919468}
Evaluation on epoch 57: loss: 1.504, acc1_cls: 71.610, acc5_cls: 85.805
{"train_lr": 0.00040690303336443065, "train_loss_total": 0.21376760490238667, "train_loss_cls": 0.21376760490238667, "train_acc1_cls": 98.75000476837158, "train_acc5_cls": 99.791672706604, "epoch": 57, "n_parameters": 617919468}
Evaluation on epoch 58: loss: 1.500, acc1_cls: 73.093, acc5_cls: 85.805
{"train_lr": 0.0003915374509224272, "train_loss_total": 0.2011482510715723, "train_loss_cls": 0.2011482510715723, "train_acc1_cls": 98.9062557220459, "train_acc5_cls": 99.791672706604, "epoch": 58, "n_parameters": 617919468}
Evaluation on epoch 59: loss: 1.481, acc1_cls: 75.000, acc5_cls: 85.805
{"train_lr": 0.00037627940136115507, "train_loss_total": 0.20218638330698013, "train_loss_cls": 0.20218638330698013, "train_acc1_cls": 99.16667175292969, "train_acc5_cls": 99.8437557220459, "epoch": 59, "n_parameters": 617919468}
Evaluation on epoch 60: loss: 1.470, acc1_cls: 73.093, acc5_cls: 86.864
{"train_lr": 0.0003611439425334051, "train_loss_total": 0.21671963296830654, "train_loss_cls": 0.21671963296830654, "train_acc1_cls": 98.85417175292969, "train_acc5_cls": 99.73958969116211, "epoch": 60, "n_parameters": 617919468}
Evaluation on epoch 61: loss: 1.464, acc1_cls: 72.881, acc5_cls: 85.805
{"train_lr": 0.000346146011309714, "train_loss_total": 0.19008418172597885, "train_loss_cls": 0.19008418172597885, "train_acc1_cls": 99.2708387374878, "train_acc5_cls": 99.94792366027832, "epoch": 61, "n_parameters": 617919468}
Evaluation on epoch 62: loss: 1.466, acc1_cls: 73.093, acc5_cls: 86.017
{"train_lr": 0.00033130040883747703, "train_loss_total": 0.19313311763107777, "train_loss_cls": 0.19313311763107777, "train_acc1_cls": 99.0625057220459, "train_acc5_cls": 99.791672706604, "epoch": 62, "n_parameters": 617919468}
Evaluation on epoch 63: loss: 1.498, acc1_cls: 72.669, acc5_cls: 85.805
{"train_lr": 0.00031662178593400354, "train_loss_total": 0.19981232099235058, "train_loss_cls": 0.19981232099235058, "train_acc1_cls": 98.8020887374878, "train_acc5_cls": 99.68750476837158, "epoch": 63, "n_parameters": 617919468}
Evaluation on epoch 64: loss: 1.511, acc1_cls: 72.458, acc5_cls: 86.017
{"train_lr": 0.0003021246286279271, "train_loss_total": 0.2045647893100977, "train_loss_cls": 0.2045647893100977, "train_acc1_cls": 99.11458778381348, "train_acc5_cls": 99.89584064483643, "epoch": 64, "n_parameters": 617919468}
Evaluation on epoch 65: loss: 1.493, acc1_cls: 72.669, acc5_cls: 86.229
{"train_lr": 0.00028782324386324626, "train_loss_total": 0.17416657507419586, "train_loss_cls": 0.17416657507419586, "train_acc1_cls": 99.21875476837158, "train_acc5_cls": 99.68750381469727, "epoch": 65, "n_parameters": 617919468}
Evaluation on epoch 66: loss: 1.486, acc1_cls: 73.517, acc5_cls: 86.017
{"train_lr": 0.00027373174538009644, "train_loss_total": 0.1784419883042574, "train_loss_cls": 0.1784419883042574, "train_acc1_cls": 99.27083969116211, "train_acc5_cls": 99.8437557220459, "epoch": 66, "n_parameters": 617919468}
Evaluation on epoch 67: loss: 1.485, acc1_cls: 73.941, acc5_cls: 86.864
{"train_lr": 0.00025986403978619317, "train_loss_total": 0.19112006574869156, "train_loss_cls": 0.19112006574869156, "train_acc1_cls": 99.16667079925537, "train_acc5_cls": 99.8437557220459, "epoch": 67, "n_parameters": 617919468}
Evaluation on epoch 68: loss: 1.468, acc1_cls: 72.881, acc5_cls: 87.288
{"train_lr": 0.00024623381283268956, "train_loss_total": 0.18439600616693497, "train_loss_cls": 0.18439600616693497, "train_acc1_cls": 99.06250476837158, "train_acc5_cls": 99.89583969116211, "epoch": 68, "n_parameters": 617919468}
Evaluation on epoch 69: loss: 1.449, acc1_cls: 73.729, acc5_cls: 87.500
{"train_lr": 0.00023285451590799108, "train_loss_total": 0.17133538238704205, "train_loss_cls": 0.17133538238704205, "train_acc1_cls": 99.58333778381348, "train_acc5_cls": 99.94792366027832, "epoch": 69, "n_parameters": 617919468}
Evaluation on epoch 70: loss: 1.429, acc1_cls: 74.364, acc5_cls: 86.864
{"train_lr": 0.00021973935276286074, "train_loss_total": 0.16827588714659214, "train_loss_cls": 0.16827588714659214, "train_acc1_cls": 99.47917175292969, "train_acc5_cls": 99.84375667572021, "epoch": 70, "n_parameters": 617919468}
Evaluation on epoch 71: loss: 1.415, acc1_cls: 74.788, acc5_cls: 86.653
{"train_lr": 0.00020690126647990973, "train_loss_total": 0.17411170154809952, "train_loss_cls": 0.17411170154809952, "train_acc1_cls": 99.42708778381348, "train_acc5_cls": 99.89583969116211, "epoch": 71, "n_parameters": 617919468}
Evaluation on epoch 72: loss: 1.409, acc1_cls: 75.000, acc5_cls: 86.441
{"train_lr": 0.0001943529267003382, "train_loss_total": 0.17387386038899422, "train_loss_cls": 0.17387386038899422, "train_acc1_cls": 99.37500476837158, "train_acc5_cls": 99.94792366027832, "epoch": 72, "n_parameters": 617919468}
Evaluation on epoch 73: loss: 1.408, acc1_cls: 75.424, acc5_cls: 86.441
{"train_lr": 0.00018210671712052948, "train_loss_total": 0.16656266897916794, "train_loss_cls": 0.16656266897916794, "train_acc1_cls": 99.53125381469727, "train_acc5_cls": 99.84375667572021, "epoch": 73, "n_parameters": 617919468}
Evaluation on epoch 74: loss: 1.415, acc1_cls: 75.636, acc5_cls: 86.017
{"train_lr": 0.00017017472327083598, "train_loss_total": 0.17727666348218918, "train_loss_cls": 0.17727666348218918, "train_acc1_cls": 99.27083969116211, "train_acc5_cls": 99.79167366027832, "epoch": 74, "n_parameters": 617919468}
Evaluation on epoch 75: loss: 1.428, acc1_cls: 75.000, acc5_cls: 85.805
{"train_lr": 0.00015856872058862, "train_loss_total": 0.17171689867973328, "train_loss_cls": 0.17171689867973328, "train_acc1_cls": 99.21875476837158, "train_acc5_cls": 99.89583969116211, "epoch": 75, "n_parameters": 617919468}
Evaluation on epoch 76: loss: 1.436, acc1_cls: 74.788, acc5_cls: 85.805
{"train_lr": 0.00014730016279731955, "train_loss_total": 0.15703583508729935, "train_loss_cls": 0.15703583508729935, "train_acc1_cls": 99.58333778381348, "train_acc5_cls": 99.94792366027832, "epoch": 76, "n_parameters": 617919468}
Evaluation on epoch 77: loss: 1.434, acc1_cls: 75.000, acc5_cls: 86.017
{"train_lr": 0.00013638017060300505, "train_loss_total": 0.16176719963550568, "train_loss_cls": 0.16176719963550568, "train_acc1_cls": 99.53125381469727, "train_acc5_cls": 99.89583969116211, "epoch": 77, "n_parameters": 617919468}
Evaluation on epoch 78: loss: 1.427, acc1_cls: 74.153, acc5_cls: 85.593
{"train_lr": 0.00012581952071958545, "train_loss_total": 0.16612250916659832, "train_loss_cls": 0.16612250916659832, "train_acc1_cls": 99.3750057220459, "train_acc5_cls": 99.8437557220459, "epoch": 78, "n_parameters": 617919468}
Evaluation on epoch 79: loss: 1.426, acc1_cls: 75.000, acc5_cls: 86.017
{"train_lr": 0.00011562863523349333, "train_loss_total": 0.16104801557958126, "train_loss_cls": 0.16104801557958126, "train_acc1_cls": 99.42708778381348, "train_acc5_cls": 99.8437557220459, "epoch": 79, "n_parameters": 617919468}
Evaluation on epoch 80: loss: 1.426, acc1_cls: 74.788, acc5_cls: 86.017
{"train_lr": 0.00010581757131834264, "train_loss_total": 0.17065511643886566, "train_loss_cls": 0.17065511643886566, "train_acc1_cls": 99.21875476837158, "train_acc5_cls": 99.791672706604, "epoch": 80, "n_parameters": 617919468}
Evaluation on epoch 81: loss: 1.426, acc1_cls: 75.000, acc5_cls: 86.441
{"train_lr": 9.639601130971382e-05, "train_loss_total": 0.15232647024095058, "train_loss_cls": 0.15232647024095058, "train_acc1_cls": 99.68750667572021, "train_acc5_cls": 99.94792366027832, "epoch": 81, "n_parameters": 617919468}
Evaluation on epoch 82: loss: 1.430, acc1_cls: 74.576, acc5_cls: 86.017
{"train_lr": 8.737325314985643e-05, "train_loss_total": 0.1776103712618351, "train_loss_cls": 0.1776103712618351, "train_acc1_cls": 99.16667175292969, "train_acc5_cls": 99.7395887374878, "epoch": 82, "n_parameters": 617919468}
Evaluation on epoch 83: loss: 1.433, acc1_cls: 73.941, acc5_cls: 86.441
{"train_lr": 7.875820121174359e-05, "train_loss_total": 0.14818879030644894, "train_loss_cls": 0.14818879030644894, "train_acc1_cls": 99.84375667572021, "train_acc5_cls": 100.00000762939453, "epoch": 83, "n_parameters": 617919468}
Evaluation on epoch 84: loss: 1.430, acc1_cls: 73.941, acc5_cls: 86.653
{"train_lr": 7.05593575115301e-05, "train_loss_total": 0.16123313643038273, "train_loss_cls": 0.16123313643038273, "train_acc1_cls": 99.37500381469727, "train_acc5_cls": 99.89583969116211, "epoch": 84, "n_parameters": 617919468}
Evaluation on epoch 85: loss: 1.432, acc1_cls: 74.576, acc5_cls: 86.441
{"train_lr": 6.278481331809015e-05, "train_loss_total": 0.15133901871740818, "train_loss_cls": 0.15133901871740818, "train_acc1_cls": 99.53125476837158, "train_acc5_cls": 99.94792366027832, "epoch": 85, "n_parameters": 617919468}
Evaluation on epoch 86: loss: 1.432, acc1_cls: 75.847, acc5_cls: 86.441
{"train_lr": 5.544224116791029e-05, "train_loss_total": 0.1500077974051237, "train_loss_cls": 0.1500077974051237, "train_acc1_cls": 99.166672706604, "train_acc5_cls": 99.791672706604, "epoch": 86, "n_parameters": 617919468}
