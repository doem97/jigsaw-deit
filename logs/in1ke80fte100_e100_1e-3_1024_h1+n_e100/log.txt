batch_size: 256
epochs: 100
bce_loss: True
unscale_lr: True
rec: False
freeze: False
model: jigsaw_base_patch56_336
input_size: 336
permcls: 50
drop: 0.0
drop_path: 0.1
model_ema: True
model_ema_decay: 0.99996
model_ema_force_cpu: False
opt: adamw
opt_eps: 1e-08
opt_betas: None
clip_grad: None
momentum: 0.9
weight_decay: 0.05
sched: cosine
lr: 0.001
lr_noise: None
lr_noise_pct: 0.67
lr_noise_std: 1.0
warmup_lr: 1e-06
min_lr: 1e-06
decay_epochs: 30
warmup_epochs: 0
cooldown_epochs: 10
patience_epochs: 10
decay_rate: 0.1
color_jitter: 0.3
aa: rand-m9-mstd0.5-inc1
smoothing: None
train_interpolation: bicubic
repeated_aug: True
train_mode: True
ThreeAugment: False
src: False
reprob: 0.25
remode: pixel
recount: 1
resplit: False
mixup: 0.0
cutmix: 0.0
cutmix_minmax: None
mixup_prob: 1.0
mixup_switch_prob: 0.5
mixup_mode: batch
teacher_model: regnety_160
teacher_path: 
distillation_type: none
distillation_alpha: 0.5
distillation_tau: 1.0
finetune: ./outputs/jigsaw_base_p56_336_f101_shuffle_in1ke10fte300/best_checkpoint_e100.pth
attn_only: False
data_path: ./data/food101/
data_set: IMNET
nb_classes: 50
inat_category: name
output_dir: ./outputs/in1ke80fte100_e100_1e-3_1024_h1+n_e100
log_dir: ./logs/in1ke80fte100_e100_1e-3_1024_h1+n_e100
device: cuda
seed: 0
resume: 
start_epoch: 0
eval: False
eval_crop_ratio: 0.875
dist_eval: False
num_workers: 10
pin_mem: True
world_size: 4
dist_url: env://
local_rank: 0
use_jigsaw: True
use_cls: True
lambda_rec: 0.1
mask_ratio: 0.0
rank: 0
gpu: 0
distributed: True
dist_backend: nccl

batch_size: 256
epochs: 100
bce_loss: True
unscale_lr: True
rec: False
freeze: True
model: jigsaw_base_patch56_336
input_size: 336
permcls: 50
drop: 0.0
drop_path: 0.1
model_ema: True
model_ema_decay: 0.99996
model_ema_force_cpu: False
opt: adamw
opt_eps: 1e-08
opt_betas: None
clip_grad: None
momentum: 0.9
weight_decay: 0.05
sched: cosine
lr: 0.001
lr_noise: None
lr_noise_pct: 0.67
lr_noise_std: 1.0
warmup_lr: 1e-06
min_lr: 1e-06
decay_epochs: 30
warmup_epochs: 0
cooldown_epochs: 10
patience_epochs: 10
decay_rate: 0.1
color_jitter: 0.3
aa: rand-m9-mstd0.5-inc1
smoothing: None
train_interpolation: bicubic
repeated_aug: True
train_mode: True
ThreeAugment: False
src: False
reprob: 0.25
remode: pixel
recount: 1
resplit: False
mixup: 0.0
cutmix: 0.0
cutmix_minmax: None
mixup_prob: 1.0
mixup_switch_prob: 0.5
mixup_mode: batch
teacher_model: regnety_160
teacher_path: 
distillation_type: none
distillation_alpha: 0.5
distillation_tau: 1.0
finetune: ./outputs/jigsaw_base_p56_336_f101_shuffle_in1ke10fte300/best_checkpoint_e100.pth
attn_only: False
data_path: ./data/food101/
data_set: IMNET
nb_classes: 50
inat_category: name
output_dir: ./outputs/in1ke80fte100_e100_1e-3_1024_h1+n_e100
log_dir: ./logs/in1ke80fte100_e100_1e-3_1024_h1+n_e100
device: cuda
seed: 0
resume: 
start_epoch: 0
eval: False
eval_crop_ratio: 0.875
dist_eval: False
num_workers: 10
pin_mem: True
world_size: 4
dist_url: env://
local_rank: 0
use_jigsaw: True
use_cls: True
lambda_rec: 0.1
mask_ratio: 0.0
rank: 0
gpu: 0
distributed: True
dist_backend: nccl

Evaluation on epoch 0: loss: 58.770, acc1_cls: 1.907, acc5_cls: 16.102
{"train_lr": 0.001, "train_loss_total": 4.214576065540314, "train_loss_cls": 4.214576065540314, "train_acc1_cls": 5.46875, "train_acc5_cls": 16.69921875, "epoch": 0, "n_parameters": 613877740}
Evaluation on epoch 1: loss: 13.758, acc1_cls: 6.992, acc5_cls: 23.517
{"train_lr": 0.001, "train_loss_total": 3.2023474872112274, "train_loss_cls": 3.2023474872112274, "train_acc1_cls": 28.61328125, "train_acc5_cls": 45.166015625, "epoch": 1, "n_parameters": 613877740}
Evaluation on epoch 2: loss: 7.941, acc1_cls: 13.559, acc5_cls: 27.331
{"train_lr": 0.0009997535269026829, "train_loss_total": 2.7858398258686066, "train_loss_cls": 2.7858398258686066, "train_acc1_cls": 39.697265625, "train_acc5_cls": 56.494140625, "epoch": 2, "n_parameters": 613877740}
Evaluation on epoch 3: loss: 9.572, acc1_cls: 6.144, acc5_cls: 29.661
{"train_lr": 0.0009990143508499217, "train_loss_total": 2.5489780604839325, "train_loss_cls": 2.5489780604839325, "train_acc1_cls": 48.046875, "train_acc5_cls": 64.453125, "epoch": 3, "n_parameters": 613877740}
Evaluation on epoch 4: loss: 7.102, acc1_cls: 11.229, acc5_cls: 28.602
{"train_lr": 0.0009977832013192385, "train_loss_total": 2.444714218378067, "train_loss_cls": 2.444714218378067, "train_acc1_cls": 48.33984375, "train_acc5_cls": 67.333984375, "epoch": 4, "n_parameters": 613877740}
Evaluation on epoch 5: loss: 7.243, acc1_cls: 9.110, acc5_cls: 27.542
{"train_lr": 0.0009960612933065818, "train_loss_total": 2.2256695330142975, "train_loss_cls": 2.2256695330142975, "train_acc1_cls": 56.591796875, "train_acc5_cls": 72.705078125, "epoch": 5, "n_parameters": 613877740}
Evaluation on epoch 6: loss: 5.690, acc1_cls: 9.958, acc5_cls: 36.017
{"train_lr": 0.0009938503261272714, "train_loss_total": 2.1447260975837708, "train_loss_cls": 2.1447260975837708, "train_acc1_cls": 58.251953125, "train_acc5_cls": 75.146484375, "epoch": 6, "n_parameters": 613877740}
Evaluation on epoch 7: loss: 4.094, acc1_cls: 20.975, acc5_cls: 40.678
{"train_lr": 0.00099115248173898, "train_loss_total": 2.0222464948892593, "train_loss_cls": 2.0222464948892593, "train_acc1_cls": 61.083984375, "train_acc5_cls": 77.83203125, "epoch": 7, "n_parameters": 613877740}
Evaluation on epoch 8: loss: 3.960, acc1_cls: 18.644, acc5_cls: 43.432
{"train_lr": 0.0009879704225884043, "train_loss_total": 1.9312320798635483, "train_loss_cls": 1.9312320798635483, "train_acc1_cls": 64.111328125, "train_acc5_cls": 79.58984375, "epoch": 8, "n_parameters": 613877740}
Evaluation on epoch 9: loss: 3.688, acc1_cls: 23.941, acc5_cls: 44.492
{"train_lr": 0.0009843072889837512, "train_loss_total": 1.8210303783416748, "train_loss_cls": 1.8210303783416748, "train_acc1_cls": 67.041015625, "train_acc5_cls": 83.0078125, "epoch": 9, "n_parameters": 613877740}
Evaluation on epoch 10: loss: 3.563, acc1_cls: 24.576, acc5_cls: 45.127
{"train_lr": 0.000980166695995633, "train_loss_total": 1.7762503027915955, "train_loss_cls": 1.7762503027915955, "train_acc1_cls": 69.384765625, "train_acc5_cls": 84.66796875, "epoch": 10, "n_parameters": 613877740}
Evaluation on epoch 11: loss: 3.445, acc1_cls: 24.788, acc5_cls: 47.246
{"train_lr": 0.0009755527298894294, "train_loss_total": 1.7082444578409195, "train_loss_cls": 1.7082444578409195, "train_acc1_cls": 70.263671875, "train_acc5_cls": 84.86328125, "epoch": 11, "n_parameters": 613877740}
Evaluation on epoch 12: loss: 3.348, acc1_cls: 25.847, acc5_cls: 45.763
{"train_lr": 0.0009704699440926358, "train_loss_total": 1.585990771651268, "train_loss_cls": 1.585990771651268, "train_acc1_cls": 74.365234375, "train_acc5_cls": 87.6953125, "epoch": 12, "n_parameters": 613877740}
Evaluation on epoch 13: loss: 3.307, acc1_cls: 23.517, acc5_cls: 46.822
{"train_lr": 0.0009649233547011816, "train_loss_total": 1.4996010512113571, "train_loss_cls": 1.4996010512113571, "train_acc1_cls": 77.34375, "train_acc5_cls": 88.76953125, "epoch": 13, "n_parameters": 613877740}
Evaluation on epoch 14: loss: 3.148, acc1_cls: 25.424, acc5_cls: 48.729
{"train_lr": 0.0009589184355291487, "train_loss_total": 1.4604898393154144, "train_loss_cls": 1.4604898393154144, "train_acc1_cls": 77.490234375, "train_acc5_cls": 89.404296875, "epoch": 14, "n_parameters": 613877740}
Evaluation on epoch 15: loss: 3.047, acc1_cls: 28.814, acc5_cls: 50.424
{"train_lr": 0.0009524611127067769, "train_loss_total": 1.3442102819681168, "train_loss_cls": 1.3442102819681168, "train_acc1_cls": 81.298828125, "train_acc5_cls": 91.064453125, "epoch": 15, "n_parameters": 613877740}
Evaluation on epoch 16: loss: 3.086, acc1_cls: 25.847, acc5_cls: 50.000
{"train_lr": 0.0009455577588320898, "train_loss_total": 1.319046601653099, "train_loss_cls": 1.319046601653099, "train_acc1_cls": 81.640625, "train_acc5_cls": 91.162109375, "epoch": 16, "n_parameters": 613877740}
Evaluation on epoch 17: loss: 3.092, acc1_cls: 26.271, acc5_cls: 47.881
{"train_lr": 0.0009382151866819099, "train_loss_total": 1.1931919008493423, "train_loss_cls": 1.1931919008493423, "train_acc1_cls": 84.9609375, "train_acc5_cls": 93.06640625, "epoch": 17, "n_parameters": 613877740}
Evaluation on epoch 18: loss: 3.007, acc1_cls: 28.814, acc5_cls: 51.907
{"train_lr": 0.00093044064248847, "train_loss_total": 1.1801007688045502, "train_loss_cls": 1.1801007688045502, "train_acc1_cls": 84.912109375, "train_acc5_cls": 93.896484375, "epoch": 18, "n_parameters": 613877740}
Evaluation on epoch 19: loss: 2.925, acc1_cls: 31.992, acc5_cls: 55.720
{"train_lr": 0.0009222417987882566, "train_loss_total": 1.105360358953476, "train_loss_cls": 1.105360358953476, "train_acc1_cls": 86.181640625, "train_acc5_cls": 94.384765625, "epoch": 19, "n_parameters": 613877740}
Evaluation on epoch 20: loss: 2.873, acc1_cls: 35.805, acc5_cls: 55.508
{"train_lr": 0.0009136267468501438, "train_loss_total": 1.0498407036066055, "train_loss_cls": 1.0498407036066055, "train_acc1_cls": 87.744140625, "train_acc5_cls": 94.43359375, "epoch": 20, "n_parameters": 613877740}
Evaluation on epoch 21: loss: 2.877, acc1_cls: 36.229, acc5_cls: 55.720
{"train_lr": 0.0009046039886902864, "train_loss_total": 1.0108099579811096, "train_loss_cls": 1.0108099579811096, "train_acc1_cls": 87.353515625, "train_acc5_cls": 94.775390625, "epoch": 21, "n_parameters": 613877740}
Evaluation on epoch 22: loss: 2.897, acc1_cls: 34.746, acc5_cls: 54.873
{"train_lr": 0.0008951824286816573, "train_loss_total": 0.9438594058156013, "train_loss_cls": 0.9438594058156013, "train_acc1_cls": 88.96484375, "train_acc5_cls": 94.921875, "epoch": 22, "n_parameters": 613877740}
Evaluation on epoch 23: loss: 2.908, acc1_cls: 34.110, acc5_cls: 53.390
{"train_lr": 0.0008853713647665069, "train_loss_total": 0.8800778090953827, "train_loss_cls": 0.8800778090953827, "train_acc1_cls": 90.8203125, "train_acc5_cls": 96.533203125, "epoch": 23, "n_parameters": 613877740}
Evaluation on epoch 24: loss: 2.883, acc1_cls: 34.534, acc5_cls: 55.508
{"train_lr": 0.0008751804792804147, "train_loss_total": 0.8815255612134933, "train_loss_cls": 0.8815255612134933, "train_acc1_cls": 89.35546875, "train_acc5_cls": 95.80078125, "epoch": 24, "n_parameters": 613877740}
Evaluation on epoch 25: loss: 2.840, acc1_cls: 38.771, acc5_cls: 58.686
{"train_lr": 0.0008646198293969952, "train_loss_total": 0.8301794677972794, "train_loss_cls": 0.8301794677972794, "train_acc1_cls": 91.455078125, "train_acc5_cls": 96.58203125, "epoch": 25, "n_parameters": 613877740}
Evaluation on epoch 26: loss: 2.820, acc1_cls: 37.924, acc5_cls: 58.898
{"train_lr": 0.0008536998372026805, "train_loss_total": 0.8071666955947876, "train_loss_cls": 0.8071666955947876, "train_acc1_cls": 90.966796875, "train_acc5_cls": 96.484375, "epoch": 26, "n_parameters": 613877740}
Evaluation on epoch 27: loss: 2.836, acc1_cls: 38.347, acc5_cls: 59.322
{"train_lr": 0.0008424312794113801, "train_loss_total": 0.7209650948643684, "train_loss_cls": 0.7209650948643684, "train_acc1_cls": 92.28515625, "train_acc5_cls": 97.265625, "epoch": 27, "n_parameters": 613877740}
Evaluation on epoch 28: loss: 2.830, acc1_cls: 37.076, acc5_cls: 59.534
{"train_lr": 0.0008308252767291642, "train_loss_total": 0.7426446005702019, "train_loss_cls": 0.7426446005702019, "train_acc1_cls": 92.1875, "train_acc5_cls": 96.97265625, "epoch": 28, "n_parameters": 613877740}
Evaluation on epoch 29: loss: 2.802, acc1_cls: 37.712, acc5_cls: 60.593
{"train_lr": 0.0008188932828794706, "train_loss_total": 0.7153770253062248, "train_loss_cls": 0.7153770253062248, "train_acc1_cls": 92.578125, "train_acc5_cls": 96.826171875, "epoch": 29, "n_parameters": 613877740}
Evaluation on epoch 30: loss: 2.762, acc1_cls: 39.195, acc5_cls: 60.593
{"train_lr": 0.0008066470732996619, "train_loss_total": 0.729598842561245, "train_loss_cls": 0.729598842561245, "train_acc1_cls": 91.845703125, "train_acc5_cls": 96.826171875, "epoch": 30, "n_parameters": 613877740}
Evaluation on epoch 31: loss: 2.741, acc1_cls: 40.890, acc5_cls: 61.017
{"train_lr": 0.0007940987335200905, "train_loss_total": 0.6577882394194603, "train_loss_cls": 0.6577882394194603, "train_acc1_cls": 92.724609375, "train_acc5_cls": 97.412109375, "epoch": 31, "n_parameters": 613877740}
Evaluation on epoch 32: loss: 2.725, acc1_cls: 41.102, acc5_cls: 62.712
{"train_lr": 0.0007812606472371394, "train_loss_total": 0.6279293969273567, "train_loss_cls": 0.6279293969273567, "train_acc1_cls": 93.359375, "train_acc5_cls": 98.095703125, "epoch": 32, "n_parameters": 613877740}
Evaluation on epoch 33: loss: 2.718, acc1_cls: 41.314, acc5_cls: 63.771
{"train_lr": 0.0007681454840920089, "train_loss_total": 0.6122601702809334, "train_loss_cls": 0.6122601702809334, "train_acc1_cls": 93.896484375, "train_acc5_cls": 97.412109375, "epoch": 33, "n_parameters": 613877740}
Evaluation on epoch 34: loss: 2.710, acc1_cls: 41.314, acc5_cls: 64.195
{"train_lr": 0.0007547661871673105, "train_loss_total": 0.6103497296571732, "train_loss_cls": 0.6103497296571732, "train_acc1_cls": 93.408203125, "train_acc5_cls": 98.33984375, "epoch": 34, "n_parameters": 613877740}
Evaluation on epoch 35: loss: 2.712, acc1_cls: 41.737, acc5_cls: 62.924
{"train_lr": 0.0007411359602138069, "train_loss_total": 0.5262717232108116, "train_loss_cls": 0.5262717232108116, "train_acc1_cls": 95.263671875, "train_acc5_cls": 98.6328125, "epoch": 35, "n_parameters": 613877740}
Evaluation on epoch 36: loss: 2.711, acc1_cls: 41.314, acc5_cls: 63.771
{"train_lr": 0.0007272682546199037, "train_loss_total": 0.5918347984552383, "train_loss_cls": 0.5918347984552383, "train_acc1_cls": 94.3359375, "train_acc5_cls": 97.94921875, "epoch": 36, "n_parameters": 613877740}
Evaluation on epoch 37: loss: 2.715, acc1_cls: 41.737, acc5_cls: 63.347
{"train_lr": 0.0007131767561367538, "train_loss_total": 0.5520784929394722, "train_loss_cls": 0.5520784929394722, "train_acc1_cls": 94.482421875, "train_acc5_cls": 98.095703125, "epoch": 37, "n_parameters": 613877740}
Evaluation on epoch 38: loss: 2.720, acc1_cls: 42.585, acc5_cls: 63.559
{"train_lr": 0.0006988753713720729, "train_loss_total": 0.5196399688720703, "train_loss_cls": 0.5196399688720703, "train_acc1_cls": 95.21484375, "train_acc5_cls": 98.486328125, "epoch": 38, "n_parameters": 613877740}
Evaluation on epoch 39: loss: 2.721, acc1_cls: 40.678, acc5_cls: 62.500
{"train_lr": 0.0006843782140659968, "train_loss_total": 0.5196991935372353, "train_loss_cls": 0.5196991935372353, "train_acc1_cls": 95.3125, "train_acc5_cls": 98.291015625, "epoch": 39, "n_parameters": 613877740}
Evaluation on epoch 40: loss: 2.717, acc1_cls: 41.314, acc5_cls: 62.076
{"train_lr": 0.0006696995911625233, "train_loss_total": 0.5074209943413734, "train_loss_cls": 0.5074209943413734, "train_acc1_cls": 94.7265625, "train_acc5_cls": 98.6328125, "epoch": 40, "n_parameters": 613877740}
Evaluation on epoch 41: loss: 2.713, acc1_cls: 40.042, acc5_cls: 62.288
{"train_lr": 0.0006548539886902864, "train_loss_total": 0.4569016359746456, "train_loss_cls": 0.4569016359746456, "train_acc1_cls": 96.19140625, "train_acc5_cls": 99.169921875, "epoch": 41, "n_parameters": 613877740}
Evaluation on epoch 42: loss: 2.708, acc1_cls: 41.314, acc5_cls: 63.136
{"train_lr": 0.0006398560574665951, "train_loss_total": 0.492279727011919, "train_loss_cls": 0.492279727011919, "train_acc1_cls": 95.654296875, "train_acc5_cls": 98.583984375, "epoch": 42, "n_parameters": 613877740}
Evaluation on epoch 43: loss: 2.701, acc1_cls: 40.254, acc5_cls: 63.559
{"train_lr": 0.0006247205986388449, "train_loss_total": 0.4430414289236069, "train_loss_cls": 0.4430414289236069, "train_acc1_cls": 96.19140625, "train_acc5_cls": 99.072265625, "epoch": 43, "n_parameters": 613877740}
Evaluation on epoch 44: loss: 2.693, acc1_cls: 41.102, acc5_cls: 64.407
{"train_lr": 0.0006094625490775732, "train_loss_total": 0.46216288581490517, "train_loss_cls": 0.46216288581490517, "train_acc1_cls": 95.21484375, "train_acc5_cls": 98.6328125, "epoch": 44, "n_parameters": 613877740}
Evaluation on epoch 45: loss: 2.688, acc1_cls: 41.314, acc5_cls: 64.407
{"train_lr": 0.0005940969666355697, "train_loss_total": 0.4353637732565403, "train_loss_cls": 0.4353637732565403, "train_acc1_cls": 96.240234375, "train_acc5_cls": 99.169921875, "epoch": 45, "n_parameters": 613877740}
Evaluation on epoch 46: loss: 2.688, acc1_cls: 41.737, acc5_cls: 65.042
{"train_lr": 0.0005786390152875954, "train_loss_total": 0.4139295518398285, "train_loss_cls": 0.4139295518398285, "train_acc1_cls": 96.240234375, "train_acc5_cls": 99.21875, "epoch": 46, "n_parameters": 613877740}
Evaluation on epoch 47: loss: 2.686, acc1_cls: 41.949, acc5_cls: 65.042
{"train_lr": 0.0005631039501653701, "train_loss_total": 0.3962019346654415, "train_loss_cls": 0.3962019346654415, "train_acc1_cls": 96.826171875, "train_acc5_cls": 99.169921875, "epoch": 47, "n_parameters": 613877740}
Evaluation on epoch 48: loss: 2.692, acc1_cls: 41.314, acc5_cls: 65.466
{"train_lr": 0.000547507102502598, "train_loss_total": 0.3991975523531437, "train_loss_cls": 0.3991975523531437, "train_acc1_cls": 96.435546875, "train_acc5_cls": 99.267578125, "epoch": 48, "n_parameters": 613877740}
Evaluation on epoch 49: loss: 2.707, acc1_cls: 41.949, acc5_cls: 66.949
{"train_lr": 0.0005318638645048922, "train_loss_total": 0.38900426775217056, "train_loss_cls": 0.38900426775217056, "train_acc1_cls": 96.97265625, "train_acc5_cls": 99.072265625, "epoch": 49, "n_parameters": 613877740}
Evaluation on epoch 50: loss: 2.718, acc1_cls: 41.102, acc5_cls: 66.314
{"train_lr": 0.0005161896741595252, "train_loss_total": 0.3713434524834156, "train_loss_cls": 0.3713434524834156, "train_acc1_cls": 96.826171875, "train_acc5_cls": 99.21875, "epoch": 50, "n_parameters": 613877740}
Evaluation on epoch 51: loss: 2.724, acc1_cls: 40.466, acc5_cls: 64.619
{"train_lr": 0.0005005000000000001, "train_loss_total": 0.34082234278321266, "train_loss_cls": 0.34082234278321266, "train_acc1_cls": 97.36328125, "train_acc5_cls": 99.267578125, "epoch": 51, "n_parameters": 613877740}
Evaluation on epoch 52: loss: 2.725, acc1_cls: 40.678, acc5_cls: 64.407
{"train_lr": 0.000484810325840475, "train_loss_total": 0.33568713441491127, "train_loss_cls": 0.33568713441491127, "train_acc1_cls": 97.55859375, "train_acc5_cls": 99.560546875, "epoch": 52, "n_parameters": 613877740}
Evaluation on epoch 53: loss: 2.719, acc1_cls: 41.737, acc5_cls: 63.347
{"train_lr": 0.00046913613549510807, "train_loss_total": 0.35009104385972023, "train_loss_cls": 0.35009104385972023, "train_acc1_cls": 97.314453125, "train_acc5_cls": 99.462890625, "epoch": 53, "n_parameters": 613877740}
Evaluation on epoch 54: loss: 2.712, acc1_cls: 43.220, acc5_cls: 64.619
{"train_lr": 0.0004534928974974022, "train_loss_total": 0.3348875381052494, "train_loss_cls": 0.3348875381052494, "train_acc1_cls": 97.0703125, "train_acc5_cls": 99.4140625, "epoch": 54, "n_parameters": 613877740}
Evaluation on epoch 55: loss: 2.703, acc1_cls: 44.492, acc5_cls: 65.678
{"train_lr": 0.00043789604983463014, "train_loss_total": 0.33663011714816093, "train_loss_cls": 0.33663011714816093, "train_acc1_cls": 97.65625, "train_acc5_cls": 99.4140625, "epoch": 55, "n_parameters": 613877740}
Evaluation on epoch 56: loss: 2.700, acc1_cls: 44.280, acc5_cls: 65.254
{"train_lr": 0.00042236098471240476, "train_loss_total": 0.32679959014058113, "train_loss_cls": 0.32679959014058113, "train_acc1_cls": 97.75390625, "train_acc5_cls": 99.0234375, "epoch": 56, "n_parameters": 613877740}
Evaluation on epoch 57: loss: 2.701, acc1_cls: 43.644, acc5_cls: 65.678
{"train_lr": 0.00040690303336443065, "train_loss_total": 0.3174440301954746, "train_loss_cls": 0.3174440301954746, "train_acc1_cls": 97.65625, "train_acc5_cls": 99.4140625, "epoch": 57, "n_parameters": 613877740}
Evaluation on epoch 58: loss: 2.705, acc1_cls: 44.068, acc5_cls: 64.195
{"train_lr": 0.0003915374509224272, "train_loss_total": 0.286451892927289, "train_loss_cls": 0.286451892927289, "train_acc1_cls": 98.291015625, "train_acc5_cls": 99.609375, "epoch": 58, "n_parameters": 613877740}
Evaluation on epoch 59: loss: 2.715, acc1_cls: 43.856, acc5_cls: 64.831
{"train_lr": 0.00037627940136115507, "train_loss_total": 0.3133123032748699, "train_loss_cls": 0.3133123032748699, "train_acc1_cls": 97.900390625, "train_acc5_cls": 99.560546875, "epoch": 59, "n_parameters": 613877740}
Evaluation on epoch 60: loss: 2.726, acc1_cls: 42.797, acc5_cls: 63.983
{"train_lr": 0.0003611439425334051, "train_loss_total": 0.29173004627227783, "train_loss_cls": 0.29173004627227783, "train_acc1_cls": 98.388671875, "train_acc5_cls": 99.853515625, "epoch": 60, "n_parameters": 613877740}
Evaluation on epoch 61: loss: 2.736, acc1_cls: 43.644, acc5_cls: 63.136
{"train_lr": 0.000346146011309714, "train_loss_total": 0.28191375732421875, "train_loss_cls": 0.28191375732421875, "train_acc1_cls": 97.998046875, "train_acc5_cls": 99.8046875, "epoch": 61, "n_parameters": 613877740}
Evaluation on epoch 62: loss: 2.742, acc1_cls: 44.280, acc5_cls: 63.136
{"train_lr": 0.00033130040883747703, "train_loss_total": 0.27738963067531586, "train_loss_cls": 0.27738963067531586, "train_acc1_cls": 97.998046875, "train_acc5_cls": 99.51171875, "epoch": 62, "n_parameters": 613877740}
Evaluation on epoch 63: loss: 2.741, acc1_cls: 44.703, acc5_cls: 63.771
{"train_lr": 0.00031662178593400354, "train_loss_total": 0.2561498750001192, "train_loss_cls": 0.2561498750001192, "train_acc1_cls": 98.779296875, "train_acc5_cls": 99.951171875, "epoch": 63, "n_parameters": 613877740}
Evaluation on epoch 64: loss: 2.740, acc1_cls: 44.915, acc5_cls: 64.407
{"train_lr": 0.0003021246286279271, "train_loss_total": 0.2709497045725584, "train_loss_cls": 0.2709497045725584, "train_acc1_cls": 98.388671875, "train_acc5_cls": 99.70703125, "epoch": 64, "n_parameters": 613877740}
Evaluation on epoch 65: loss: 2.741, acc1_cls: 44.915, acc5_cls: 65.042
{"train_lr": 0.00028782324386324626, "train_loss_total": 0.2560252174735069, "train_loss_cls": 0.2560252174735069, "train_acc1_cls": 98.486328125, "train_acc5_cls": 99.8046875, "epoch": 65, "n_parameters": 613877740}
Evaluation on epoch 66: loss: 2.732, acc1_cls: 45.127, acc5_cls: 65.678
{"train_lr": 0.00027373174538009644, "train_loss_total": 0.2531280890107155, "train_loss_cls": 0.2531280890107155, "train_acc1_cls": 98.291015625, "train_acc5_cls": 99.8046875, "epoch": 66, "n_parameters": 613877740}
Evaluation on epoch 67: loss: 2.713, acc1_cls: 45.975, acc5_cls: 66.102
{"train_lr": 0.00025986403978619317, "train_loss_total": 0.23959217965602875, "train_loss_cls": 0.23959217965602875, "train_acc1_cls": 98.828125, "train_acc5_cls": 99.8046875, "epoch": 67, "n_parameters": 613877740}
Evaluation on epoch 68: loss: 2.697, acc1_cls: 45.339, acc5_cls: 67.161
{"train_lr": 0.00024623381283268956, "train_loss_total": 0.25699459575116634, "train_loss_cls": 0.25699459575116634, "train_acc1_cls": 97.998046875, "train_acc5_cls": 99.658203125, "epoch": 68, "n_parameters": 613877740}
Evaluation on epoch 69: loss: 2.685, acc1_cls: 47.458, acc5_cls: 67.797
{"train_lr": 0.00023285451590799108, "train_loss_total": 0.2403707206249237, "train_loss_cls": 0.2403707206249237, "train_acc1_cls": 98.486328125, "train_acc5_cls": 99.755859375, "epoch": 69, "n_parameters": 613877740}
Evaluation on epoch 70: loss: 2.671, acc1_cls: 48.729, acc5_cls: 67.373
{"train_lr": 0.00021973935276286074, "train_loss_total": 0.2350363675504923, "train_loss_cls": 0.2350363675504923, "train_acc1_cls": 98.876953125, "train_acc5_cls": 99.951171875, "epoch": 70, "n_parameters": 613877740}
Evaluation on epoch 71: loss: 2.664, acc1_cls: 48.305, acc5_cls: 67.161
{"train_lr": 0.00020690126647990973, "train_loss_total": 0.23908473923802376, "train_loss_cls": 0.23908473923802376, "train_acc1_cls": 98.681640625, "train_acc5_cls": 99.853515625, "epoch": 71, "n_parameters": 613877740}
