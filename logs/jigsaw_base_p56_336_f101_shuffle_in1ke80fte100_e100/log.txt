batch_size: 256
epochs: 100
bce_loss: True
unscale_lr: True
rec: False
freeze: False
model: jigsaw_base_patch56_336
input_size: 336
permcls: 50
drop: 0.0
drop_path: 0.1
model_ema: True
model_ema_decay: 0.99996
model_ema_force_cpu: False
opt: adamw
opt_eps: 1e-08
opt_betas: None
clip_grad: None
momentum: 0.9
weight_decay: 0.05
sched: cosine
lr: 0.001
lr_noise: None
lr_noise_pct: 0.67
lr_noise_std: 1.0
warmup_lr: 1e-06
min_lr: 1e-08
decay_epochs: 30
warmup_epochs: 0
cooldown_epochs: 10
patience_epochs: 10
decay_rate: 0.1
color_jitter: 0.3
aa: rand-m9-mstd0.5-inc1
smoothing: None
train_interpolation: bicubic
repeated_aug: True
train_mode: True
ThreeAugment: False
src: False
reprob: 0.25
remode: pixel
recount: 1
resplit: False
mixup: 0.0
cutmix: 0.0
cutmix_minmax: None
mixup_prob: 1.0
mixup_switch_prob: 0.5
mixup_mode: batch
teacher_model: regnety_160
teacher_path: 
distillation_type: none
distillation_alpha: 0.5
distillation_tau: 1.0
finetune: ./outputs/jigsaw_base_p56_336_f101_shuffle_in1ke10fte300/best_checkpoint_e100.pth
attn_only: False
data_path: ./data/food101/
data_set: IMNET
nb_classes: 50
inat_category: name
output_dir: ./outputs/jigsaw_base_p56_336_f101_shuffle_in1ke80fte100_e100
log_dir: ./logs/jigsaw_base_p56_336_f101_shuffle_in1ke80fte100_e100
device: cuda
seed: 0
resume: 
start_epoch: 0
eval: False
eval_crop_ratio: 0.875
dist_eval: False
num_workers: 10
pin_mem: True
world_size: 2
dist_url: env://
local_rank: 0
use_jigsaw: True
use_cls: True
lambda_rec: 0.1
mask_ratio: 0.0
rank: 0
gpu: 0
distributed: True
dist_backend: nccl

Evaluation on epoch 0: loss: 42.705, acc1_cls: 2.542, acc5_cls: 12.076
{"train_lr": 0.001, "train_loss_total": 4.242424130439758, "train_loss_cls": 4.242424130439758, "train_acc1_cls": 5.078125, "train_acc5_cls": 14.990234375, "epoch": 0, "n_parameters": 613877740}
Evaluation on epoch 1: loss: 18.610, acc1_cls: 2.119, acc5_cls: 11.229
{"train_lr": 0.001, "train_loss_total": 4.179738521575928, "train_loss_cls": 4.179738521575928, "train_acc1_cls": 5.859375, "train_acc5_cls": 18.798828125, "epoch": 1, "n_parameters": 613877740}
Evaluation on epoch 2: loss: 14.690, acc1_cls: 2.331, acc5_cls: 10.593
{"train_lr": 0.000999753282650064, "train_loss_total": 4.1141796708106995, "train_loss_cls": 4.1141796708106995, "train_acc1_cls": 6.25, "train_acc5_cls": 20.99609375, "epoch": 2, "n_parameters": 613877740}
Evaluation on epoch 3: loss: 14.548, acc1_cls: 2.119, acc5_cls: 10.381
{"train_lr": 0.0009990133740804936, "train_loss_total": 4.1004414558410645, "train_loss_cls": 4.1004414558410645, "train_acc1_cls": 7.275390625, "train_acc5_cls": 22.998046875, "epoch": 3, "n_parameters": 613877740}
Evaluation on epoch 4: loss: 8.870, acc1_cls: 2.119, acc5_cls: 11.864
{"train_lr": 0.000997781004491717, "train_loss_total": 3.939331531524658, "train_loss_cls": 3.939331531524658, "train_acc1_cls": 9.9609375, "train_acc5_cls": 25.68359375, "epoch": 4, "n_parameters": 613877740}
Evaluation on epoch 5: loss: 10.532, acc1_cls: 1.907, acc5_cls: 11.653
{"train_lr": 0.0009960573900837325, "train_loss_total": 3.9380457401275635, "train_loss_cls": 3.9380457401275635, "train_acc1_cls": 8.935546875, "train_acc5_cls": 24.21875, "epoch": 5, "n_parameters": 613877740}
Evaluation on epoch 6: loss: 7.774, acc1_cls: 2.331, acc5_cls: 14.831
{"train_lr": 0.000993844231855866, "train_loss_total": 3.7806694507598877, "train_loss_cls": 3.7806694507598877, "train_acc1_cls": 14.501953125, "train_acc5_cls": 31.787109375, "epoch": 6, "n_parameters": 613877740}
Evaluation on epoch 7: loss: 6.882, acc1_cls: 2.754, acc5_cls: 12.712
{"train_lr": 0.0009911437139280908, "train_loss_total": 3.6121721267700195, "train_loss_cls": 3.6121721267700195, "train_acc1_cls": 17.138671875, "train_acc5_cls": 36.81640625, "epoch": 7, "n_parameters": 613877740}
Evaluation on epoch 8: loss: 5.971, acc1_cls: 3.814, acc5_cls: 16.737
{"train_lr": 0.000987958501385564, "train_loss_total": 3.4781710505485535, "train_loss_cls": 3.4781710505485535, "train_acc1_cls": 21.38671875, "train_acc5_cls": 40.91796875, "epoch": 8, "n_parameters": 613877740}
Evaluation on epoch 9: loss: 5.563, acc1_cls: 7.203, acc5_cls: 18.008
{"train_lr": 0.00098429173764851, "train_loss_total": 3.2299500703811646, "train_loss_cls": 3.2299500703811646, "train_acc1_cls": 26.26953125, "train_acc5_cls": 49.169921875, "epoch": 9, "n_parameters": 613877740}
Evaluation on epoch 10: loss: 5.756, acc1_cls: 6.144, acc5_cls: 17.585
{"train_lr": 0.0009801470413700432, "train_loss_total": 3.1109706461429596, "train_loss_cls": 3.1109706461429596, "train_acc1_cls": 27.63671875, "train_acc5_cls": 49.658203125, "epoch": 10, "n_parameters": 613877740}
Evaluation on epoch 11: loss: 5.268, acc1_cls: 7.203, acc5_cls: 21.822
{"train_lr": 0.0009755285028649954, "train_loss_total": 3.0248614251613617, "train_loss_cls": 3.0248614251613617, "train_acc1_cls": 33.7890625, "train_acc5_cls": 54.00390625, "epoch": 11, "n_parameters": 613877740}
Evaluation on epoch 12: loss: 4.990, acc1_cls: 8.263, acc5_cls: 22.669
{"train_lr": 0.0009704406800732681, "train_loss_total": 2.774529844522476, "train_loss_cls": 2.774529844522476, "train_acc1_cls": 39.697265625, "train_acc5_cls": 62.6953125, "epoch": 12, "n_parameters": 613877740}
Evaluation on epoch 13: loss: 5.080, acc1_cls: 8.051, acc5_cls: 24.153
{"train_lr": 0.0009648885940616963, "train_loss_total": 2.6641146540641785, "train_loss_cls": 2.6641146540641785, "train_acc1_cls": 44.189453125, "train_acc5_cls": 65.13671875, "epoch": 13, "n_parameters": 613877740}
Evaluation on epoch 14: loss: 4.874, acc1_cls: 10.169, acc5_cls: 20.975
{"train_lr": 0.0009588777240688622, "train_loss_total": 2.5580207109451294, "train_loss_cls": 2.5580207109451294, "train_acc1_cls": 46.826171875, "train_acc5_cls": 67.08984375, "epoch": 14, "n_parameters": 613877740}
Evaluation on epoch 15: loss: 4.857, acc1_cls: 8.898, acc5_cls: 25.424
{"train_lr": 0.0009524140020977476, "train_loss_total": 2.3885817527770996, "train_loss_cls": 2.3885817527770996, "train_acc1_cls": 49.70703125, "train_acc5_cls": 71.97265625, "epoch": 15, "n_parameters": 613877740}
Evaluation on epoch 16: loss: 4.767, acc1_cls: 8.263, acc5_cls: 26.483
{"train_lr": 0.0009455038070615631, "train_loss_total": 2.268424928188324, "train_loss_cls": 2.268424928188324, "train_acc1_cls": 53.173828125, "train_acc5_cls": 75.29296875, "epoch": 16, "n_parameters": 613877740}
Evaluation on epoch 17: loss: 4.455, acc1_cls: 10.805, acc5_cls: 27.331
{"train_lr": 0.0009381539584885317, "train_loss_total": 2.0104176104068756, "train_loss_cls": 2.0104176104068756, "train_acc1_cls": 63.37890625, "train_acc5_cls": 80.6640625, "epoch": 17, "n_parameters": 613877740}
Evaluation on epoch 18: loss: 4.068, acc1_cls: 16.949, acc5_cls: 32.203
{"train_lr": 0.0009303717097918369, "train_loss_total": 1.8365095555782318, "train_loss_cls": 1.8365095555782318, "train_acc1_cls": 66.943359375, "train_acc5_cls": 83.203125, "epoch": 18, "n_parameters": 613877740}
Evaluation on epoch 19: loss: 4.033, acc1_cls: 14.831, acc5_cls: 33.475
{"train_lr": 0.0009221647411113801, "train_loss_total": 1.6028655618429184, "train_loss_cls": 1.6028655618429184, "train_acc1_cls": 71.728515625, "train_acc5_cls": 86.865234375, "epoch": 19, "n_parameters": 613877740}
Evaluation on epoch 20: loss: 3.871, acc1_cls: 15.466, acc5_cls: 38.136
{"train_lr": 0.0009135411517344096, "train_loss_total": 1.4472458809614182, "train_loss_cls": 1.4472458809614182, "train_acc1_cls": 76.07421875, "train_acc5_cls": 90.33203125, "epoch": 20, "n_parameters": 613877740}
Evaluation on epoch 21: loss: 3.958, acc1_cls: 8.686, acc5_cls: 38.983
{"train_lr": 0.000904509452102502, "train_loss_total": 1.2828202098608017, "train_loss_cls": 1.2828202098608017, "train_acc1_cls": 79.78515625, "train_acc5_cls": 91.50390625, "epoch": 21, "n_parameters": 613877740}
Evaluation on epoch 22: loss: 3.798, acc1_cls: 7.203, acc5_cls: 40.678
{"train_lr": 0.0008950785554127834, "train_loss_total": 1.0842142701148987, "train_loss_cls": 1.0842142701148987, "train_acc1_cls": 84.912109375, "train_acc5_cls": 93.994140625, "epoch": 22, "n_parameters": 613877740}
Evaluation on epoch 23: loss: 3.645, acc1_cls: 6.568, acc5_cls: 45.339
{"train_lr": 0.0008852577688216809, "train_loss_total": 0.9638542830944061, "train_loss_cls": 0.9638542830944061, "train_acc1_cls": 86.71875, "train_acc5_cls": 95.166015625, "epoch": 23, "n_parameters": 613877740}
Evaluation on epoch 24: loss: 3.610, acc1_cls: 6.356, acc5_cls: 46.822
{"train_lr": 0.0008750567842598818, "train_loss_total": 0.7982520163059235, "train_loss_cls": 0.7982520163059235, "train_acc1_cls": 88.76953125, "train_acc5_cls": 96.6796875, "epoch": 24, "n_parameters": 613877740}
Evaluation on epoch 25: loss: 3.329, acc1_cls: 9.958, acc5_cls: 51.271
{"train_lr": 0.0008644856688675688, "train_loss_total": 0.7258381173014641, "train_loss_cls": 0.7258381173014641, "train_acc1_cls": 90.966796875, "train_acc5_cls": 96.97265625, "epoch": 25, "n_parameters": 613877740}
Evaluation on epoch 26: loss: 2.946, acc1_cls: 24.788, acc5_cls: 61.229
{"train_lr": 0.0008535548550593679, "train_loss_total": 0.6296319290995598, "train_loss_cls": 0.6296319290995598, "train_acc1_cls": 92.578125, "train_acc5_cls": 97.36328125, "epoch": 26, "n_parameters": 613877740}
Evaluation on epoch 27: loss: 2.771, acc1_cls: 32.415, acc5_cls: 64.619
{"train_lr": 0.0008422751302288148, "train_loss_total": 0.49018342792987823, "train_loss_cls": 0.49018342792987823, "train_acc1_cls": 94.775390625, "train_acc5_cls": 99.072265625, "epoch": 27, "n_parameters": 613877740}
Evaluation on epoch 28: loss: 2.699, acc1_cls: 37.076, acc5_cls: 65.466
{"train_lr": 0.0008306576261024994, "train_loss_total": 0.4977323152124882, "train_loss_cls": 0.4977323152124882, "train_acc1_cls": 94.43359375, "train_acc5_cls": 98.779296875, "epoch": 28, "n_parameters": 613877740}
Evaluation on epoch 29: loss: 2.509, acc1_cls: 44.068, acc5_cls: 70.127
{"train_lr": 0.0008187138077543962, "train_loss_total": 0.4306015521287918, "train_loss_cls": 0.4306015521287918, "train_acc1_cls": 96.044921875, "train_acc5_cls": 99.267578125, "epoch": 29, "n_parameters": 613877740}
Evaluation on epoch 30: loss: 2.429, acc1_cls: 47.034, acc5_cls: 70.975
{"train_lr": 0.0008064554622912201, "train_loss_total": 0.38679829239845276, "train_loss_cls": 0.38679829239845276, "train_acc1_cls": 96.240234375, "train_acc5_cls": 99.51171875, "epoch": 30, "n_parameters": 613877740}
Evaluation on epoch 31: loss: 2.377, acc1_cls: 49.576, acc5_cls: 70.551
{"train_lr": 0.0007938946872199753, "train_loss_total": 0.32676312141120434, "train_loss_cls": 0.32676312141120434, "train_acc1_cls": 97.509765625, "train_acc5_cls": 99.51171875, "epoch": 31, "n_parameters": 613877740}
Evaluation on epoch 32: loss: 2.315, acc1_cls: 52.119, acc5_cls: 73.305
{"train_lr": 0.0007810438785091762, "train_loss_total": 0.33590007573366165, "train_loss_cls": 0.33590007573366165, "train_acc1_cls": 97.705078125, "train_acc5_cls": 99.70703125, "epoch": 32, "n_parameters": 613877740}
Evaluation on epoch 33: loss: 2.201, acc1_cls: 56.356, acc5_cls: 72.669
{"train_lr": 0.0007679157183555235, "train_loss_total": 0.2977609746158123, "train_loss_cls": 0.2977609746158123, "train_acc1_cls": 98.2421875, "train_acc5_cls": 99.853515625, "epoch": 33, "n_parameters": 613877740}
Evaluation on epoch 34: loss: 2.136, acc1_cls: 55.932, acc5_cls: 74.788
{"train_lr": 0.0007545231626681071, "train_loss_total": 0.2888934966176748, "train_loss_cls": 0.2888934966176748, "train_acc1_cls": 98.095703125, "train_acc5_cls": 99.755859375, "epoch": 34, "n_parameters": 613877740}
Evaluation on epoch 35: loss: 2.174, acc1_cls: 56.992, acc5_cls: 74.364
{"train_lr": 0.0007408794282824872, "train_loss_total": 0.24623269401490688, "train_loss_cls": 0.24623269401490688, "train_acc1_cls": 98.4375, "train_acc5_cls": 99.8046875, "epoch": 35, "n_parameters": 613877740}
Evaluation on epoch 36: loss: 2.165, acc1_cls: 57.415, acc5_cls: 75.212
{"train_lr": 0.0007269979799172748, "train_loss_total": 0.24506596103310585, "train_loss_cls": 0.24506596103310585, "train_acc1_cls": 99.072265625, "train_acc5_cls": 99.951171875, "epoch": 36, "n_parameters": 613877740}
Evaluation on epoch 37: loss: 2.085, acc1_cls: 59.746, acc5_cls: 75.424
{"train_lr": 0.0007128925168860787, "train_loss_total": 0.22913815267384052, "train_loss_cls": 0.22913815267384052, "train_acc1_cls": 99.267578125, "train_acc5_cls": 100.0, "epoch": 37, "n_parameters": 613877740}
Evaluation on epoch 38: loss: 2.056, acc1_cls: 57.415, acc5_cls: 78.178
{"train_lr": 0.0006985769595779372, "train_loss_total": 0.22034523077309132, "train_loss_cls": 0.22034523077309132, "train_acc1_cls": 98.876953125, "train_acc5_cls": 99.755859375, "epoch": 38, "n_parameters": 613877740}
Evaluation on epoch 39: loss: 2.006, acc1_cls: 59.958, acc5_cls: 74.153
{"train_lr": 0.0006840654357195757, "train_loss_total": 0.22051457688212395, "train_loss_cls": 0.22051457688212395, "train_acc1_cls": 98.876953125, "train_acc5_cls": 99.853515625, "epoch": 39, "n_parameters": 613877740}
Evaluation on epoch 40: loss: 2.020, acc1_cls: 59.534, acc5_cls: 76.695
{"train_lr": 0.0006693722664330447, "train_loss_total": 0.20246868766844273, "train_loss_cls": 0.20246868766844273, "train_acc1_cls": 99.267578125, "train_acc5_cls": 99.951171875, "epoch": 40, "n_parameters": 613877740}
Evaluation on epoch 41: loss: 2.062, acc1_cls: 58.475, acc5_cls: 77.119
{"train_lr": 0.000654511952102502, "train_loss_total": 0.1901016067713499, "train_loss_cls": 0.1901016067713499, "train_acc1_cls": 99.560546875, "train_acc5_cls": 99.951171875, "epoch": 41, "n_parameters": 613877740}
